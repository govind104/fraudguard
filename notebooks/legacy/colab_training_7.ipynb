{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsjoNAnuj7ws"
      },
      "source": [
        "# ğŸ”’ FraudGuard Training Notebook\n",
        "\n",
        "**AD-RL-GNN Fraud Detection** | Full training pipeline with mini-batch processing\n",
        "\n",
        "This notebook trains the FraudGuard model on the IEEE-CIS fraud detection dataset using:\n",
        "- **NeighborLoader** for memory-efficient mini-batch training\n",
        "- **FAISS** for similarity graph construction (GPU if available, CPU fallback)\n",
        "- **FocalLoss** for class-imbalanced learning\n",
        "\n",
        "**Target Metrics:**\n",
        "- Specificity: 98.72%\n",
        "- G-Means Improvement: 18.11%\n",
        "- P95 Latency: <100ms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJcMLlwrj7wu"
      },
      "source": [
        "## 1ï¸âƒ£ Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQkR0H15j7wv",
        "outputId": "de134284-3fcc-46b0-ec2f-a92728717f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for data storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FiJD_x_j7ww",
        "outputId": "baede0ee-f15e-45a3-d2cd-d692070a2ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fraudguard'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 154 (delta 60), reused 125 (delta 42), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (154/154), 104.58 KiB | 5.23 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n",
            "/content/fraudguard\n"
          ]
        }
      ],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/govind104/fraudguard.git\n",
        "%cd fraudguard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vsh_FW9lj7wx",
        "outputId": "672498ce-57ff-458a-a36a-7a9a7e91528f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâš ï¸ faiss-gpu not available, using faiss-cpu\n",
            "   (Graph building on CPU, but GNN training still runs on GPU!)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPyTorch: 2.9.0, CUDA: cu126\n",
            "Downloading from: https://data.pyg.org/whl/torch-2.9.0+cu126.html\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.9.0+cu126.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy (from torch-sparse)\n",
            "  Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<2.7,>=1.26.4 (from scipy->torch-sparse)\n",
            "  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m133.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-scatter, torch-sparse\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp312-cp312-linux_x86_64.whl size=3857028 sha256=f27b7bae55dd1add42c72634a1285d22055bd28e9880af6ee8d840bff370ea96\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/20/50/44800723f57cd798630e77b3ec83bc80bd26a1e3dc3a672ef5\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp312-cp312-linux_x86_64.whl size=3039800 sha256=75c7e442fc8a9526762858c71a2e4e257a2a30b83448a88f8e42d9f9320c6bf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/fa/21/bd1d78ce1629aec4ecc924a63b82f6949dda484b6321eac6f2\n",
            "Successfully built torch-scatter torch-sparse\n",
            "Installing collected packages: torch-scatter, numpy, scipy, torch-sparse\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.4.1 scipy-1.17.0 torch-scatter-2.1.2 torch-sparse-0.6.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "9a9a4a98ea014022a86429b41f462d16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fraudguard\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: faiss-cpu<2.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (1.13.2)\n",
            "Collecting numpy<2.0.0,>=1.24.0 (from fraudguard==0.1.0)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (1.6.1)\n",
            "Collecting structlog<24.0.0,>=23.1.0 (from fraudguard==0.1.0)\n",
            "  Downloading structlog-23.3.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: torch-geometric<3.0.0,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.7.0)\n",
            "Requirement already satisfied: torch-scatter<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.1.2)\n",
            "Requirement already satisfied: torch-sparse<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (0.6.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu<2.0.0,>=1.7.4->fraudguard==0.1.0) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0.0,>=1.3.0->fraudguard==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0.0,>=1.3.0->fraudguard==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0.0,>=1.3.0->fraudguard==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.13.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (2026.1.4)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m132.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading structlog-23.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fraudguard\n",
            "  Building editable for fraudguard (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fraudguard: filename=fraudguard-0.1.0-py3-none-any.whl size=2801 sha256=5638c0b714acd4b297203f70f102910966a1da4432de3a3f589a22ae37244e19\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0ob56ewf/wheels/c6/29/62/fb6d8d095576e7e3efddf4fdcb7dfc799af71ace273f1ee84c\n",
            "Successfully built fraudguard\n",
            "Installing collected packages: structlog, numpy, fraudguard\n",
            "  Attempting uninstall: structlog\n",
            "    Found existing installation: structlog 25.5.0\n",
            "    Uninstalling structlog-25.5.0:\n",
            "      Successfully uninstalled structlog-25.5.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.4.1\n",
            "    Uninstalling numpy-2.4.1:\n",
            "      Successfully uninstalled numpy-2.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fraudguard-0.1.0 numpy-1.26.4 structlog-23.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "2c3a6a8dae7946e0a0ef21cbdb112224"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ“ Environment setup complete\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "# Note: faiss-gpu may not be available on Python 3.12\n",
        "# The code will fallback to faiss-cpu automatically\n",
        "# GNN training STILL runs on GPU - only graph building uses CPU FAISS\n",
        "!pip install -q torch torch-geometric pandas numpy scikit-learn pyyaml structlog\n",
        "\n",
        "# Try faiss-gpu first, fallback to faiss-cpu\n",
        "import subprocess\n",
        "result = subprocess.run(['pip', 'install', '-q', 'faiss-gpu'], capture_output=True)\n",
        "if result.returncode != 0:\n",
        "    print('âš ï¸ faiss-gpu not available, using faiss-cpu')\n",
        "    print('   (Graph building on CPU, but GNN training still runs on GPU!)')\n",
        "    !pip install -q faiss-cpu\n",
        "else:\n",
        "    print('âœ“ faiss-gpu installed')\n",
        "\n",
        "import torch\n",
        "\n",
        "# 1. Get exact versions\n",
        "pt_version = torch.__version__.split('+')[0]  # e.g., 2.5.1\n",
        "cuda_version = \"cu\" + torch.version.cuda.replace('.', '')  # e.g., cu124\n",
        "wheel_url = f\"https://data.pyg.org/whl/torch-{pt_version}+{cuda_version}.html\"\n",
        "\n",
        "print(f\"PyTorch: {pt_version}, CUDA: {cuda_version}\")\n",
        "print(f\"Downloading from: {wheel_url}\")\n",
        "\n",
        "# 2. Install with visible output (force reinstall to fix broken partial installs)\n",
        "!pip install --force-reinstall torch-scatter torch-sparse -f $wheel_url\n",
        "\n",
        "# Install repo in editable mode\n",
        "!pip install -e .\n",
        "\n",
        "print('\\nâœ“ Environment setup complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32LXcfp8_bZ8",
        "outputId": "23cb248a-478a-43e6-bd46-913e8ba79e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Success! Libraries are installed and loaded.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "try:\n",
        "    import torch_scatter\n",
        "    import torch_sparse\n",
        "    import fraudguard\n",
        "    print(\"âœ… Success! Libraries are installed and loaded.\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Still missing libraries: {e}\")\n",
        "    # Only if you see this error should you go back and install again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQIB4vEej7wx"
      },
      "source": [
        "## 2ï¸âƒ£ Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQDtmVWBj7wy",
        "outputId": "cddfe4d6-97e9-40db-c5f8-68e89d4ec312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: /content/drive/MyDrive/ieee-fraud-detection\n",
            "Models: /content/drive/MyDrive/fraudguard-models\n",
            "Logs: /content/drive/MyDrive/fraudguard-logs\n",
            "\n",
            "Batch size: 4096\n",
            "Sample fraction: 100%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# ==============================================\n",
        "# CONFIGURATION - UPDATE THESE PATHS AS NEEDED\n",
        "# ==============================================\n",
        "\n",
        "# Data paths - Point to your Google Drive folders\n",
        "DATA_DIR = \"/content/drive/MyDrive/ieee-fraud-detection\"\n",
        "MODELS_DIR = \"/content/drive/MyDrive/fraudguard-models\"\n",
        "LOGS_DIR = \"/content/drive/MyDrive/fraudguard-logs\"\n",
        "\n",
        "# Training parameters\n",
        "SAMPLE_FRAC = 1.0      # Use full dataset (1.0 = 100%)\n",
        "MAX_EPOCHS = 30\n",
        "BATCH_SIZE = 4096      # Reduce to 2048 or 1024 if OOM\n",
        "NUM_NEIGHBORS = [25, 10]  # 2-hop neighborhood sampling\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(LOGS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Data: {DATA_DIR}\")\n",
        "print(f\"Models: {MODELS_DIR}\")\n",
        "print(f\"Logs: {LOGS_DIR}\")\n",
        "print(f\"\\nBatch size: {BATCH_SIZE}\")\n",
        "print(f\"Sample fraction: {SAMPLE_FRAC*100:.0f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM3sXum3j7wz"
      },
      "source": [
        "## 3ï¸âƒ£ Verify GPU and FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7CHUJ3nj7wz",
        "outputId": "fc6edf58-fe8f-443e-8dc6-524d5bea1a45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "VRAM: 15.8 GB\n",
            "\n",
            "âœ“ GNN training will run on GPU\n",
            "\n",
            "FAISS GPUs: 0\n",
            "   (Using CPU FAISS for graph building - this is OK)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import faiss\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(\"\\nâœ“ GNN training will run on GPU\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ WARNING: No GPU detected. Go to Runtime > Change runtime type > GPU\")\n",
        "\n",
        "# Check FAISS GPU\n",
        "faiss_gpus = faiss.get_num_gpus() if hasattr(faiss, 'get_num_gpus') else 0\n",
        "print(f\"\\nFAISS GPUs: {faiss_gpus}\")\n",
        "if faiss_gpus == 0:\n",
        "    print(\"   (Using CPU FAISS for graph building - this is OK)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmk_r0omj7w0"
      },
      "source": [
        "## 4ï¸âƒ£ Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVU_fGbPj7w0",
        "outputId": "1f669793-bed1-4c64-8257-07d09748487a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading faiss with CPU support (no GPU detected).\n",
            "Using device: cuda\n",
            "\n",
            "Data loaded:\n",
            "  Train: 354,324\n",
            "  Val: 118,108\n",
            "  Test: 118,108\n",
            "  Fraud rate: 3.50%\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/fraudguard')\n",
        "\n",
        "from pathlib import Path\n",
        "from src.data.loader import FraudDataLoader\n",
        "from src.data.preprocessor import FeaturePreprocessor\n",
        "from src.data.graph_builder import GraphBuilder\n",
        "from src.utils.config import load_data_config\n",
        "from src.utils.device_utils import set_seed, get_device\n",
        "\n",
        "set_seed(42)\n",
        "device = get_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load config and override path with notebook variable\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# Load data with corrected path\n",
        "loader = FraudDataLoader(config=data_cfg)\n",
        "df = loader.load_train_data(sample_frac=SAMPLE_FRAC)\n",
        "train_df, val_df, test_df = loader.create_splits(df)\n",
        "\n",
        "print(f\"\\nData loaded:\")\n",
        "print(f\"  Train: {len(train_df):,}\")\n",
        "print(f\"  Val: {len(val_df):,}\")\n",
        "print(f\"  Test: {len(test_df):,}\")\n",
        "print(f\"  Fraud rate: {df['isFraud'].mean()*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV4Kblyi-Xk_"
      },
      "source": [
        "## 5ï¸âƒ£ Run Full AD-RL-GNN Pipeline\n",
        "\n",
        "We use the `FraudTrainer` class to orchestrate the full pipeline, including:\n",
        "1. **AdaptiveMCD**: Intelligent majority downsampling\n",
        "2. **RL Agent**: Dynamic subgraph selection (Random Walk, K-Hop, K-Ego)\n",
        "3. **Graph Enhancement**: Adding semantic edges\n",
        "4. **GNN Training**: CrossEntropyLoss (15x weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVCPMmZ6-Xk_",
        "outputId": "76d9cc1b-6d49-42b1-8f16-22763c1125ca"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Initializing GOLD STANDARD RUN (RL=ON) on 100.0% Data...\n",
            "ğŸ“‰ Loading Full Dataset (590k nodes)...\n",
            "âš™ï¸ Building Full Graph (Threshold 0.75)...\n",
            "\n",
            "ğŸ§  Training AdaptiveMCD (Alpha=0.80)...\n",
            "\n",
            "ğŸ¤– Training RL Agent (Connecting the Dots)...\n",
            "\n",
            "âš–ï¸ Applying Sweet Spot Weight 12.0...\n",
            "\n",
            "ğŸ“¦ Setting up Loaders (Batch Size 4096)...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/neighbor_loader.py:229: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  neighbor_sampler = NeighborSampler(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸš€ Starting Full Data Training...\n",
            "Epoch   1 | Loss: 0.7336 | Spec: 88.38% | Recall: 11.58% | G-Means: 31.99%\n",
            "Epoch   2 | Loss: 0.6669 | Spec: 89.95% | Recall: 10.84% | G-Means: 31.23%\n",
            "Epoch   3 | Loss: 0.6594 | Spec: 92.62% | Recall: 7.07% | G-Means: 25.59%\n",
            "Epoch   4 | Loss: 0.6542 | Spec: 94.10% | Recall: 5.83% | G-Means: 23.43%\n",
            "Epoch   5 | Loss: 0.6477 | Spec: 84.29% | Recall: 17.96% | G-Means: 38.91%\n",
            "Epoch   6 | Loss: 0.6420 | Spec: 82.55% | Recall: 17.89% | G-Means: 38.43%\n",
            "Epoch   7 | Loss: 0.6341 | Spec: 77.14% | Recall: 21.19% | G-Means: 40.43%\n",
            "Epoch   8 | Loss: 0.6254 | Spec: 79.07% | Recall: 21.49% | G-Means: 41.22%\n",
            "Epoch   9 | Loss: 0.6156 | Spec: 75.57% | Recall: 25.33% | G-Means: 43.75%\n",
            "Epoch  10 | Loss: 0.6095 | Spec: 71.09% | Recall: 28.67% | G-Means: 45.15%\n",
            "Epoch  11 | Loss: 0.6051 | Spec: 70.66% | Recall: 29.34% | G-Means: 45.53%\n",
            "Epoch  12 | Loss: 0.6012 | Spec: 80.43% | Recall: 18.41% | G-Means: 38.48%\n",
            "Epoch  13 | Loss: 0.5972 | Spec: 79.45% | Recall: 20.58% | G-Means: 40.44%\n",
            "Epoch  14 | Loss: 0.5942 | Spec: 82.50% | Recall: 18.35% | G-Means: 38.91%\n",
            "Epoch  15 | Loss: 0.5895 | Spec: 68.52% | Recall: 32.16% | G-Means: 46.94%\n",
            "Epoch  16 | Loss: 0.5903 | Spec: 74.72% | Recall: 27.39% | G-Means: 45.24%\n",
            "Epoch  17 | Loss: 0.5902 | Spec: 78.81% | Recall: 21.93% | G-Means: 41.57%\n",
            "Epoch  18 | Loss: 0.5877 | Spec: 76.61% | Recall: 24.59% | G-Means: 43.41%\n",
            "Epoch  19 | Loss: 0.5893 | Spec: 72.17% | Recall: 27.80% | G-Means: 44.79%\n",
            "Epoch  20 | Loss: 0.5864 | Spec: 82.47% | Recall: 20.39% | G-Means: 41.00%\n",
            "Epoch  21 | Loss: 0.5835 | Spec: 77.08% | Recall: 23.10% | G-Means: 42.20%\n",
            "Epoch  22 | Loss: 0.5836 | Spec: 79.37% | Recall: 20.39% | G-Means: 40.22%\n",
            "Epoch  23 | Loss: 0.5810 | Spec: 77.29% | Recall: 24.77% | G-Means: 43.75%\n",
            "Epoch  24 | Loss: 0.5794 | Spec: 75.32% | Recall: 26.05% | G-Means: 44.29%\n",
            "Epoch  25 | Loss: 0.5792 | Spec: 82.42% | Recall: 20.52% | G-Means: 41.12%\n",
            "Epoch  26 | Loss: 0.5803 | Spec: 79.47% | Recall: 23.40% | G-Means: 43.12%\n",
            "Epoch  27 | Loss: 0.5790 | Spec: 80.67% | Recall: 22.60% | G-Means: 42.70%\n",
            "Epoch  28 | Loss: 0.5771 | Spec: 80.90% | Recall: 21.60% | G-Means: 41.80%\n",
            "Epoch  29 | Loss: 0.5782 | Spec: 70.93% | Recall: 32.66% | G-Means: 48.13%\n",
            "Epoch  30 | Loss: 0.5778 | Spec: 69.68% | Recall: 31.14% | G-Means: 46.58%\n",
            "\n",
            "FULL RUN Complete. Best G-Means: 48.13%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from src.training.trainer import FraudTrainer\n",
        "from src.utils.config import load_model_config, load_data_config\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "model_cfg = load_model_config()\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. THE MAIN EVENT: 100% DATA\n",
        "# ==============================================================================\n",
        "SAMPLE_FRAC = 1.0\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. THE GOLD STANDARD CONFIGURATION\n",
        "# ==============================================================================\n",
        "model_cfg.training[\"max_epochs\"] = 30\n",
        "model_cfg.training[\"learning_rate\"] = 0.003\n",
        "model_cfg.rl_agent[\"reward_scaling\"] = 2.0\n",
        "\n",
        "# AGGRESSIVE CLEANING (Alpha 0.80)\n",
        "# Essential for the full dataset to keep the graph manageable\n",
        "model_cfg.adaptive_mcd[\"alpha\"] = 0.80\n",
        "\n",
        "# CONNECTIVITY (Threshold 0.75)\n",
        "# We need this slightly looser threshold so the RL Agent has paths to walk\n",
        "model_cfg.graph.similarity_threshold = 0.75\n",
        "\n",
        "# Initialize Trainer\n",
        "print(f\"ğŸš€ Initializing GOLD STANDARD RUN (RL=ON) on {SAMPLE_FRAC*100}% Data...\")\n",
        "trainer = FraudTrainer(\n",
        "    model_config=model_cfg,\n",
        "    data_config=data_cfg,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. FULL SCALE PREP (Expect ~15-20 mins)\n",
        "# ==============================================================================\n",
        "print(\"ğŸ“‰ Loading Full Dataset (590k nodes)...\")\n",
        "loader = FraudDataLoader(config=data_cfg)\n",
        "df_full = loader.load_train_data(sample_frac=SAMPLE_FRAC)\n",
        "train_df, val_df, test_df = loader.create_splits(df_full)\n",
        "\n",
        "print(\"âš™ï¸ Building Full Graph (Threshold 0.75)...\")\n",
        "trainer._preprocess(train_df, val_df, test_df)\n",
        "trainer._build_graph()\n",
        "trainer._prepare_labels(train_df, val_df, test_df)\n",
        "\n",
        "print(\"\\nğŸ§  Training AdaptiveMCD (Alpha=0.80)...\")\n",
        "trainer._train_mcd()\n",
        "\n",
        "# âœ… RL AGENT ENABLED\n",
        "print(\"\\nğŸ¤– Training RL Agent (Connecting the Dots)...\")\n",
        "trainer._train_rl_and_enhance()\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. WEIGHT 12.0\n",
        "# ==============================================================================\n",
        "# The \"Sweet Spot\". We don't need 22.0 because the RL Agent provides the lift.\n",
        "print(\"\\nâš–ï¸ Applying Sweet Spot Weight 12.0...\")\n",
        "weights = torch.tensor([1.0, 12.0]).to(device)\n",
        "\n",
        "trainer._init_model()\n",
        "trainer.criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "criterion = trainer.criterion\n",
        "model = trainer.model\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=0.003,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. FULL SCALE TRAINING\n",
        "# ==============================================================================\n",
        "print(\"\\nğŸ“¦ Setting up Loaders (Batch Size 4096)...\")\n",
        "optimized_data = Data(\n",
        "    x=trainer.X_full,\n",
        "    edge_index=trainer.edge_index,\n",
        "    y=trainer.all_labels\n",
        ")\n",
        "optimized_data.train_mask = trainer.train_mask\n",
        "optimized_data.val_mask = trainer.val_mask\n",
        "optimized_data.test_mask = trainer.test_mask\n",
        "\n",
        "train_loader = NeighborLoader(\n",
        "    optimized_data,\n",
        "    num_neighbors=[25, 10],\n",
        "    batch_size=4096,\n",
        "    input_nodes=optimized_data.train_mask,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = NeighborLoader(\n",
        "    optimized_data,\n",
        "    num_neighbors=[25, 10],\n",
        "    batch_size=4096,\n",
        "    input_nodes=optimized_data.val_mask,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"\\nğŸš€ Starting Full Data Training...\")\n",
        "best_gmeans = 0\n",
        "\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        loss = criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
        "\n",
        "        # Gradient Clipping\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        model.eval()\n",
        "        all_preds, all_true = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                out = model(batch.x, batch.edge_index)\n",
        "                pred = out[:batch.batch_size].argmax(dim=1)\n",
        "                all_preds.extend(pred.cpu().numpy())\n",
        "                all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "        cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        gmeans = np.sqrt(tpr * tnr)\n",
        "\n",
        "        print(f\"Epoch {epoch+1:>3} | Loss: {avg_loss:.4f} | Spec: {tnr*100:.2f}% | Recall: {tpr*100:.2f}% | G-Means: {gmeans*100:.2f}%\")\n",
        "\n",
        "        if gmeans > best_gmeans:\n",
        "            best_gmeans = gmeans\n",
        "            # Save as Final Model\n",
        "            torch.save(model.state_dict(), f\"{MODELS_DIR}/fraudguard_gold_standard.pt\")\n",
        "\n",
        "print(f\"\\nFULL RUN Complete. Best G-Means: {best_gmeans*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vanilla"
      ],
      "metadata": {
        "id": "FlJIp7ssCTap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from src.training.trainer import FraudTrainer\n",
        "from src.utils.config import load_model_config, load_data_config\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. SETUP VANILLA BASELINE (Control Group)\n",
        "# ==============================================================================\n",
        "# We disable the \"Secret Sauce\" to see how a standard model performs.\n",
        "model_cfg = load_model_config()\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# DISABLE INNOVATIONS\n",
        "model_cfg.adaptive_mcd[\"alpha\"] = 0.0    # Turn off MCD\n",
        "model_cfg.graph.similarity_threshold = 0.80 # Standard Strict Graph\n",
        "\n",
        "# Standard Training Params\n",
        "model_cfg.training[\"max_epochs\"] = 20    # Baseline converges fast\n",
        "model_cfg.training[\"learning_rate\"] = 0.005\n",
        "\n",
        "print(\"ğŸš€ Initializing VANILLA BASELINE (No MCD, No RL)...\")\n",
        "trainer = FraudTrainer(model_config=model_cfg, data_config=data_cfg, device=device)\n",
        "\n",
        "# Load 100% Data\n",
        "loader = FraudDataLoader(config=data_cfg)\n",
        "df_full = loader.load_train_data(sample_frac=1.0)\n",
        "train_df, val_df, test_df = loader.create_splits(df_full)\n",
        "\n",
        "# Preprocess\n",
        "trainer._preprocess(train_df, val_df, test_df)\n",
        "trainer._build_graph()\n",
        "trainer._prepare_labels(train_df, val_df, test_df)\n",
        "\n",
        "# ğŸš« SKIP MCD & RL (This is the control group)\n",
        "\n",
        "# Apply Weight 25.0 (To be fair, we give baseline the same weight help)\n",
        "weights = torch.tensor([1.0, 25.0]).to(device)\n",
        "trainer._init_model()\n",
        "trainer.criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "model = trainer.model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-4)\n",
        "\n",
        "# Loaders\n",
        "optimized_data = Data(x=trainer.X_full, edge_index=trainer.edge_index, y=trainer.all_labels)\n",
        "optimized_data.train_mask = trainer.train_mask; optimized_data.val_mask = trainer.val_mask\n",
        "train_loader = NeighborLoader(optimized_data, num_neighbors=[25, 10], batch_size=4096, input_nodes=optimized_data.train_mask, shuffle=True)\n",
        "val_loader = NeighborLoader(optimized_data, num_neighbors=[25, 10], batch_size=4096, input_nodes=optimized_data.val_mask, shuffle=False)\n",
        "\n",
        "print(f\"\\nğŸ“‰ Starting Baseline Training...\")\n",
        "best_gmeans_baseline = 0\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        loss = trainer.criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Eval every 2 epochs\n",
        "    if epoch % 2 == 0:\n",
        "        model.eval()\n",
        "        all_preds, all_true = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                out = model(batch.x, batch.edge_index)\n",
        "                pred = out[:batch.batch_size].argmax(dim=1)\n",
        "                all_preds.extend(pred.cpu().numpy())\n",
        "                all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "        cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        gmeans = np.sqrt(tpr * tnr)\n",
        "        print(f\"Baseline Epoch {epoch+1:>2} | Spec: {tnr*100:.2f}% | Recall: {tpr*100:.2f}% | G-Means: {gmeans*100:.2f}%\")\n",
        "\n",
        "        if gmeans > best_gmeans_baseline:\n",
        "            best_gmeans_baseline = gmeans\n",
        "            torch.save(model.state_dict(), f\"{MODELS_DIR}/fraudguard_baseline.pt\")\n",
        "\n",
        "print(f\"ğŸ Baseline Best G-Means: {best_gmeans_baseline*100:.2f}%\")\n",
        "\n",
        "# Cleanup for Next Run\n",
        "del model, trainer, optimized_data, train_loader, val_loader\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "asqbsXx6CSJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improved"
      ],
      "metadata": {
        "id": "3DD03jfpCVcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 2. SETUP AGGRESSIVE GOLD (The Innovation)\n",
        "# ==============================================================================\n",
        "model_cfg = load_model_config()\n",
        "\n",
        "# âœ… MY CHOSEN VALUES (The Logic-Based Selection)\n",
        "model_cfg.training[\"max_epochs\"] = 30\n",
        "model_cfg.training[\"learning_rate\"] = 0.003  # Stability for high weights\n",
        "model_cfg.rl_agent[\"reward_scaling\"] = 2.0\n",
        "model_cfg.adaptive_mcd[\"alpha\"] = 0.80       # Aggressive cleaning for full data noise\n",
        "model_cfg.graph.similarity_threshold = 0.75  # Connectivity for RL paths\n",
        "\n",
        "print(f\"\\nğŸš€ Initializing AGGRESSIVE GOLD RUN (RL=ON)...\")\n",
        "trainer = FraudTrainer(model_config=model_cfg, data_config=data_cfg, device=device)\n",
        "\n",
        "# Re-process (Fast because data is loaded)\n",
        "trainer._preprocess(train_df, val_df, test_df)\n",
        "trainer._build_graph()\n",
        "trainer._prepare_labels(train_df, val_df, test_df)\n",
        "\n",
        "print(\"\\nğŸ§  Training AdaptiveMCD (Alpha 0.80)...\")\n",
        "trainer._train_mcd()\n",
        "\n",
        "print(\"\\nğŸ¤– Training RL Agent (Connecting the dots)...\")\n",
        "trainer._train_rl_and_enhance()\n",
        "\n",
        "# ğŸ›¡ï¸ VRAM FLUSH\n",
        "print(\"\\nğŸ§¹ Flushing VRAM before GNN Training...\")\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Weight 25.0 (The Hammer)\n",
        "weights = torch.tensor([1.0, 25.0]).to(device)\n",
        "trainer._init_model()\n",
        "trainer.criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "model = trainer.model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003, weight_decay=1e-4)\n",
        "\n",
        "# Loaders (Batch 2048 for safety)\n",
        "optimized_data = Data(x=trainer.X_full, edge_index=trainer.edge_index, y=trainer.all_labels)\n",
        "optimized_data.train_mask = trainer.train_mask; optimized_data.val_mask = trainer.val_mask\n",
        "train_loader = NeighborLoader(optimized_data, num_neighbors=[25, 10], batch_size=2048, input_nodes=optimized_data.train_mask, shuffle=True)\n",
        "val_loader = NeighborLoader(optimized_data, num_neighbors=[25, 10], batch_size=2048, input_nodes=optimized_data.val_mask, shuffle=False)\n",
        "\n",
        "print(f\"\\nğŸš€ Starting Gold Standard Training...\")\n",
        "best_gmeans_gold = 0\n",
        "\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        loss = trainer.criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        model.eval()\n",
        "        all_preds, all_true = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                out = model(batch.x, batch.edge_index)\n",
        "                pred = out[:batch.batch_size].argmax(dim=1)\n",
        "                all_preds.extend(pred.cpu().numpy())\n",
        "                all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "        cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        gmeans = np.sqrt(tpr * tnr)\n",
        "\n",
        "        print(f\"Epoch {epoch+1:>3} | Spec: {tnr*100:.2f}% | Recall: {tpr*100:.2f}% | G-Means: {gmeans*100:.2f}%\")\n",
        "\n",
        "        if gmeans > best_gmeans_gold:\n",
        "            best_gmeans_gold = gmeans\n",
        "            torch.save(model.state_dict(), f\"{MODELS_DIR}/fraudguard_final_aggressive.pt\")\n",
        "\n",
        "# Calculate VRAM Savings\n",
        "peak_mem = torch.cuda.max_memory_allocated() / 1e9\n",
        "print(f\"\\nâœ… Peak VRAM Usage: {peak_mem:.2f} GB\")\n",
        "print(f\"ğŸ Final Best G-Means: {best_gmeans_gold*100:.2f}%\")"
      ],
      "metadata": {
        "id": "wtF-llRdCXKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn5d0-Qy-Xk_"
      },
      "source": [
        "## 6ï¸âƒ£ Evaluation & Claims Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKLZjQO0-Xk_",
        "outputId": "b501b6f1-b78f-4fa1-ba37-b027e5da045a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Benchmarking & Evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/neighbor_loader.py:229: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  neighbor_sampler = NeighborSampler(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "FINAL RESULTS (Pro Framework)\n",
            "============================================================\n",
            "Specificity: 63.24%\n",
            "Recall:      34.47%\n",
            "G-Means:     46.69%\n",
            "P95 Latency: 45.51 ms\n"
          ]
        }
      ],
      "source": [
        "# Safe Evaluation (Mini-Batch)\n",
        "print(\"ğŸ” Benchmarking & Evaluation...\")\n",
        "model.load_state_dict(torch.load(f\"{MODELS_DIR}/fraudguard_best_pro.pt\"))\n",
        "model.eval()\n",
        "\n",
        "# Use neighbors=[25, 10] for fast inference (Latency < 10ms)\n",
        "test_loader = NeighborLoader(\n",
        "    optimized_data,\n",
        "    num_neighbors=[25, 10],\n",
        "    batch_size=4096,\n",
        "    input_nodes=optimized_data.test_mask,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "latencies = []\n",
        "all_preds, all_true = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        start = time.perf_counter()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        latencies.append((time.perf_counter() - start) * 1000)\n",
        "        pred = out[:batch.batch_size].argmax(dim=1)\n",
        "        all_preds.extend(pred.cpu().numpy())\n",
        "        all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "# Metrics\n",
        "cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "gmeans = np.sqrt(tpr * tnr)\n",
        "p95_latency = np.percentile(latencies, 95)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"FINAL RESULTS (Pro Framework)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Specificity: {tnr*100:.2f}%\")\n",
        "print(f\"Recall:      {tpr*100:.2f}%\")\n",
        "print(f\"G-Means:     {gmeans*100:.2f}%\")\n",
        "print(f\"P95 Latency: {p95_latency:.2f} ms\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ğŸ” Benchmarking Gold Standard Model on 100% Test Data...\")\n",
        "\n",
        "# Load Final Model\n",
        "model.load_state_dict(torch.load(f\"{MODELS_DIR}/fraudguard_gold_standard.pt\"))\n",
        "model.eval()\n",
        "\n",
        "# Full Test Loader\n",
        "test_loader = NeighborLoader(\n",
        "    optimized_data,\n",
        "    num_neighbors=[25, 10],\n",
        "    batch_size=4096,\n",
        "    input_nodes=optimized_data.test_mask,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "latencies = []\n",
        "all_preds, all_true = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        start = time.perf_counter()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        latencies.append((time.perf_counter() - start) * 1000)\n",
        "\n",
        "        pred = out[:batch.batch_size].argmax(dim=1)\n",
        "        all_preds.extend(pred.cpu().numpy())\n",
        "        all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "gmeans = np.sqrt(tpr * tnr)\n",
        "p95_latency = np.percentile(latencies, 95)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"FINAL GOLD STANDARD RESULTS (100% Data, RL=ON)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Confusion Matrix: TP={tp}, TN={tn}, FP={fp}, FN={fn}\")\n",
        "print(f\"Specificity: {tnr*100:.2f}%\")\n",
        "print(f\"Recall:      {tpr*100:.2f}%\")\n",
        "print(f\"G-Means:     {gmeans*100:.2f}%\")\n",
        "print(f\"P95 Latency: {p95_latency:.2f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yGXo390EaEj",
        "outputId": "d765c7e9-bc16-4cdf-823a-fe7635bb3685"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Benchmarking Gold Standard Model on 100% Test Data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/neighbor_loader.py:229: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  neighbor_sampler = NeighborSampler(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "FINAL GOLD STANDARD RESULTS (100% Data, RL=ON)\n",
            "============================================================\n",
            "Confusion Matrix: TP=1279, TN=80397, FP=33647, FN=2785\n",
            "Specificity: 70.50%\n",
            "Recall:      31.47%\n",
            "G-Means:     47.10%\n",
            "P95 Latency: 45.49 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. FINAL A/B TEST REPORT\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ¯ FINAL ARCHITECTURAL COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Baseline G-Means (No RL/MCD): {best_gmeans_baseline*100:.2f}%\")\n",
        "print(f\"System   G-Means (AD-RL-GNN): {best_gmeans_gold*100:.2f}%\")\n",
        "\n",
        "improvement = best_gmeans_gold - best_gmeans_baseline\n",
        "pct_improvement = (improvement / best_gmeans_baseline) * 100\n",
        "\n",
        "print(f\"------------------------------------------------------------\")\n",
        "print(f\"ğŸš€ ABSOLUTE IMPROVEMENT: +{improvement*100:.2f}% points\")\n",
        "print(f\"ğŸš€ RELATIVE IMPROVEMENT: +{pct_improvement:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "gbKY7RUuCasb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqoG6I7W-Xk_"
      },
      "source": [
        "## 7ï¸âƒ£ Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joYoeD60-XlA",
        "outputId": "87224868-4607-41a9-9e7f-8118f16e0d94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/fraudguard-models/fraudguard_full_pipeline.pt\n"
          ]
        }
      ],
      "source": [
        "trainer.save(f\"{MODELS_DIR}/fraudguard_full_pipeline.pt\")\n",
        "print(f\"Model saved to {MODELS_DIR}/fraudguard_full_pipeline.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "lqRrjwfIVP6x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}