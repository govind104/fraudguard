{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsjoNAnuj7ws"
      },
      "source": [
        "# ğŸ”’ FraudGuard Training Notebook\n",
        "\n",
        "**AD-RL-GNN Fraud Detection** | Full training pipeline with mini-batch processing\n",
        "\n",
        "This notebook trains the FraudGuard model on the IEEE-CIS fraud detection dataset using:\n",
        "- **NeighborLoader** for memory-efficient mini-batch training\n",
        "- **FAISS** for similarity graph construction (GPU if available, CPU fallback)\n",
        "- **FocalLoss** for class-imbalanced learning\n",
        "\n",
        "**Target Metrics:**\n",
        "- Specificity: 98.72%\n",
        "- G-Means Improvement: 18.11%\n",
        "- P95 Latency: <100ms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJcMLlwrj7wu"
      },
      "source": [
        "## 1ï¸âƒ£ Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQkR0H15j7wv",
        "outputId": "3b20d122-b04e-4534-8911-7859ce2b4b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for data storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FiJD_x_j7ww",
        "outputId": "7eca906f-c50b-41a5-c940-ae77f3ef42a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fraudguard'...\n",
            "remote: Enumerating objects: 162, done.\u001b[K\n",
            "remote: Counting objects: 100% (162/162), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 162 (delta 62), reused 135 (delta 49), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (162/162), 117.11 KiB | 1.67 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "/content/fraudguard\n"
          ]
        }
      ],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/govind104/fraudguard.git\n",
        "%cd fraudguard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vsh_FW9lj7wx",
        "outputId": "17aeaa8c-4978-4548-b341-601ac5cf940a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâš ï¸ faiss-gpu not available, using faiss-cpu\n",
            "   (Graph building on CPU, but GNN training still runs on GPU!)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPyTorch: 2.9.0, CUDA: cu126\n",
            "Downloading from: https://data.pyg.org/whl/torch-2.9.0+cu126.html\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.9.0+cu126.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy (from torch-sparse)\n",
            "  Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<2.7,>=1.26.4 (from scipy->torch-sparse)\n",
            "  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-scatter, torch-sparse\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp312-cp312-linux_x86_64.whl size=3857032 sha256=0db14c693ec059d0a45998295edade7710abd61de43d5c62f89f7253e49c1e51\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/20/50/44800723f57cd798630e77b3ec83bc80bd26a1e3dc3a672ef5\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp312-cp312-linux_x86_64.whl size=3039802 sha256=1acb45ad05199395cff7cf85eead900bc8f5b3f5ddd81f399905924a9023da31\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/fa/21/bd1d78ce1629aec4ecc924a63b82f6949dda484b6321eac6f2\n",
            "Successfully built torch-scatter torch-sparse\n",
            "Installing collected packages: torch-scatter, numpy, scipy, torch-sparse\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.4.1 scipy-1.17.0 torch-scatter-2.1.2 torch-sparse-0.6.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "925fbc134953456e89b542af96f292d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fraudguard\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: faiss-cpu<2.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (1.13.2)\n",
            "Collecting numpy<2.0.0,>=1.24.0 (from fraudguard==0.1.0)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (1.6.1)\n",
            "Collecting structlog<24.0.0,>=23.1.0 (from fraudguard==0.1.0)\n",
            "  Downloading structlog-23.3.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: torch-geometric<3.0.0,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.7.0)\n",
            "Requirement already satisfied: torch-scatter<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.1.2)\n",
            "Requirement already satisfied: torch-sparse<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (0.6.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu<2.0.0,>=1.7.4->fraudguard==0.1.0) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0.0,>=1.3.0->fraudguard==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0.0,>=1.3.0->fraudguard==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0.0,>=1.3.0->fraudguard==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.13.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (2026.1.4)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading structlog-23.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fraudguard\n",
            "  Building editable for fraudguard (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fraudguard: filename=fraudguard-0.1.0-py3-none-any.whl size=2801 sha256=5638c0b714acd4b297203f70f102910966a1da4432de3a3f589a22ae37244e19\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-borqex6g/wheels/c6/29/62/fb6d8d095576e7e3efddf4fdcb7dfc799af71ace273f1ee84c\n",
            "Successfully built fraudguard\n",
            "Installing collected packages: structlog, numpy, fraudguard\n",
            "  Attempting uninstall: structlog\n",
            "    Found existing installation: structlog 25.5.0\n",
            "    Uninstalling structlog-25.5.0:\n",
            "      Successfully uninstalled structlog-25.5.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.4.1\n",
            "    Uninstalling numpy-2.4.1:\n",
            "      Successfully uninstalled numpy-2.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fraudguard-0.1.0 numpy-1.26.4 structlog-23.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "4a211e37c1664a58a938b710193b1f9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ“ Environment setup complete\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "# Note: faiss-gpu may not be available on Python 3.12\n",
        "# The code will fallback to faiss-cpu automatically\n",
        "# GNN training STILL runs on GPU - only graph building uses CPU FAISS\n",
        "!pip install -q torch torch-geometric pandas numpy scikit-learn pyyaml structlog\n",
        "\n",
        "# Try faiss-gpu first, fallback to faiss-cpu\n",
        "import subprocess\n",
        "result = subprocess.run(['pip', 'install', '-q', 'faiss-gpu'], capture_output=True)\n",
        "if result.returncode != 0:\n",
        "    print('âš ï¸ faiss-gpu not available, using faiss-cpu')\n",
        "    print('   (Graph building on CPU, but GNN training still runs on GPU!)')\n",
        "    !pip install -q faiss-cpu\n",
        "else:\n",
        "    print('âœ“ faiss-gpu installed')\n",
        "\n",
        "import torch\n",
        "\n",
        "# 1. Get exact versions\n",
        "pt_version = torch.__version__.split('+')[0]  # e.g., 2.5.1\n",
        "cuda_version = \"cu\" + torch.version.cuda.replace('.', '')  # e.g., cu124\n",
        "wheel_url = f\"https://data.pyg.org/whl/torch-{pt_version}+{cuda_version}.html\"\n",
        "\n",
        "print(f\"PyTorch: {pt_version}, CUDA: {cuda_version}\")\n",
        "print(f\"Downloading from: {wheel_url}\")\n",
        "\n",
        "# 2. Install with visible output (force reinstall to fix broken partial installs)\n",
        "!pip install --force-reinstall torch-scatter torch-sparse -f $wheel_url\n",
        "\n",
        "# Install repo in editable mode\n",
        "!pip install -e .\n",
        "\n",
        "print('\\nâœ“ Environment setup complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32LXcfp8_bZ8",
        "outputId": "aa318e1b-b2be-4995-acf7-f2ab2a8135ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Success! Libraries are installed and loaded.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "try:\n",
        "    import torch_scatter\n",
        "    import torch_sparse\n",
        "    import fraudguard\n",
        "    print(\"âœ… Success! Libraries are installed and loaded.\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Still missing libraries: {e}\")\n",
        "    # Only if you see this error should you go back and install again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQIB4vEej7wx"
      },
      "source": [
        "## 2ï¸âƒ£ Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQDtmVWBj7wy",
        "outputId": "681f341a-db3f-42d7-c31f-4598169b1408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: /content/drive/MyDrive/ieee-fraud-detection\n",
            "Models: /content/drive/MyDrive/fraudguard-models\n",
            "Logs: /content/drive/MyDrive/fraudguard-logs\n",
            "\n",
            "Batch size: 4096\n",
            "Sample fraction: 100%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Data paths - Point to your Google Drive folders\n",
        "DATA_DIR = \"/content/drive/MyDrive/ieee-fraud-detection\"\n",
        "MODELS_DIR = \"/content/drive/MyDrive/fraudguard-models\"\n",
        "LOGS_DIR = \"/content/drive/MyDrive/fraudguard-logs\"\n",
        "\n",
        "# Training parameters\n",
        "SAMPLE_FRAC = 1.0      # Use full dataset (1.0 = 100%)\n",
        "MAX_EPOCHS = 30\n",
        "BATCH_SIZE = 4096      # Reduce to 2048 or 1024 if OOM\n",
        "NUM_NEIGHBORS = [25, 10]  # 2-hop neighborhood sampling\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(LOGS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Data: {DATA_DIR}\")\n",
        "print(f\"Models: {MODELS_DIR}\")\n",
        "print(f\"Logs: {LOGS_DIR}\")\n",
        "print(f\"\\nBatch size: {BATCH_SIZE}\")\n",
        "print(f\"Sample fraction: {SAMPLE_FRAC*100:.0f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM3sXum3j7wz"
      },
      "source": [
        "## 3ï¸âƒ£ Verify GPU and FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7CHUJ3nj7wz",
        "outputId": "96540330-b29b-47b7-a93f-0dbd5f863591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "VRAM: 15.8 GB\n",
            "\n",
            "âœ“ GNN training will run on GPU\n",
            "\n",
            "FAISS GPUs: 0\n",
            "   (Using CPU FAISS for graph building - this is OK)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import faiss\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(\"\\nâœ“ GNN training will run on GPU\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ WARNING: No GPU detected. Go to Runtime > Change runtime type > GPU\")\n",
        "\n",
        "# Check FAISS GPU\n",
        "faiss_gpus = faiss.get_num_gpus() if hasattr(faiss, 'get_num_gpus') else 0\n",
        "print(f\"\\nFAISS GPUs: {faiss_gpus}\")\n",
        "if faiss_gpus == 0:\n",
        "    print(\"   (Using CPU FAISS for graph building - this is OK)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmk_r0omj7w0"
      },
      "source": [
        "## 4ï¸âƒ£ Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVU_fGbPj7w0",
        "outputId": "82e2c202-4605-4e34-8521-f83cbfdc652e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Data loaded:\n",
            "  Train: 354,324\n",
            "  Val: 118,108\n",
            "  Test: 118,108\n",
            "  Fraud rate: 3.50%\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/fraudguard')\n",
        "\n",
        "from pathlib import Path\n",
        "from src.data.loader import FraudDataLoader\n",
        "from src.data.preprocessor import FeaturePreprocessor\n",
        "from src.data.graph_builder import GraphBuilder\n",
        "from src.utils.config import load_data_config\n",
        "from src.utils.device_utils import set_seed, get_device\n",
        "\n",
        "set_seed(42)\n",
        "device = get_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load config and override path with notebook variable\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# Load data with corrected path\n",
        "loader = FraudDataLoader(config=data_cfg)\n",
        "df = loader.load_train_data(sample_frac=SAMPLE_FRAC)\n",
        "train_df, val_df, test_df = loader.create_splits(df)\n",
        "\n",
        "print(f\"\\nData loaded:\")\n",
        "print(f\"  Train: {len(train_df):,}\")\n",
        "print(f\"  Val: {len(val_df):,}\")\n",
        "print(f\"  Test: {len(test_df):,}\")\n",
        "print(f\"  Fraud rate: {df['isFraud'].mean()*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV4Kblyi-Xk_"
      },
      "source": [
        "## 5ï¸âƒ£ Run Full AD-RL-GNN Pipeline\n",
        "\n",
        "We use the `FraudTrainer` class to orchestrate the full pipeline, including:\n",
        "1. **AdaptiveMCD**: Intelligent majority downsampling\n",
        "2. **RL Agent**: Dynamic subgraph selection (Random Walk, K-Hop, K-Ego)\n",
        "3. **Graph Enhancement**: Adding semantic edges\n",
        "4. **GNN Training**: CrossEntropyLoss (15x weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vanilla Baseline GNN"
      ],
      "metadata": {
        "id": "FlJIp7ssCTap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from src.training.trainer import FraudTrainer\n",
        "from src.utils.config import load_model_config, load_data_config\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "model_cfg = load_model_config()\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "\n",
        "# Aligned Hyperparameters (Strict Ceteris Paribus)\n",
        "model_cfg.training[\"max_epochs\"] = 30\n",
        "model_cfg.training[\"learning_rate\"] = 0.003\n",
        "model_cfg.adaptive_mcd[\"alpha\"] = 0.0        # No MCD\n",
        "model_cfg.graph.similarity_threshold = 0.75\n",
        "\n",
        "print(\"Initializing Vanilla Baseline (No MCD, No RL)...\")\n",
        "trainer = FraudTrainer(model_config=model_cfg, data_config=data_cfg, device=device)\n",
        "\n",
        "# Load 100% Data\n",
        "loader = FraudDataLoader(config=data_cfg)\n",
        "df_full = loader.load_train_data(sample_frac=SAMPLE_FRAC)\n",
        "train_df, val_df, test_df = loader.create_splits(df_full)\n",
        "\n",
        "# Preprocess\n",
        "trainer._preprocess(train_df, val_df, test_df)\n",
        "trainer._build_graph()\n",
        "trainer._prepare_labels(train_df, val_df, test_df)\n",
        "\n",
        "# Reset VRAM Monitor\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "# Apply Weight 25.0\n",
        "weights = torch.tensor([1.0, 25.0]).to(device)\n",
        "trainer._init_model()\n",
        "trainer.criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "model = trainer.model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003, weight_decay=1e-4)\n",
        "\n",
        "# Loaders (Batch 2048)\n",
        "optimized_data = Data(x=trainer.X_full, edge_index=trainer.edge_index, y=trainer.all_labels)\n",
        "optimized_data.train_mask = trainer.train_mask; optimized_data.val_mask = trainer.val_mask\n",
        "train_loader = NeighborLoader(optimized_data, num_neighbors=[25, 10], batch_size=2048, input_nodes=optimized_data.train_mask, shuffle=True)\n",
        "val_loader = NeighborLoader(optimized_data, num_neighbors=[25, 10], batch_size=2048, input_nodes=optimized_data.val_mask, shuffle=False)\n",
        "\n",
        "print(f\"\\n Starting Baseline Training (30 Epochs)...\")\n",
        "best_gmeans_baseline = 0\n",
        "\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        loss = trainer.criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
        "\n",
        "        # Gradient clipping\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "    # Eval every 1 epoch\n",
        "    if epoch % 1 == 0:\n",
        "        model.eval()\n",
        "        all_preds, all_true = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                out = model(batch.x, batch.edge_index)\n",
        "                pred = out[:batch.batch_size].argmax(dim=1)\n",
        "                all_preds.extend(pred.cpu().numpy())\n",
        "                all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "        cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        gmeans = np.sqrt(tpr * tnr)\n",
        "        print(f\"Baseline Epoch {epoch+1:>2} | Spec: {tnr*100:.2f}% | Recall: {tpr*100:.2f}% | G-Means: {gmeans*100:.2f}%\")\n",
        "\n",
        "        if gmeans > best_gmeans_baseline:\n",
        "            best_gmeans_baseline = gmeans\n",
        "            torch.save(model.state_dict(), f\"{MODELS_DIR}/fraudguard_baseline.pt\")\n",
        "\n",
        "# Capture Baseline Metrics\n",
        "baseline_vram = torch.cuda.max_memory_allocated() / 1e9\n",
        "\n",
        "model.load_state_dict(torch.load(f\"{MODELS_DIR}/fraudguard_baseline.pt\"))\n",
        "model.eval()\n",
        "latencies_baseline = []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        start = time.perf_counter()\n",
        "        _ = model(batch.x, batch.edge_index)\n",
        "        latencies_baseline.append((time.perf_counter() - start) * 1000)\n",
        "\n",
        "baseline_p95 = np.percentile(latencies_baseline, 95)\n",
        "\n",
        "print(f\"\\n Baseline VRAM: {baseline_vram:.2f} GB\")\n",
        "print(f\" Baseline P95 Latency: {baseline_p95:.2f} ms\")\n",
        "print(f\" Baseline Best G-Means: {best_gmeans_baseline*100:.2f}%\")\n",
        "\n",
        "# Clean up\n",
        "del model, trainer, optimized_data, train_loader, val_loader\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "asqbsXx6CSJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c90846e4-275f-43f0-f4cf-fb328dd9b5ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Initializing VANILLA BASELINE (No MCD, No RL)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/neighbor_loader.py:229: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  neighbor_sampler = NeighborSampler(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“‰ Starting Baseline Training (30 Epochs, Aligned)...\n",
            "Baseline Epoch  1 | Spec: 85.07% | Recall: 16.31% | G-Means: 37.25%\n",
            "Baseline Epoch  2 | Spec: 94.45% | Recall: 8.05% | G-Means: 27.57%\n",
            "Baseline Epoch  3 | Spec: 95.49% | Recall: 6.64% | G-Means: 25.17%\n",
            "Baseline Epoch  4 | Spec: 92.09% | Recall: 11.52% | G-Means: 32.57%\n",
            "Baseline Epoch  5 | Spec: 89.78% | Recall: 14.99% | G-Means: 36.68%\n",
            "Baseline Epoch  6 | Spec: 76.97% | Recall: 27.50% | G-Means: 46.01%\n",
            "Baseline Epoch  7 | Spec: 91.98% | Recall: 12.06% | G-Means: 33.30%\n",
            "Baseline Epoch  8 | Spec: 80.81% | Recall: 25.57% | G-Means: 45.46%\n",
            "Baseline Epoch  9 | Spec: 85.23% | Recall: 20.78% | G-Means: 42.08%\n",
            "Baseline Epoch 10 | Spec: 85.96% | Recall: 19.95% | G-Means: 41.41%\n",
            "Baseline Epoch 11 | Spec: 94.62% | Recall: 10.30% | G-Means: 31.22%\n",
            "Baseline Epoch 12 | Spec: 88.61% | Recall: 17.52% | G-Means: 39.41%\n",
            "Baseline Epoch 13 | Spec: 93.70% | Recall: 11.26% | G-Means: 32.48%\n",
            "Baseline Epoch 14 | Spec: 93.58% | Recall: 11.58% | G-Means: 32.92%\n",
            "Baseline Epoch 15 | Spec: 88.03% | Recall: 19.32% | G-Means: 41.24%\n",
            "Baseline Epoch 16 | Spec: 86.58% | Recall: 20.34% | G-Means: 41.97%\n",
            "Baseline Epoch 17 | Spec: 91.54% | Recall: 14.64% | G-Means: 36.61%\n",
            "Baseline Epoch 18 | Spec: 86.47% | Recall: 20.93% | G-Means: 42.54%\n",
            "Baseline Epoch 19 | Spec: 90.14% | Recall: 16.83% | G-Means: 38.95%\n",
            "Baseline Epoch 20 | Spec: 89.59% | Recall: 17.89% | G-Means: 40.04%\n",
            "Baseline Epoch 21 | Spec: 89.63% | Recall: 17.50% | G-Means: 39.61%\n",
            "Baseline Epoch 22 | Spec: 89.18% | Recall: 18.04% | G-Means: 40.11%\n",
            "Baseline Epoch 23 | Spec: 91.51% | Recall: 14.90% | G-Means: 36.93%\n",
            "Baseline Epoch 24 | Spec: 90.96% | Recall: 16.33% | G-Means: 38.54%\n",
            "Baseline Epoch 25 | Spec: 86.55% | Recall: 20.65% | G-Means: 42.27%\n",
            "Baseline Epoch 26 | Spec: 90.72% | Recall: 15.66% | G-Means: 37.69%\n",
            "Baseline Epoch 27 | Spec: 83.14% | Recall: 25.01% | G-Means: 45.59%\n",
            "Baseline Epoch 28 | Spec: 85.73% | Recall: 22.51% | G-Means: 43.93%\n",
            "Baseline Epoch 29 | Spec: 81.79% | Recall: 27.26% | G-Means: 47.22%\n",
            "Baseline Epoch 30 | Spec: 86.63% | Recall: 21.49% | G-Means: 43.15%\n",
            "\n",
            "âœ… Baseline VRAM: 3.95 GB\n",
            "âœ… Baseline P95 Latency: 26.62 ms\n",
            "ğŸ Baseline Best G-Means: 47.22%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improved AD-RL-GNN"
      ],
      "metadata": {
        "id": "3DD03jfpCVcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cfg = load_model_config()\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# Aligned Hyperparameters (Strict Ceteris Paribus)\n",
        "model_cfg.training[\"max_epochs\"] = 30\n",
        "model_cfg.training[\"learning_rate\"] = 0.003\n",
        "model_cfg.rl_agent[\"reward_scaling\"] = 2.0\n",
        "model_cfg.adaptive_mcd[\"alpha\"] = 0.80       # Aggressive cleaning\n",
        "model_cfg.graph.similarity_threshold = 0.75\n",
        "\n",
        "print(f\"\\n Initializing AD-RL (MCD=ON, RL=ON)...\")\n",
        "trainer = FraudTrainer(model_config=model_cfg, data_config=data_cfg, device=device)\n",
        "\n",
        "# Reset Stats\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "# Re-process\n",
        "trainer._preprocess(train_df, val_df, test_df)\n",
        "trainer._build_graph()\n",
        "trainer._prepare_labels(train_df, val_df, test_df)\n",
        "\n",
        "print(\"\\n Training AdaptiveMCD (Alpha 0.80)...\")\n",
        "trainer._train_mcd()\n",
        "\n",
        "print(\"\\n Training RL Agent...\")\n",
        "trainer._train_rl_and_enhance()\n",
        "\n",
        "# VRAM Flush\n",
        "print(\"\\nğŸ§¹ Flushing VRAM before GNN Training...\")\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Weight 25.0\n",
        "weights = torch.tensor([1.0, 25.0]).to(device)\n",
        "trainer._init_model()\n",
        "trainer.criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "model = trainer.model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003, weight_decay=1e-4)\n",
        "\n",
        "# Loaders (Batch 2048)\n",
        "optimized_data = Data(x=trainer.X_full, edge_index=trainer.edge_index, y=trainer.all_labels)\n",
        "optimized_data.train_mask = trainer.train_mask; optimized_data.val_mask = trainer.val_mask\n",
        "train_loader = NeighborLoader(optimized_data, num_neighbors=[25, 10], batch_size=2048, input_nodes=optimized_data.train_mask, shuffle=True)\n",
        "val_loader = NeighborLoader(optimized_data, num_neighbors=[25, 10], batch_size=2048, input_nodes=optimized_data.val_mask, shuffle=False)\n",
        "\n",
        "print(f\"\\n Starting AD-RL Training (30 Epochs)...\")\n",
        "best_gmeans_gold = 0\n",
        "\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        loss = trainer.criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
        "\n",
        "        # Gradient clipping\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "    # Eval every 1 epoch\n",
        "    if epoch % 1 == 0:\n",
        "        model.eval()\n",
        "        all_preds, all_true = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                out = model(batch.x, batch.edge_index)\n",
        "                pred = out[:batch.batch_size].argmax(dim=1)\n",
        "                all_preds.extend(pred.cpu().numpy())\n",
        "                all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "        cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        gmeans = np.sqrt(tpr * tnr)\n",
        "        print(f\"Epoch {epoch+1:>3} | Spec: {tnr*100:.2f}% | Recall: {tpr*100:.2f}% | G-Means: {gmeans*100:.2f}%\")\n",
        "\n",
        "        if gmeans > best_gmeans_gold:\n",
        "            best_gmeans_gold = gmeans\n",
        "            torch.save(model.state_dict(), f\"{MODELS_DIR}/fraudguard_final_aggressive.pt\")\n",
        "\n",
        "# Capture AD-RL Metrics\n",
        "gold_vram = torch.cuda.max_memory_allocated() / 1e9\n",
        "\n",
        "model.load_state_dict(torch.load(f\"{MODELS_DIR}/fraudguard_final_aggressive.pt\"))\n",
        "model.eval()\n",
        "latencies_gold = []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        start = time.perf_counter()\n",
        "        _ = model(batch.x, batch.edge_index)\n",
        "        latencies_gold.append((time.perf_counter() - start) * 1000)\n",
        "\n",
        "gold_p95 = np.percentile(latencies_gold, 95)\n",
        "\n",
        "print(f\"\\nâœ… Gold VRAM: {gold_vram:.2f} GB\")\n",
        "print(f\"âœ… Gold P95 Latency: {gold_p95:.2f} ms\")\n",
        "print(f\"ğŸ Final Best G-Means: {best_gmeans_gold*100:.2f}%\")\n",
        "\n",
        "# Clean up\n",
        "del model, trainer, optimized_data, train_loader, val_loader\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "wtF-llRdCXKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc5aa88-a433-4d40-83d0-ef7f4ccc8ba3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸš€ Initializing AGGRESSIVE GOLD RUN (RL=ON)...\n",
            "\n",
            "ğŸ§  Training AdaptiveMCD (Alpha 0.80)...\n",
            "\n",
            "ğŸ¤– Training RL Agent...\n",
            "\n",
            "ğŸ§¹ Flushing VRAM before GNN Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/neighbor_loader.py:229: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  neighbor_sampler = NeighborSampler(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸš€ Starting Gold Standard Training (30 Epochs)...\n",
            "Epoch   1 | Spec: 28.01% | Recall: 74.58% | G-Means: 45.71%\n",
            "Epoch   2 | Spec: 13.55% | Recall: 88.90% | G-Means: 34.70%\n",
            "Epoch   3 | Spec: 29.52% | Recall: 75.86% | G-Means: 47.32%\n",
            "Epoch   4 | Spec: 28.00% | Recall: 78.83% | G-Means: 46.98%\n",
            "Epoch   5 | Spec: 24.96% | Recall: 81.11% | G-Means: 45.00%\n",
            "Epoch   6 | Spec: 29.47% | Recall: 78.12% | G-Means: 47.98%\n",
            "Epoch   7 | Spec: 37.43% | Recall: 70.14% | G-Means: 51.23%\n",
            "Epoch   8 | Spec: 47.85% | Recall: 61.68% | G-Means: 54.33%\n",
            "Epoch   9 | Spec: 44.87% | Recall: 63.09% | G-Means: 53.20%\n",
            "Epoch  10 | Spec: 43.56% | Recall: 67.47% | G-Means: 54.21%\n",
            "Epoch  11 | Spec: 52.83% | Recall: 56.97% | G-Means: 54.86%\n",
            "Epoch  12 | Spec: 54.29% | Recall: 54.63% | G-Means: 54.46%\n",
            "Epoch  13 | Spec: 47.20% | Recall: 63.78% | G-Means: 54.87%\n",
            "Epoch  14 | Spec: 45.19% | Recall: 65.86% | G-Means: 54.55%\n",
            "Epoch  15 | Spec: 64.64% | Recall: 47.73% | G-Means: 55.55%\n",
            "Epoch  16 | Spec: 55.04% | Recall: 54.80% | G-Means: 54.92%\n",
            "Epoch  17 | Spec: 40.77% | Recall: 67.23% | G-Means: 52.36%\n",
            "Epoch  18 | Spec: 48.91% | Recall: 61.96% | G-Means: 55.05%\n",
            "Epoch  19 | Spec: 44.14% | Recall: 64.30% | G-Means: 53.27%\n",
            "Epoch  20 | Spec: 38.71% | Recall: 68.79% | G-Means: 51.60%\n",
            "Epoch  21 | Spec: 37.78% | Recall: 69.88% | G-Means: 51.38%\n",
            "Epoch  22 | Spec: 57.72% | Recall: 51.79% | G-Means: 54.67%\n",
            "Epoch  23 | Spec: 45.47% | Recall: 65.17% | G-Means: 54.44%\n",
            "Epoch  24 | Spec: 43.11% | Recall: 67.69% | G-Means: 54.02%\n",
            "Epoch  25 | Spec: 57.19% | Recall: 53.22% | G-Means: 55.17%\n",
            "Epoch  26 | Spec: 61.70% | Recall: 52.05% | G-Means: 56.67%\n",
            "Epoch  27 | Spec: 47.88% | Recall: 63.04% | G-Means: 54.94%\n",
            "Epoch  28 | Spec: 63.21% | Recall: 50.55% | G-Means: 56.53%\n",
            "Epoch  29 | Spec: 59.83% | Recall: 54.76% | G-Means: 57.24%\n",
            "Epoch  30 | Spec: 41.02% | Recall: 68.42% | G-Means: 52.98%\n",
            "\n",
            "âœ… Gold VRAM: 11.40 GB\n",
            "âœ… Gold P95 Latency: 27.55 ms\n",
            "ğŸ Final Best G-Means: 57.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn5d0-Qy-Xk_"
      },
      "source": [
        "## 6ï¸âƒ£ Evaluation & Claims Verification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 3. FINAL A/B TEST REPORT\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ¯ FINAL ARCHITECTURAL COMPARISON (Scientifically Aligned)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"| Metric      | Baseline | Optimized | Improvement |\")\n",
        "print(f\"|-------------|----------|-----------|-------------|\")\n",
        "print(f\"| G-Means     | {best_gmeans_baseline*100:.1f}%    | {best_gmeans_gold*100:.1f}%     | +{((best_gmeans_gold-best_gmeans_baseline)/best_gmeans_baseline)*100:.1f}%        |\")\n",
        "print(f\"| P95 Latency | {baseline_p95:.1f} ms  | {gold_p95:.1f} ms   | {((baseline_p95-gold_p95)/baseline_p95)*100:.1f}%         |\")\n",
        "print(f\"| Peak VRAM   | {baseline_vram:.1f} GB   | {gold_vram:.1f} GB    | {((baseline_vram-gold_vram)/baseline_vram)*100:.1f}%         |\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "QomZFRRzkaw2",
        "outputId": "7dd62382-3fa6-4b72-cf80-1775cc676fc2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ¯ FINAL ARCHITECTURAL COMPARISON (Scientifically Aligned)\n",
            "============================================================\n",
            "| Metric      | Baseline | Optimized | Improvement |\n",
            "|-------------|----------|-----------|-------------|\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'best_gmeans_baseline' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-370823007.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"| Metric      | Baseline | Optimized | Improvement |\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"|-------------|----------|-----------|-------------|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"| G-Means     | {best_gmeans_baseline*100:.1f}%    | {best_gmeans_gold*100:.1f}%     | +{((best_gmeans_gold-best_gmeans_baseline)/best_gmeans_baseline)*100:.1f}%        |\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"| P95 Latency | {baseline_p95:.1f} ms  | {gold_p95:.1f} ms   | {((baseline_p95-gold_p95)/baseline_p95)*100:.1f}%         |\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"| Peak VRAM   | {baseline_vram:.1f} GB   | {gold_vram:.1f} GB    | {((baseline_vram-gold_vram)/baseline_vram)*100:.1f}%         |\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_gmeans_baseline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqoG6I7W-Xk_"
      },
      "source": [
        "## 7ï¸âƒ£ Save Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save(f\"{MODELS_DIR}/fraudguard_full_pipeline.pt\")\n",
        "print(f\"Model saved to {MODELS_DIR}/fraudguard_full_pipeline.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "oTJKMfd3kcnj",
        "outputId": "ac29306f-8eac-44eb-fe88-67236162976c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1143096707.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{MODELS_DIR}/fraudguard_full_pipeline.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model saved to {MODELS_DIR}/fraudguard_full_pipeline.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "TNHrhZ6CkdSr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}