{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsjoNAnuj7ws"
      },
      "source": [
        "# ğŸ”’ FraudGuard Training Notebook\n",
        "\n",
        "**AD-RL-GNN Fraud Detection** | Full training pipeline with mini-batch processing\n",
        "\n",
        "This notebook trains the FraudGuard model on the IEEE-CIS fraud detection dataset using:\n",
        "- **NeighborLoader** for memory-efficient mini-batch training\n",
        "- **FAISS** for similarity graph construction (GPU if available, CPU fallback)\n",
        "- **FocalLoss** for class-imbalanced learning\n",
        "\n",
        "**Target Metrics:**\n",
        "- Specificity: 98.72%\n",
        "- G-Means Improvement: 18.11%\n",
        "- P95 Latency: <100ms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJcMLlwrj7wu"
      },
      "source": [
        "## 1ï¸âƒ£ Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQkR0H15j7wv",
        "outputId": "de134284-3fcc-46b0-ec2f-a92728717f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for data storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FiJD_x_j7ww",
        "outputId": "baede0ee-f15e-45a3-d2cd-d692070a2ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fraudguard'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 154 (delta 60), reused 125 (delta 42), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (154/154), 104.58 KiB | 5.23 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n",
            "/content/fraudguard\n"
          ]
        }
      ],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/govind104/fraudguard.git\n",
        "%cd fraudguard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vsh_FW9lj7wx",
        "outputId": "672498ce-57ff-458a-a36a-7a9a7e91528f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâš ï¸ faiss-gpu not available, using faiss-cpu\n",
            "   (Graph building on CPU, but GNN training still runs on GPU!)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPyTorch: 2.9.0, CUDA: cu126\n",
            "Downloading from: https://data.pyg.org/whl/torch-2.9.0+cu126.html\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.9.0+cu126.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy (from torch-sparse)\n",
            "  Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<2.7,>=1.26.4 (from scipy->torch-sparse)\n",
            "  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m133.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-scatter, torch-sparse\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp312-cp312-linux_x86_64.whl size=3857028 sha256=f27b7bae55dd1add42c72634a1285d22055bd28e9880af6ee8d840bff370ea96\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/20/50/44800723f57cd798630e77b3ec83bc80bd26a1e3dc3a672ef5\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp312-cp312-linux_x86_64.whl size=3039800 sha256=75c7e442fc8a9526762858c71a2e4e257a2a30b83448a88f8e42d9f9320c6bf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/fa/21/bd1d78ce1629aec4ecc924a63b82f6949dda484b6321eac6f2\n",
            "Successfully built torch-scatter torch-sparse\n",
            "Installing collected packages: torch-scatter, numpy, scipy, torch-sparse\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.4.1 scipy-1.17.0 torch-scatter-2.1.2 torch-sparse-0.6.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "9a9a4a98ea014022a86429b41f462d16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fraudguard\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: faiss-cpu<2.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (1.13.2)\n",
            "Collecting numpy<2.0.0,>=1.24.0 (from fraudguard==0.1.0)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (1.6.1)\n",
            "Collecting structlog<24.0.0,>=23.1.0 (from fraudguard==0.1.0)\n",
            "  Downloading structlog-23.3.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: torch-geometric<3.0.0,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.7.0)\n",
            "Requirement already satisfied: torch-scatter<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.1.2)\n",
            "Requirement already satisfied: torch-sparse<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (0.6.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu<2.0.0,>=1.7.4->fraudguard==0.1.0) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0.0,>=1.3.0->fraudguard==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0.0,>=1.3.0->fraudguard==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0.0,>=1.3.0->fraudguard==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.13.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (2026.1.4)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m132.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading structlog-23.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fraudguard\n",
            "  Building editable for fraudguard (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fraudguard: filename=fraudguard-0.1.0-py3-none-any.whl size=2801 sha256=5638c0b714acd4b297203f70f102910966a1da4432de3a3f589a22ae37244e19\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0ob56ewf/wheels/c6/29/62/fb6d8d095576e7e3efddf4fdcb7dfc799af71ace273f1ee84c\n",
            "Successfully built fraudguard\n",
            "Installing collected packages: structlog, numpy, fraudguard\n",
            "  Attempting uninstall: structlog\n",
            "    Found existing installation: structlog 25.5.0\n",
            "    Uninstalling structlog-25.5.0:\n",
            "      Successfully uninstalled structlog-25.5.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.4.1\n",
            "    Uninstalling numpy-2.4.1:\n",
            "      Successfully uninstalled numpy-2.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fraudguard-0.1.0 numpy-1.26.4 structlog-23.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "2c3a6a8dae7946e0a0ef21cbdb112224"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ“ Environment setup complete\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "# Note: faiss-gpu may not be available on Python 3.12\n",
        "# The code will fallback to faiss-cpu automatically\n",
        "# GNN training STILL runs on GPU - only graph building uses CPU FAISS\n",
        "!pip install -q torch torch-geometric pandas numpy scikit-learn pyyaml structlog\n",
        "\n",
        "# Try faiss-gpu first, fallback to faiss-cpu\n",
        "import subprocess\n",
        "result = subprocess.run(['pip', 'install', '-q', 'faiss-gpu'], capture_output=True)\n",
        "if result.returncode != 0:\n",
        "    print('âš ï¸ faiss-gpu not available, using faiss-cpu')\n",
        "    print('   (Graph building on CPU, but GNN training still runs on GPU!)')\n",
        "    !pip install -q faiss-cpu\n",
        "else:\n",
        "    print('âœ“ faiss-gpu installed')\n",
        "\n",
        "import torch\n",
        "\n",
        "# 1. Get exact versions\n",
        "pt_version = torch.__version__.split('+')[0]  # e.g., 2.5.1\n",
        "cuda_version = \"cu\" + torch.version.cuda.replace('.', '')  # e.g., cu124\n",
        "wheel_url = f\"https://data.pyg.org/whl/torch-{pt_version}+{cuda_version}.html\"\n",
        "\n",
        "print(f\"PyTorch: {pt_version}, CUDA: {cuda_version}\")\n",
        "print(f\"Downloading from: {wheel_url}\")\n",
        "\n",
        "# 2. Install with visible output (force reinstall to fix broken partial installs)\n",
        "!pip install --force-reinstall torch-scatter torch-sparse -f $wheel_url\n",
        "\n",
        "# Install repo in editable mode\n",
        "!pip install -e .\n",
        "\n",
        "print('\\nâœ“ Environment setup complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32LXcfp8_bZ8",
        "outputId": "23cb248a-478a-43e6-bd46-913e8ba79e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Success! Libraries are installed and loaded.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "try:\n",
        "    import torch_scatter\n",
        "    import torch_sparse\n",
        "    import fraudguard\n",
        "    print(\"âœ… Success! Libraries are installed and loaded.\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Still missing libraries: {e}\")\n",
        "    # Only if you see this error should you go back and install again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQIB4vEej7wx"
      },
      "source": [
        "## 2ï¸âƒ£ Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQDtmVWBj7wy",
        "outputId": "cddfe4d6-97e9-40db-c5f8-68e89d4ec312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: /content/drive/MyDrive/ieee-fraud-detection\n",
            "Models: /content/drive/MyDrive/fraudguard-models\n",
            "Logs: /content/drive/MyDrive/fraudguard-logs\n",
            "\n",
            "Batch size: 4096\n",
            "Sample fraction: 100%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# ==============================================\n",
        "# CONFIGURATION - UPDATE THESE PATHS AS NEEDED\n",
        "# ==============================================\n",
        "\n",
        "# Data paths - Point to your Google Drive folders\n",
        "DATA_DIR = \"/content/drive/MyDrive/ieee-fraud-detection\"\n",
        "MODELS_DIR = \"/content/drive/MyDrive/fraudguard-models\"\n",
        "LOGS_DIR = \"/content/drive/MyDrive/fraudguard-logs\"\n",
        "\n",
        "# Training parameters\n",
        "SAMPLE_FRAC = 1.0      # Use full dataset (1.0 = 100%)\n",
        "MAX_EPOCHS = 30\n",
        "BATCH_SIZE = 4096      # Reduce to 2048 or 1024 if OOM\n",
        "NUM_NEIGHBORS = [25, 10]  # 2-hop neighborhood sampling\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(LOGS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Data: {DATA_DIR}\")\n",
        "print(f\"Models: {MODELS_DIR}\")\n",
        "print(f\"Logs: {LOGS_DIR}\")\n",
        "print(f\"\\nBatch size: {BATCH_SIZE}\")\n",
        "print(f\"Sample fraction: {SAMPLE_FRAC*100:.0f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM3sXum3j7wz"
      },
      "source": [
        "## 3ï¸âƒ£ Verify GPU and FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7CHUJ3nj7wz",
        "outputId": "fc6edf58-fe8f-443e-8dc6-524d5bea1a45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "VRAM: 15.8 GB\n",
            "\n",
            "âœ“ GNN training will run on GPU\n",
            "\n",
            "FAISS GPUs: 0\n",
            "   (Using CPU FAISS for graph building - this is OK)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import faiss\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(\"\\nâœ“ GNN training will run on GPU\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ WARNING: No GPU detected. Go to Runtime > Change runtime type > GPU\")\n",
        "\n",
        "# Check FAISS GPU\n",
        "faiss_gpus = faiss.get_num_gpus() if hasattr(faiss, 'get_num_gpus') else 0\n",
        "print(f\"\\nFAISS GPUs: {faiss_gpus}\")\n",
        "if faiss_gpus == 0:\n",
        "    print(\"   (Using CPU FAISS for graph building - this is OK)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmk_r0omj7w0"
      },
      "source": [
        "## 4ï¸âƒ£ Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVU_fGbPj7w0",
        "outputId": "1f669793-bed1-4c64-8257-07d09748487a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading faiss with CPU support (no GPU detected).\n",
            "Using device: cuda\n",
            "\n",
            "Data loaded:\n",
            "  Train: 354,324\n",
            "  Val: 118,108\n",
            "  Test: 118,108\n",
            "  Fraud rate: 3.50%\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/fraudguard')\n",
        "\n",
        "from pathlib import Path\n",
        "from src.data.loader import FraudDataLoader\n",
        "from src.data.preprocessor import FeaturePreprocessor\n",
        "from src.data.graph_builder import GraphBuilder\n",
        "from src.utils.config import load_data_config\n",
        "from src.utils.device_utils import set_seed, get_device\n",
        "\n",
        "set_seed(42)\n",
        "device = get_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load config and override path with notebook variable\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# Load data with corrected path\n",
        "loader = FraudDataLoader(config=data_cfg)\n",
        "df = loader.load_train_data(sample_frac=SAMPLE_FRAC)\n",
        "train_df, val_df, test_df = loader.create_splits(df)\n",
        "\n",
        "print(f\"\\nData loaded:\")\n",
        "print(f\"  Train: {len(train_df):,}\")\n",
        "print(f\"  Val: {len(val_df):,}\")\n",
        "print(f\"  Test: {len(test_df):,}\")\n",
        "print(f\"  Fraud rate: {df['isFraud'].mean()*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV4Kblyi-Xk_"
      },
      "source": [
        "## 5ï¸âƒ£ Run Full AD-RL-GNN Pipeline\n",
        "\n",
        "We use the `FraudTrainer` class to orchestrate the full pipeline, including:\n",
        "1. **AdaptiveMCD**: Intelligent majority downsampling\n",
        "2. **RL Agent**: Dynamic subgraph selection (Random Walk, K-Hop, K-Ego)\n",
        "3. **Graph Enhancement**: Adding semantic edges\n",
        "4. **GNN Training**: CrossEntropyLoss (15x weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVCPMmZ6-Xk_",
        "outputId": "0e7bcd6e-0001-432b-b4d7-30c204f85e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Initializing Balanced Optimization on 20.0% Data...\n",
            "ğŸ“‰ Loading 20% Data Subset...\n",
            "âš™ï¸ Building Denser Graph (0.75)...\n",
            "\n",
            "ğŸ§  Training AdaptiveMCD (Alpha=0.70)...\n",
            "\n",
            "ğŸ¤– Training RL Agent...\n",
            "\n",
            "âš–ï¸ Applying Balanced Weight 18.0...\n",
            "\n",
            "ğŸ“¦ Setting up Loaders...\n",
            "\n",
            "ğŸš€ Starting Training (Target: ~60% Spec / ~60% Recall)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/neighbor_loader.py:229: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  neighbor_sampler = NeighborSampler(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   1 | Loss: 0.7808 | Spec: 14.68% | Recall: 83.97% | G-Means: 35.11%\n",
            "Epoch   2 | Loss: 0.6857 | Spec: 44.79% | Recall: 52.97% | G-Means: 48.71%\n",
            "Epoch   3 | Loss: 0.6693 | Spec: 50.78% | Recall: 47.35% | G-Means: 49.03%\n",
            "Epoch   4 | Loss: 0.6628 | Spec: 51.19% | Recall: 46.71% | G-Means: 48.90%\n",
            "Epoch   5 | Loss: 0.6585 | Spec: 70.38% | Recall: 30.15% | G-Means: 46.06%\n",
            "Epoch   6 | Loss: 0.6552 | Spec: 47.86% | Recall: 49.68% | G-Means: 48.76%\n",
            "Epoch   7 | Loss: 0.6551 | Spec: 52.01% | Recall: 45.44% | G-Means: 48.61%\n",
            "Epoch   8 | Loss: 0.6488 | Spec: 45.46% | Recall: 54.14% | G-Means: 49.61%\n",
            "Epoch   9 | Loss: 0.6466 | Spec: 55.09% | Recall: 41.51% | G-Means: 47.82%\n",
            "Epoch  10 | Loss: 0.6460 | Spec: 56.61% | Recall: 42.25% | G-Means: 48.91%\n",
            "Epoch  11 | Loss: 0.6484 | Spec: 59.04% | Recall: 38.00% | G-Means: 47.37%\n",
            "Epoch  12 | Loss: 0.6442 | Spec: 41.71% | Recall: 58.17% | G-Means: 49.26%\n",
            "Epoch  13 | Loss: 0.6425 | Spec: 55.04% | Recall: 44.48% | G-Means: 49.48%\n",
            "Epoch  14 | Loss: 0.6435 | Spec: 58.21% | Recall: 39.49% | G-Means: 47.95%\n",
            "Epoch  15 | Loss: 0.6395 | Spec: 51.29% | Recall: 46.28% | G-Means: 48.72%\n",
            "Epoch  16 | Loss: 0.6376 | Spec: 48.79% | Recall: 51.06% | G-Means: 49.91%\n",
            "Epoch  17 | Loss: 0.6354 | Spec: 57.15% | Recall: 41.19% | G-Means: 48.52%\n",
            "Epoch  18 | Loss: 0.6357 | Spec: 54.55% | Recall: 44.90% | G-Means: 49.49%\n",
            "Epoch  19 | Loss: 0.6352 | Spec: 62.76% | Recall: 33.97% | G-Means: 46.17%\n",
            "Epoch  20 | Loss: 0.6352 | Spec: 45.09% | Recall: 54.88% | G-Means: 49.75%\n",
            "Epoch  21 | Loss: 0.6367 | Spec: 59.10% | Recall: 37.69% | G-Means: 47.20%\n",
            "Epoch  22 | Loss: 0.6320 | Spec: 50.86% | Recall: 49.68% | G-Means: 50.27%\n",
            "Epoch  23 | Loss: 0.6327 | Spec: 46.09% | Recall: 54.99% | G-Means: 50.34%\n",
            "Epoch  24 | Loss: 0.6280 | Spec: 52.24% | Recall: 46.50% | G-Means: 49.28%\n",
            "Epoch  25 | Loss: 0.6310 | Spec: 62.28% | Recall: 34.61% | G-Means: 46.43%\n",
            "Epoch  26 | Loss: 0.6308 | Spec: 53.87% | Recall: 47.03% | G-Means: 50.33%\n",
            "Epoch  27 | Loss: 0.6290 | Spec: 47.13% | Recall: 55.20% | G-Means: 51.01%\n",
            "Epoch  28 | Loss: 0.6258 | Spec: 50.65% | Recall: 50.53% | G-Means: 50.59%\n",
            "Epoch  29 | Loss: 0.6264 | Spec: 53.24% | Recall: 45.33% | G-Means: 49.12%\n",
            "Epoch  30 | Loss: 0.6251 | Spec: 47.53% | Recall: 53.18% | G-Means: 50.28%\n",
            "\n",
            "Test Complete. Best G-Means: 51.01%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from src.training.trainer import FraudTrainer\n",
        "from src.utils.config import load_model_config, load_data_config\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "model_cfg = load_model_config()\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# A. DATASET SIZE (Stick to 20% for verification)\n",
        "SAMPLE_FRAC_TEST = 0.20\n",
        "\n",
        "# B. TUNED PARAMETERS (CLAUDE'S BALANCED SETTINGS)\n",
        "model_cfg.training[\"max_epochs\"] = 30\n",
        "model_cfg.training[\"learning_rate\"] = 0.003  # CHANGED: Lower LR for stability (Was 0.005)\n",
        "model_cfg.adaptive_mcd[\"alpha\"] = 0.70       # CHANGED: Moderate Drop (Was 0.85)\n",
        "model_cfg.rl_agent[\"reward_scaling\"] = 2.0   # Keep\n",
        "\n",
        "# Keep Denser Graph (Good for Recall)\n",
        "model_cfg.graph.similarity_threshold = 0.75\n",
        "\n",
        "# Initialize Trainer\n",
        "print(f\"ğŸš€ Initializing Balanced Optimization on {SAMPLE_FRAC_TEST*100}% Data...\")\n",
        "trainer = FraudTrainer(\n",
        "    model_config=model_cfg,\n",
        "    data_config=data_cfg,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"ğŸ“‰ Loading 20% Data Subset...\")\n",
        "loader = FraudDataLoader(config=data_cfg)\n",
        "df_subset = loader.load_train_data(sample_frac=SAMPLE_FRAC_TEST)\n",
        "train_df_sub, val_df_sub, test_df_sub = loader.create_splits(df_subset)\n",
        "\n",
        "print(\"âš™ï¸ Building Denser Graph (0.75)...\")\n",
        "trainer._preprocess(train_df_sub, val_df_sub, test_df_sub)\n",
        "trainer._build_graph()\n",
        "trainer._prepare_labels(train_df_sub, val_df_sub, test_df_sub)\n",
        "\n",
        "print(\"\\nğŸ§  Training AdaptiveMCD (Alpha=0.70)...\")\n",
        "trainer._train_mcd()\n",
        "\n",
        "print(\"\\nğŸ¤– Training RL Agent...\")\n",
        "trainer._train_rl_and_enhance()\n",
        "\n",
        "print(\"\\nâš–ï¸ Applying Balanced Weight 18.0...\")\n",
        "weights = torch.tensor([1.0, 18.0]).to(device)\n",
        "\n",
        "trainer._init_model()\n",
        "trainer.criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "criterion = trainer.criterion\n",
        "model = trainer.model\n",
        "\n",
        "# Optimizer with new LR\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=0.003,  # CHANGED: Match config\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ“¦ Setting up Loaders...\")\n",
        "optimized_data = Data(\n",
        "    x=trainer.X_full,\n",
        "    edge_index=trainer.edge_index,\n",
        "    y=trainer.all_labels\n",
        ")\n",
        "optimized_data.train_mask = trainer.train_mask\n",
        "optimized_data.val_mask = trainer.val_mask\n",
        "optimized_data.test_mask = trainer.test_mask\n",
        "\n",
        "train_loader = NeighborLoader(\n",
        "    optimized_data,\n",
        "    num_neighbors=[25, 10],\n",
        "    batch_size=2048,\n",
        "    input_nodes=optimized_data.train_mask,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = NeighborLoader(\n",
        "    optimized_data,\n",
        "    num_neighbors=[25, 10],\n",
        "    batch_size=2048,\n",
        "    input_nodes=optimized_data.val_mask,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"\\nğŸš€ Starting Training (Target: ~60% Spec / ~60% Recall)...\")\n",
        "best_gmeans = 0\n",
        "\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        loss = criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
        "\n",
        "        # Gradient Clipping\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        model.eval()\n",
        "        all_preds, all_true = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                out = model(batch.x, batch.edge_index)\n",
        "                pred = out[:batch.batch_size].argmax(dim=1)\n",
        "                all_preds.extend(pred.cpu().numpy())\n",
        "                all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "        cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        gmeans = np.sqrt(tpr * tnr)\n",
        "\n",
        "        print(f\"Epoch {epoch+1:>3} | Loss: {avg_loss:.4f} | Spec: {tnr*100:.2f}% | Recall: {tpr*100:.2f}% | G-Means: {gmeans*100:.2f}%\")\n",
        "\n",
        "        if gmeans > best_gmeans:\n",
        "            best_gmeans = gmeans\n",
        "            torch.save(model.state_dict(), f\"{MODELS_DIR}/fraudguard_subset_test.pt\")\n",
        "\n",
        "print(f\"\\nTest Complete. Best G-Means: {best_gmeans*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn5d0-Qy-Xk_"
      },
      "source": [
        "## 6ï¸âƒ£ Evaluation & Claims Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKLZjQO0-Xk_",
        "outputId": "b501b6f1-b78f-4fa1-ba37-b027e5da045a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Benchmarking & Evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/neighbor_loader.py:229: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  neighbor_sampler = NeighborSampler(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "FINAL RESULTS (Pro Framework)\n",
            "============================================================\n",
            "Specificity: 63.24%\n",
            "Recall:      34.47%\n",
            "G-Means:     46.69%\n",
            "P95 Latency: 45.51 ms\n"
          ]
        }
      ],
      "source": [
        "# Safe Evaluation (Mini-Batch)\n",
        "print(\"ğŸ” Benchmarking & Evaluation...\")\n",
        "model.load_state_dict(torch.load(f\"{MODELS_DIR}/fraudguard_best_pro.pt\"))\n",
        "model.eval()\n",
        "\n",
        "# Use neighbors=[25, 10] for fast inference (Latency < 10ms)\n",
        "test_loader = NeighborLoader(\n",
        "    optimized_data,\n",
        "    num_neighbors=[25, 10],\n",
        "    batch_size=4096,\n",
        "    input_nodes=optimized_data.test_mask,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "latencies = []\n",
        "all_preds, all_true = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        start = time.perf_counter()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        latencies.append((time.perf_counter() - start) * 1000)\n",
        "        pred = out[:batch.batch_size].argmax(dim=1)\n",
        "        all_preds.extend(pred.cpu().numpy())\n",
        "        all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "# Metrics\n",
        "cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "gmeans = np.sqrt(tpr * tnr)\n",
        "p95_latency = np.percentile(latencies, 95)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"FINAL RESULTS (Pro Framework)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Specificity: {tnr*100:.2f}%\")\n",
        "print(f\"Recall:      {tpr*100:.2f}%\")\n",
        "print(f\"G-Means:     {gmeans*100:.2f}%\")\n",
        "print(f\"P95 Latency: {p95_latency:.2f} ms\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 5. SUBSET EVALUATION (STABILITY CHECK)\n",
        "# ==============================================================================\n",
        "import time\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "print(\"ğŸ” Benchmarking Stability on 20% Test Set...\")\n",
        "\n",
        "# 1. Load the model trained on the subset\n",
        "# Note: We load 'fraudguard_subset_test.pt', not 'best_model.pt'\n",
        "model.load_state_dict(torch.load(f\"{MODELS_DIR}/fraudguard_subset_test.pt\"))\n",
        "model.eval()\n",
        "\n",
        "# 2. Create a Test Loader linked to the OPTIMIZED data\n",
        "# Note: We use 'optimized_data', not 'data'\n",
        "test_loader = NeighborLoader(\n",
        "    optimized_data,\n",
        "    num_neighbors=[25, 10],   # Standard inference neighbors\n",
        "    batch_size=4096,\n",
        "    input_nodes=optimized_data.test_mask,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# 3. Run Inference\n",
        "latencies = []\n",
        "all_preds, all_true = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        start = time.perf_counter()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        latencies.append((time.perf_counter() - start) * 1000)\n",
        "\n",
        "        pred = out[:batch.batch_size].argmax(dim=1)\n",
        "        all_preds.extend(pred.cpu().numpy())\n",
        "        all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "# 4. Compute Metrics\n",
        "cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "gmeans = np.sqrt(tpr * tnr)\n",
        "p95_latency = np.percentile(latencies, 95)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"STABILITY TEST RESULTS (20% Data)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Confusion Matrix: TP={tp}, TN={tn}, FP={fp}, FN={fn}\")\n",
        "print(f\"Specificity: {tnr*100:.2f}%\")\n",
        "print(f\"Recall:      {tpr*100:.2f}%\")\n",
        "print(f\"G-Means:     {gmeans*100:.2f}%\")\n",
        "print(f\"P95 Latency: {p95_latency:.2f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yGXo390EaEj",
        "outputId": "dca22ecf-15ed-45f7-845b-ee09884b62ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Benchmarking Stability on 20% Test Set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/neighbor_loader.py:229: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  neighbor_sampler = NeighborSampler(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STABILITY TEST RESULTS (20% Data)\n",
            "============================================================\n",
            "Confusion Matrix: TP=295, TN=12957, FP=9875, FN=495\n",
            "Specificity: 56.75%\n",
            "Recall:      37.34%\n",
            "G-Means:     46.03%\n",
            "P95 Latency: 22.39 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqoG6I7W-Xk_"
      },
      "source": [
        "## 7ï¸âƒ£ Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joYoeD60-XlA",
        "outputId": "87224868-4607-41a9-9e7f-8118f16e0d94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/fraudguard-models/fraudguard_full_pipeline.pt\n"
          ]
        }
      ],
      "source": [
        "trainer.save(f\"{MODELS_DIR}/fraudguard_full_pipeline.pt\")\n",
        "print(f\"Model saved to {MODELS_DIR}/fraudguard_full_pipeline.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "lqRrjwfIVP6x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}