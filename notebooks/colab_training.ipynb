{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsjoNAnuj7ws"
      },
      "source": [
        "# üîí FraudGuard Training Notebook\n",
        "\n",
        "**AD-RL-GNN Fraud Detection** | Full training pipeline with mini-batch processing\n",
        "\n",
        "This notebook trains the FraudGuard model on the IEEE-CIS fraud detection dataset using:\n",
        "- **NeighborLoader** for memory-efficient mini-batch training\n",
        "- **FAISS** for similarity graph construction (GPU if available, CPU fallback)\n",
        "- **FocalLoss** for class-imbalanced learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJcMLlwrj7wu"
      },
      "source": [
        "## 1Ô∏è‚É£ Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQkR0H15j7wv"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive for data storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FiJD_x_j7ww"
      },
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/govind104/fraudguard.git\n",
        "%cd fraudguard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsh_FW9lj7wx"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "# Note: faiss-gpu may not be available on Python 3.12\n",
        "# The code will fallback to faiss-cpu automatically\n",
        "# GNN training STILL runs on GPU - only graph building uses CPU FAISS\n",
        "!pip install -q torch torch-geometric pandas numpy scikit-learn pyyaml structlog\n",
        "\n",
        "# Try faiss-gpu first, fallback to faiss-cpu\n",
        "import subprocess\n",
        "result = subprocess.run(['pip', 'install', '-q', 'faiss-gpu'], capture_output=True)\n",
        "if result.returncode != 0:\n",
        "    print('‚ö†Ô∏è faiss-gpu not available, using faiss-cpu')\n",
        "        print('   (Graph building on CPU, but GNN training still runs on GPU!)')\n",
        "            !pip install -q faiss-cpu\n",
        "            else:\n",
        "                print('‚úì faiss-gpu installed')\n",
        "\n",
        "                # Installing torch-scatter and torch-sparse for NeighborLoader\n",
        "                import torch\n",
        "\n",
        "                # 1. Get exact versions\n",
        "                pt_version = torch.__version__.split('+')[0]  # e.g., 2.5.1\n",
        "                cuda_version = \"cu\" + torch.version.cuda.replace('.', '')  # e.g., cu124\n",
        "                wheel_url = f\"https://data.pyg.org/whl/torch-{pt_version}+{cuda_version}.html\"\n",
        "\n",
        "                print(f\"PyTorch: {pt_version}, CUDA: {cuda_version}\")\n",
        "                print(f\"Downloading from: {wheel_url}\")\n",
        "\n",
        "                # 2. Install with visible output (force reinstall to fix broken partial installs)\n",
        "                !pip install --force-reinstall torch-scatter torch-sparse -f $wheel_url\n",
        "\n",
        "                # Install repo in editable mode\n",
        "                !pip install -e .\n",
        "\n",
        "                print('\\n‚úì Environment setup complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32LXcfp8_bZ8"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import torch_scatter\n",
        "    import torch_sparse\n",
        "    import fraudguard\n",
        "    print(\"‚úÖ Success! Libraries are installed and loaded.\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Still missing libraries: {e}\")\n",
        "    # Only if you see this error should you go back and install again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQIB4vEej7wx"
      },
      "source": [
        "## 2Ô∏è‚É£ Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQDtmVWBj7wy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "# Data paths - Point to your Google Drive folders\n",
        "DATA_DIR = \"/content/drive/MyDrive/ieee-fraud-detection\"\n",
        "MODELS_DIR = \"/content/drive/MyDrive/fraudguard-models\"\n",
        "LOGS_DIR = \"/content/drive/MyDrive/fraudguard-logs\"\n",
        "\n",
        "# Training parameters\n",
        "SAMPLE_FRAC = 1.0           # Use full dataset (1.0 = 100%)\n",
        "MAX_EPOCHS = 30\n",
        "BATCH_SIZE = 2048           # Batch size for NeighborLoader\n",
        "NUM_NEIGHBORS = [25, 10]    # 2-hop neighborhood sampling\n",
        "LEARNING_RATE = 0.003       # Adam learning rate\n",
        "FRAUD_WEIGHT = 25.0         # Class weight for fraud (minority class)\n",
        "GRADIENT_CLIP = 1.0         # Max gradient norm\n",
        "\n",
        "# MCD Alpha values for A/B comparison\n",
        "BASELINE_ALPHA = 0.0        # No MCD for baseline\n",
        "GOLD_ALPHA = 0.80           # Aggressive MCD for AD-RL-GNN\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(LOGS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Data: {DATA_DIR}\")\n",
        "print(f\"Models: {MODELS_DIR}\")\n",
        "print(f\"Logs: {LOGS_DIR}\")\n",
        "print(f\"\\nBatch size: {BATCH_SIZE}\")\n",
        "print(f\"Sample fraction: {SAMPLE_FRAC*100:.0f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM3sXum3j7wz"
      },
      "source": [
        "## 3Ô∏è‚É£ Verify GPU and FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7CHUJ3nj7wz"
      },
      "outputs": [],
      "source": [
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(\"\\n‚úì GNN training will run on GPU\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è WARNING: No GPU detected. Go to Runtime > Change runtime type > GPU\")\n",
        "\n",
        "# Check FAISS GPU\n",
        "faiss_gpus = faiss.get_num_gpus() if hasattr(faiss, 'get_num_gpus') else 0\n",
        "print(f\"\\nFAISS GPUs: {faiss_gpus}\")\n",
        "if faiss_gpus == 0:\n",
        "    print(\"   (Using CPU FAISS for graph building - this is OK)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmk_r0omj7w0"
      },
      "source": [
        "## 4Ô∏è‚É£ Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVU_fGbPj7w0"
      },
      "outputs": [],
      "source": [
        "sys.path.insert(0, '/content/fraudguard')\n",
        "\n",
        "from pathlib import Path\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from src.data.loader import FraudDataLoader\n",
        "from src.utils.config import load_data_config, load_model_config\n",
        "from src.utils.device_utils import set_seed, get_device\n",
        "from src.training.trainer import FraudTrainer\n",
        "from src.training.evaluator import Evaluator\n",
        "\n",
        "set_seed(42)\n",
        "device = get_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load config and override path with notebook variable\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# Load data with corrected path\n",
        "loader = FraudDataLoader(config=data_cfg)\n",
        "df = loader.load_train_data(sample_frac=SAMPLE_FRAC)\n",
        "train_df, val_df, test_df = loader.create_splits(df)\n",
        "\n",
        "print(f\"\\nData loaded:\")\n",
        "print(f\"  Train: {len(train_df):,}\")\n",
        "print(f\"  Val: {len(val_df):,}\")\n",
        "print(f\"  Test: {len(test_df):,}\")\n",
        "print(f\"  Fraud rate: {df['isFraud'].mean()*100:.2f}%\")\n",
        "\n",
        "# Initialize evaluator for metrics computation\n",
        "evaluator = Evaluator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV4Kblyi-Xk_"
      },
      "source": [
        "## 5Ô∏è‚É£ Run Full AD-RL-GNN Pipeline\n",
        "\n",
        "We use the `FraudTrainer` class to orchestrate the full pipeline, including:\n",
        "1. **AdaptiveMCD**: Intelligent majority downsampling\n",
        "2. **RL Agent**: Dynamic subgraph selection (Random Walk, K-Hop, K-Ego)\n",
        "3. **Graph Enhancement**: Adding semantic edges\n",
        "4. **GNN Training**: CrossEntropyLoss (15x weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vanilla Baseline GNN"
      ],
      "metadata": {
        "id": "FlJIp7ssCTap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cfg = load_model_config()\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# Aligned Hyperparameters (Strict Ceteris Paribus)\n",
        "model_cfg.training[\"max_epochs\"] = MAX_EPOCHS\n",
        "model_cfg.training[\"learning_rate\"] = LEARNING_RATE\n",
        "model_cfg.adaptive_mcd[\"alpha\"] = BASELINE_ALPHA  # No MCD\n",
        "model_cfg.graph.similarity_threshold = 0.75\n",
        "\n",
        "print(\"Initializing Vanilla Baseline (No MCD, No RL)...\")\n",
        "trainer = FraudTrainer(model_config=model_cfg, data_config=data_cfg, device=device)\n",
        "\n",
        "# Preprocess\n",
        "trainer._preprocess(train_df, val_df, test_df)\n",
        "trainer._build_graph()\n",
        "trainer._prepare_labels(train_df, val_df, test_df)\n",
        "\n",
        "# Reset VRAM Monitor\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "# Apply class weight\n",
        "weights = torch.tensor([1.0, FRAUD_WEIGHT]).to(device)\n",
        "trainer._init_model()\n",
        "trainer.criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "model = trainer.model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "\n",
        "# Loaders\n",
        "optimized_data = Data(x=trainer.X_full, edge_index=trainer.edge_index, y=trainer.all_labels)\n",
        "optimized_data.train_mask = trainer.train_mask\n",
        "optimized_data.val_mask = trainer.val_mask\n",
        "train_loader = NeighborLoader(optimized_data, num_neighbors=NUM_NEIGHBORS, batch_size=BATCH_SIZE, input_nodes=optimized_data.train_mask, shuffle=True)\n",
        "val_loader = NeighborLoader(optimized_data, num_neighbors=NUM_NEIGHBORS, batch_size=BATCH_SIZE, input_nodes=optimized_data.val_mask, shuffle=False)\n",
        "\n",
        "print(f\"\\n Starting Baseline Training ({MAX_EPOCHS} Epochs)...\")\n",
        "best_gmeans_baseline = 0\n",
        "\n",
        "for epoch in range(MAX_EPOCHS):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        loss = trainer.criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
        "\n",
        "        # Gradient clipping\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=GRADIENT_CLIP)\n",
        "        optimizer.step()\n",
        "\n",
        "    # Eval every epoch\n",
        "    model.eval()\n",
        "    all_preds, all_true = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index)\n",
        "            pred = out[:batch.batch_size].argmax(dim=1)\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "    metrics = evaluator.compute_metrics(np.array(all_true), np.array(all_preds))\n",
        "    gmeans = metrics['gmeans']\n",
        "    print(f\"Baseline Epoch {epoch+1:>2} | Spec: {metrics['specificity']*100:.2f}% | Recall: {metrics['recall']*100:.2f}% | G-Means: {gmeans*100:.2f}%\")\n",
        "\n",
        "    if gmeans > best_gmeans_baseline:\n",
        "        best_gmeans_baseline = gmeans\n",
        "        torch.save(model.state_dict(), f\"{MODELS_DIR}/fraudguard_baseline.pt\")\n",
        "\n",
        "# Capture Baseline Metrics\n",
        "baseline_vram = torch.cuda.max_memory_allocated() / 1e9\n",
        "\n",
        "model.load_state_dict(torch.load(f\"{MODELS_DIR}/fraudguard_baseline.pt\"))\n",
        "model.eval()\n",
        "latencies_baseline = []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        start = time.perf_counter()\n",
        "        _ = model(batch.x, batch.edge_index)\n",
        "        latencies_baseline.append((time.perf_counter() - start) * 1000)\n",
        "\n",
        "baseline_p95 = np.percentile(latencies_baseline, 95)\n",
        "\n",
        "print(f\"\\n‚úÖ Baseline VRAM: {baseline_vram:.2f} GB\")\n",
        "print(f\"‚úÖ Baseline P95 Latency: {baseline_p95:.2f} ms\")\n",
        "print(f\"üèÅ Baseline Best G-Means: {best_gmeans_baseline*100:.2f}%\")\n",
        "\n",
        "# Clean up\n",
        "del model, trainer, optimized_data, train_loader, val_loader\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "asqbsXx6CSJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improved AD-RL-GNN"
      ],
      "metadata": {
        "id": "3DD03jfpCVcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cfg = load_model_config()\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# Aligned Hyperparameters (Strict Ceteris Paribus)\n",
        "model_cfg.training[\"max_epochs\"] = MAX_EPOCHS\n",
        "model_cfg.training[\"learning_rate\"] = LEARNING_RATE\n",
        "model_cfg.rl_agent[\"reward_scaling\"] = 2.0\n",
        "model_cfg.adaptive_mcd[\"alpha\"] = GOLD_ALPHA  # Aggressive cleaning\n",
        "model_cfg.graph.similarity_threshold = 0.75\n",
        "\n",
        "print(f\"\\nüöÄ Initializing AD-RL (MCD=ON, RL=ON)...\")\n",
        "trainer = FraudTrainer(model_config=model_cfg, data_config=data_cfg, device=device)\n",
        "\n",
        "# Reset Stats\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "# Re-process\n",
        "trainer._preprocess(train_df, val_df, test_df)\n",
        "trainer._build_graph()\n",
        "trainer._prepare_labels(train_df, val_df, test_df)\n",
        "\n",
        "print(\"\\nüß† Training AdaptiveMCD (Alpha 0.80)...\")\n",
        "trainer._train_mcd()\n",
        "\n",
        "print(\"\\nü§ñ Training RL Agent...\")\n",
        "trainer._train_rl_and_enhance()\n",
        "\n",
        "# VRAM Flush\n",
        "print(\"\\nüßπ Flushing VRAM before GNN Training...\")\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Apply class weight\n",
        "weights = torch.tensor([1.0, FRAUD_WEIGHT]).to(device)\n",
        "trainer._init_model()\n",
        "trainer.criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "model = trainer.model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "\n",
        "# Loaders\n",
        "optimized_data = Data(x=trainer.X_full, edge_index=trainer.edge_index, y=trainer.all_labels)\n",
        "optimized_data.train_mask = trainer.train_mask\n",
        "optimized_data.val_mask = trainer.val_mask\n",
        "train_loader = NeighborLoader(optimized_data, num_neighbors=NUM_NEIGHBORS, batch_size=BATCH_SIZE, input_nodes=optimized_data.train_mask, shuffle=True)\n",
        "val_loader = NeighborLoader(optimized_data, num_neighbors=NUM_NEIGHBORS, batch_size=BATCH_SIZE, input_nodes=optimized_data.val_mask, shuffle=False)\n",
        "\n",
        "print(f\"\\nüöÄ Starting AD-RL Training ({MAX_EPOCHS} Epochs)...\")\n",
        "best_gmeans_gold = 0\n",
        "\n",
        "for epoch in range(MAX_EPOCHS):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        loss = trainer.criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
        "\n",
        "        # Gradient clipping\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=GRADIENT_CLIP)\n",
        "        optimizer.step()\n",
        "\n",
        "    # Eval every epoch\n",
        "    model.eval()\n",
        "    all_preds, all_true = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index)\n",
        "            pred = out[:batch.batch_size].argmax(dim=1)\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "    metrics = evaluator.compute_metrics(np.array(all_true), np.array(all_preds))\n",
        "    gmeans = metrics['gmeans']\n",
        "    print(f\"Epoch {epoch+1:>3} | Spec: {metrics['specificity']*100:.2f}% | Recall: {metrics['recall']*100:.2f}% | G-Means: {gmeans*100:.2f}%\")\n",
        "\n",
        "    if gmeans > best_gmeans_gold:\n",
        "        best_gmeans_gold = gmeans\n",
        "        torch.save(model.state_dict(), f\"{MODELS_DIR}/fraudguard_AD_RL.pt\")\n",
        "\n",
        "# Capture AD-RL Metrics\n",
        "gold_vram = torch.cuda.max_memory_allocated() / 1e9\n",
        "\n",
        "model.load_state_dict(torch.load(f\"{MODELS_DIR}/fraudguard_AD_RL.pt\"))\n",
        "model.eval()\n",
        "latencies_gold = []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        start = time.perf_counter()\n",
        "        _ = model(batch.x, batch.edge_index)\n",
        "        latencies_gold.append((time.perf_counter() - start) * 1000)\n",
        "\n",
        "gold_p95 = np.percentile(latencies_gold, 95)\n",
        "\n",
        "print(f\"\\n‚úÖ Gold VRAM: {gold_vram:.2f} GB\")\n",
        "print(f\"‚úÖ Gold P95 Latency: {gold_p95:.2f} ms\")\n",
        "print(f\"üèÅ Final Best G-Means: {best_gmeans_gold*100:.2f}%\")\n",
        "\n",
        "# Clean up\n",
        "del model, trainer, optimized_data, train_loader, val_loader\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "wtF-llRdCXKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn5d0-Qy-Xk_"
      },
      "source": [
        "## 6Ô∏è‚É£ Evaluation & Claims Verification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute improvement using Evaluator method\n",
        "gmeans_improvement = evaluator.compute_gmeans_improvement(best_gmeans_baseline, best_gmeans_gold)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üéØ FINAL ARCHITECTURAL COMPARISON (Scientifically Aligned)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"| Metric      | Baseline | Optimized | Improvement |\")\n",
        "print(f\"|-------------|----------|-----------|-------------|\")\n",
        "print(f\"| G-Means     | {best_gmeans_baseline*100:.1f}%    | {best_gmeans_gold*100:.1f}%     | +{gmeans_improvement:.1f}%        |\")\n",
        "print(f\"| P95 Latency | {baseline_p95:.1f} ms  | {gold_p95:.1f} ms   | {((baseline_p95-gold_p95)/baseline_p95)*100:.1f}%         |\")\n",
        "print(f\"| Peak VRAM   | {baseline_vram:.1f} GB   | {gold_vram:.1f} GB    | {((baseline_vram-gold_vram)/baseline_vram)*100:.1f}%         |\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "QomZFRRzkaw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "TNHrhZ6CkdSr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}