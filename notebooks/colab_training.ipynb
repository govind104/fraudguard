{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsjoNAnuj7ws"
      },
      "source": [
        "# ğŸ”’ FraudGuard Training Notebook\n",
        "\n",
        "**AD-RL-GNN Fraud Detection** | Full training pipeline with mini-batch processing\n",
        "\n",
        "This notebook trains the FraudGuard model on the IEEE-CIS fraud detection dataset using:\n",
        "- **NeighborLoader** for memory-efficient mini-batch training\n",
        "- **FAISS** for similarity graph construction (GPU if available, CPU fallback)\n",
        "- **CrossEntropyLoss** for class-imbalanced learning\n",
        "- **MLflow** for experiment tracking and model versioning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJcMLlwrj7wu"
      },
      "source": [
        "## 1ï¸âƒ£ Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQkR0H15j7wv",
        "outputId": "e9a3b4e0-8f4f-4537-d16d-e7b039d4b0a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for data storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FiJD_x_j7ww",
        "outputId": "269f144c-4627-4f7c-e81a-523ba12cf979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fraudguard'...\n",
            "remote: Enumerating objects: 246, done.\u001b[K\n",
            "remote: Counting objects: 100% (246/246), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 246 (delta 116), reused 237 (delta 110), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (246/246), 173.66 KiB | 6.95 MiB/s, done.\n",
            "Resolving deltas: 100% (116/116), done.\n",
            "/content/fraudguard\n"
          ]
        }
      ],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/govind104/fraudguard.git\n",
        "%cd fraudguard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vsh_FW9lj7wx",
        "outputId": "7e97166c-8662-4854-f61b-361d513f2e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m135.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m787.9/787.9 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâš ï¸ faiss-gpu not available, using faiss-cpu\n",
            "   (Graph building on CPU, but GNN training still runs on GPU!)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPyTorch: 2.9.0, CUDA: cu126\n",
            "Downloading from: https://data.pyg.org/whl/torch-2.9.0+cu126.html\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.9.0+cu126.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy (from torch-sparse)\n",
            "  Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<2.7,>=1.26.4 (from scipy->torch-sparse)\n",
            "  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m145.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-scatter, torch-sparse\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp312-cp312-linux_x86_64.whl size=3857008 sha256=d665673139166d85d57310728ab6278cb4bcd12e537d4ec9493beef65609a921\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/20/50/44800723f57cd798630e77b3ec83bc80bd26a1e3dc3a672ef5\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp312-cp312-linux_x86_64.whl size=3039791 sha256=0edd51b146678aea67be50942935ca43dc4be8220e3a09b956ea8fe3241f312e\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/fa/21/bd1d78ce1629aec4ecc924a63b82f6949dda484b6321eac6f2\n",
            "Successfully built torch-scatter torch-sparse\n",
            "Installing collected packages: torch-scatter, numpy, scipy, torch-sparse\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.3\n",
            "    Uninstalling scipy-1.16.3:\n",
            "      Successfully uninstalled scipy-1.16.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.4.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.4.1 scipy-1.17.0 torch-scatter-2.1.2 torch-sparse-0.6.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "905e8b7346d54f5f8d33e7479d4e1219"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fraudguard\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: faiss-cpu<2.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (1.13.2)\n",
            "Collecting fastapi<0.110.0,>=0.109.0 (from fraudguard==0.1.0)\n",
            "  Downloading fastapi-0.109.2-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting mlflow<3.0.0,>=2.10.0 (from fraudguard==0.1.0)\n",
            "  Downloading mlflow-2.22.4-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting numpy<2.0.0,>=1.24.0 (from fraudguard==0.1.0)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.12.3)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (6.0.3)\n",
            "Collecting redis<6.0.0,>=5.0.0 (from fraudguard==0.1.0)\n",
            "  Downloading redis-5.3.1-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (1.6.1)\n",
            "Collecting structlog<24.0.0,>=23.1.0 (from fraudguard==0.1.0)\n",
            "  Downloading structlog-23.3.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: torch-geometric<3.0.0,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.7.0)\n",
            "Requirement already satisfied: torch-scatter<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (2.1.2)\n",
            "Requirement already satisfied: torch-sparse<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from fraudguard==0.1.0) (0.6.18)\n",
            "Collecting uvicorn<0.28.0,>=0.27.0 (from uvicorn[standard]<0.28.0,>=0.27.0->fraudguard==0.1.0)\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu<2.0.0,>=1.7.4->fraudguard==0.1.0) (25.0)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi<0.110.0,>=0.109.0->fraudguard==0.1.0)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<0.110.0,>=0.109.0->fraudguard==0.1.0) (4.15.0)\n",
            "Collecting mlflow-skinny==2.22.4 (from mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0)\n",
            "  Downloading mlflow_skinny-2.22.4-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.12/dist-packages (from mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (1.18.1)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.12/dist-packages (from mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.12/dist-packages (from mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (23.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.12/dist-packages (from mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.10)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.10.0)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (18.1.0)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (2.0.45)\n",
            "Collecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (0.79.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.1.46)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (8.7.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (1.37.0)\n",
            "Collecting packaging (from faiss-cpu<2.0.0,>=1.7.4->fraudguard==0.1.0)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (0.5.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->fraudguard==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->fraudguard==0.1.0) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.5.0->fraudguard==0.1.0) (0.4.2)\n",
            "Requirement already satisfied: PyJWT>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from redis<6.0.0,>=5.0.0->fraudguard==0.1.0) (2.10.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0.0,>=1.3.0->fraudguard==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2.0.0,>=1.3.0->fraudguard==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.6.1)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.13.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<0.28.0,>=0.27.0->uvicorn[standard]<0.28.0,>=0.27.0->fraudguard==0.1.0) (0.16.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]<0.28.0,>=0.27.0->fraudguard==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]<0.28.0,>=0.27.0->fraudguard==0.1.0) (1.2.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]<0.28.0,>=0.27.0->fraudguard==0.1.0) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]<0.28.0,>=0.27.0->fraudguard==0.1.0) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]<0.28.0,>=0.27.0->fraudguard==0.1.0) (15.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (1.3.10)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.1.5)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.2.7)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (11.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi<0.110.0,>=0.109.0->fraudguard==0.1.0) (4.12.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0.0,>=2.0.0->fraudguard==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric<3.0.0,>=2.3.0->fraudguard==0.1.0) (1.22.0)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (2.43.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (0.58b0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3.0.0,>=2.10.0->fraudguard==0.1.0) (0.6.2)\n",
            "Downloading fastapi-0.109.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow-2.22.4-py3-none-any.whl (29.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.22.4-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.3.1-py3-none-any.whl (272 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading structlog-23.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: fraudguard\n",
            "  Building editable for fraudguard (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fraudguard: filename=fraudguard-0.1.0-py3-none-any.whl size=4217 sha256=13d5fbba985f222f5277532f2cba8d7a588544c6a485d765d5a488a7399aae7a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uigkqe8b/wheels/c6/29/62/fb6d8d095576e7e3efddf4fdcb7dfc799af71ace273f1ee84c\n",
            "Successfully built fraudguard\n",
            "Installing collected packages: uvicorn, structlog, redis, packaging, numpy, cachetools, starlette, fastapi, mlflow-skinny, mlflow, fraudguard\n",
            "  Attempting uninstall: uvicorn\n",
            "    Found existing installation: uvicorn 0.40.0\n",
            "    Uninstalling uvicorn-0.40.0:\n",
            "      Successfully uninstalled uvicorn-0.40.0\n",
            "  Attempting uninstall: structlog\n",
            "    Found existing installation: structlog 25.5.0\n",
            "    Uninstalling structlog-25.5.0:\n",
            "      Successfully uninstalled structlog-25.5.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.4.1\n",
            "    Uninstalling numpy-2.4.1:\n",
            "      Successfully uninstalled numpy-2.4.1\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 6.2.4\n",
            "    Uninstalling cachetools-6.2.4:\n",
            "      Successfully uninstalled cachetools-6.2.4\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.50.0\n",
            "    Uninstalling starlette-0.50.0:\n",
            "      Successfully uninstalled starlette-0.50.0\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.123.10\n",
            "    Uninstalling fastapi-0.123.10:\n",
            "      Successfully uninstalled fastapi-0.123.10\n",
            "  Attempting uninstall: mlflow-skinny\n",
            "    Found existing installation: mlflow-skinny 3.8.1\n",
            "    Uninstalling mlflow-skinny-3.8.1:\n",
            "      Successfully uninstalled mlflow-skinny-3.8.1\n",
            "  Attempting uninstall: mlflow\n",
            "    Found existing installation: mlflow 3.8.1\n",
            "    Uninstalling mlflow-3.8.1:\n",
            "      Successfully uninstalled mlflow-3.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "python-fasthtml 0.12.39 requires uvicorn[standard]>=0.30, but you have uvicorn 0.27.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "google-adk 1.21.0 requires fastapi<0.124.0,>=0.115.0, but you have fastapi 0.109.2 which is incompatible.\n",
            "google-adk 1.21.0 requires starlette<1.0.0,>=0.49.1, but you have starlette 0.36.3 which is incompatible.\n",
            "google-adk 1.21.0 requires uvicorn<1.0.0,>=0.34.0, but you have uvicorn 0.27.1 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "sse-starlette 3.1.2 requires starlette>=0.49.1, but you have starlette 0.36.3 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "gradio 5.50.0 requires fastapi<1.0,>=0.115.2, but you have fastapi 0.109.2 which is incompatible.\n",
            "gradio 5.50.0 requires starlette<1.0,>=0.40.0, but you have starlette 0.36.3 which is incompatible.\n",
            "mcp 1.25.0 requires uvicorn>=0.31.1; sys_platform != \"emscripten\", but you have uvicorn 0.27.1 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cachetools-5.5.2 fastapi-0.109.2 fraudguard-0.1.0 mlflow-2.22.4 mlflow-skinny-2.22.4 numpy-1.26.4 packaging-24.2 redis-5.3.1 starlette-0.36.3 structlog-23.3.0 uvicorn-0.27.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "packaging"
                ]
              },
              "id": "e0d0cad4c4114a3bad745cdb843ba4ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ“ Environment setup complete\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "# Note: faiss-gpu may not be available on Python 3.12\n",
        "# The code will fallback to faiss-cpu automatically\n",
        "# GNN training STILL runs on GPU - only graph building uses CPU FAISS\n",
        "!pip install -q torch torch-geometric pandas numpy scikit-learn pyyaml structlog mlflow\n",
        "\n",
        "# Try faiss-gpu first, fallback to faiss-cpu\n",
        "import subprocess\n",
        "result = subprocess.run(['pip', 'install', '-q', 'faiss-gpu'], capture_output=True)\n",
        "if result.returncode != 0:\n",
        "    print('âš ï¸ faiss-gpu not available, using faiss-cpu')\n",
        "    print('   (Graph building on CPU, but GNN training still runs on GPU!)')\n",
        "    !pip install -q faiss-cpu\n",
        "else:\n",
        "    print('âœ“ faiss-gpu installed')\n",
        "\n",
        "# Installing torch-scatter and torch-sparse for NeighborLoader\n",
        "import torch\n",
        "\n",
        "# 1. Get exact versions\n",
        "pt_version = torch.__version__.split('+')[0]  # e.g., 2.5.1\n",
        "cuda_version = \"cu\" + torch.version.cuda.replace('.', '')  # e.g., cu124\n",
        "wheel_url = f\"https://data.pyg.org/whl/torch-{pt_version}+{cuda_version}.html\"\n",
        "\n",
        "print(f\"PyTorch: {pt_version}, CUDA: {cuda_version}\")\n",
        "print(f\"Downloading from: {wheel_url}\")\n",
        "\n",
        "# 2. Install with visible output (force reinstall to fix broken partial installs)\n",
        "!pip install --force-reinstall torch-scatter torch-sparse -f $wheel_url\n",
        "\n",
        "# Install repo in editable mode\n",
        "!pip install -e .\n",
        "\n",
        "print('\\nâœ“ Environment setup complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32LXcfp8_bZ8",
        "outputId": "e86474e3-eb66-429c-f01e-0aa9a80e422d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Success! Libraries are installed and loaded.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import torch_scatter\n",
        "    import torch_sparse\n",
        "    import fraudguard\n",
        "    print(\"âœ… Success! Libraries are installed and loaded.\")\n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Still missing libraries: {e}\")\n",
        "    # Only if you see this error should you go back and install again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQIB4vEej7wx"
      },
      "source": [
        "## 2ï¸âƒ£ Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQDtmVWBj7wy",
        "outputId": "a13f10e6-c5d4-4b4a-8b79-c57ab8ae4221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026/01/22 13:07:04 INFO mlflow.tracking.fluent: Experiment with name 'FraudGuard-GNN' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š MLflow tracking: /content/drive/MyDrive/fraudguard-logs/mlruns\n",
            "Data: /content/drive/MyDrive/ieee-fraud-detection\n",
            "Models: /content/drive/MyDrive/fraudguard-models\n",
            "Logs: /content/drive/MyDrive/fraudguard-logs\n",
            "\n",
            "Batch size: 2048\n",
            "Sample fraction: 100%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gc\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import faiss\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "\n",
        "# Data paths - Point to your Google Drive folders\n",
        "DATA_DIR = \"/content/drive/MyDrive/ieee-fraud-detection\"\n",
        "MODELS_DIR = \"/content/drive/MyDrive/fraudguard-models\"\n",
        "LOGS_DIR = \"/content/drive/MyDrive/fraudguard-logs\"\n",
        "\n",
        "# Training parameters\n",
        "SAMPLE_FRAC = 1.0           # Use full dataset (1.0 = 100%)\n",
        "MAX_EPOCHS = 30\n",
        "BATCH_SIZE = 2048           # Batch size for NeighborLoader\n",
        "NUM_NEIGHBORS = [25, 10]    # 2-hop neighborhood sampling\n",
        "LEARNING_RATE = 0.003       # Adam learning rate\n",
        "FRAUD_WEIGHT = 25.0         # Class weight for fraud (minority class)\n",
        "GRADIENT_CLIP = 1.0         # Max gradient norm\n",
        "\n",
        "# MCD Alpha values for A/B comparison\n",
        "BASELINE_ALPHA = 0.0        # No MCD for baseline\n",
        "GOLD_ALPHA = 0.80           # Aggressive MCD for AD-RL-GNN\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(LOGS_DIR, exist_ok=True)\n",
        "\n",
        "# Initialize MLflow\n",
        "MLFLOW_DIR = f\"{LOGS_DIR}/mlruns\"\n",
        "mlflow.set_tracking_uri(f\"file://{MLFLOW_DIR}\")\n",
        "mlflow.set_experiment(\"FraudGuard-GNN\")\n",
        "print(f\"\\nğŸ“Š MLflow tracking: {MLFLOW_DIR}\")\n",
        "\n",
        "print(f\"Data: {DATA_DIR}\")\n",
        "print(f\"Models: {MODELS_DIR}\")\n",
        "print(f\"Logs: {LOGS_DIR}\")\n",
        "print(f\"\\nBatch size: {BATCH_SIZE}\")\n",
        "print(f\"Sample fraction: {SAMPLE_FRAC*100:.0f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM3sXum3j7wz"
      },
      "source": [
        "## 3ï¸âƒ£ Verify GPU and FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7CHUJ3nj7wz",
        "outputId": "b0d679cf-8e4d-4143-e35c-23260a0285a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "VRAM: 15.8 GB\n",
            "\n",
            "âœ“ GNN training will run on GPU\n",
            "\n",
            "FAISS GPUs: 0\n",
            "   (Using CPU FAISS for graph building - this is OK)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(\"\\nâœ“ GNN training will run on GPU\")\n",
        "else:\n",
        "    print(\"\\nâš ï¸ WARNING: No GPU detected. Go to Runtime > Change runtime type > GPU\")\n",
        "\n",
        "# Check FAISS GPU\n",
        "faiss_gpus = faiss.get_num_gpus() if hasattr(faiss, 'get_num_gpus') else 0\n",
        "print(f\"\\nFAISS GPUs: {faiss_gpus}\")\n",
        "if faiss_gpus == 0:\n",
        "    print(\"   (Using CPU FAISS for graph building - this is OK)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmk_r0omj7w0"
      },
      "source": [
        "## 4ï¸âƒ£ Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVU_fGbPj7w0",
        "outputId": "c3f5e5b7-0a5d-4e09-83de-3e9205d66398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading faiss with CPU support (no GPU detected).\n",
            "Using device: cuda\n",
            "\n",
            "Data loaded:\n",
            "  Train: 354,324\n",
            "  Val: 118,108\n",
            "  Test: 118,108\n",
            "  Fraud rate: 3.50%\n"
          ]
        }
      ],
      "source": [
        "sys.path.insert(0, '/content/fraudguard')\n",
        "\n",
        "from pathlib import Path\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from src.data.loader import FraudDataLoader\n",
        "from src.utils.config import load_data_config, load_model_config\n",
        "from src.utils.device_utils import set_seed, get_device\n",
        "from src.training.trainer import FraudTrainer\n",
        "from src.training.evaluator import Evaluator\n",
        "\n",
        "set_seed(42)\n",
        "device = get_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load config and override path with notebook variable\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# Load data with corrected path\n",
        "loader = FraudDataLoader(config=data_cfg)\n",
        "df = loader.load_train_data(sample_frac=SAMPLE_FRAC)\n",
        "train_df, val_df, test_df = loader.create_splits(df)\n",
        "\n",
        "print(f\"\\nData loaded:\")\n",
        "print(f\"  Train: {len(train_df):,}\")\n",
        "print(f\"  Val: {len(val_df):,}\")\n",
        "print(f\"  Test: {len(test_df):,}\")\n",
        "print(f\"  Fraud rate: {df['isFraud'].mean()*100:.2f}%\")\n",
        "\n",
        "# Initialize evaluator for metrics computation\n",
        "evaluator = Evaluator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV4Kblyi-Xk_"
      },
      "source": [
        "## 5ï¸âƒ£ Run Full AD-RL-GNN Pipeline\n",
        "\n",
        "We use the `FraudTrainer` class to orchestrate the full pipeline, including:\n",
        "1. **AdaptiveMCD**: Intelligent majority downsampling\n",
        "2. **RL Agent**: Dynamic subgraph selection (Random Walk, K-Hop, K-Ego)\n",
        "3. **Graph Enhancement**: Adding semantic edges\n",
        "4. **GNN Training**: CrossEntropyLoss (25x weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlJIp7ssCTap"
      },
      "source": [
        "# Vanilla Baseline GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asqbsXx6CSJz",
        "outputId": "62bbbfdf-c60e-4dff-f8dc-14b44c536b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Vanilla Baseline (No MCD, No RL)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/neighbor_loader.py:229: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  neighbor_sampler = NeighborSampler(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Starting Baseline Training (30 Epochs)...\n",
            "Baseline Epoch  1 | Spec: 85.23% | Recall: 16.16% | G-Means: 37.11%\n",
            "Baseline Epoch  2 | Spec: 85.61% | Recall: 16.92% | G-Means: 38.05%\n",
            "Baseline Epoch  3 | Spec: 78.60% | Recall: 25.42% | G-Means: 44.70%\n",
            "Baseline Epoch  4 | Spec: 76.83% | Recall: 27.26% | G-Means: 45.76%\n",
            "Baseline Epoch  5 | Spec: 87.65% | Recall: 17.05% | G-Means: 38.65%\n",
            "Baseline Epoch  6 | Spec: 86.29% | Recall: 17.96% | G-Means: 39.36%\n",
            "Baseline Epoch  7 | Spec: 92.88% | Recall: 11.84% | G-Means: 33.16%\n",
            "Baseline Epoch  8 | Spec: 84.39% | Recall: 21.51% | G-Means: 42.61%\n",
            "Baseline Epoch  9 | Spec: 92.79% | Recall: 11.36% | G-Means: 32.47%\n",
            "Baseline Epoch 10 | Spec: 88.59% | Recall: 17.94% | G-Means: 39.86%\n",
            "Baseline Epoch 11 | Spec: 93.22% | Recall: 12.54% | G-Means: 34.18%\n",
            "Baseline Epoch 12 | Spec: 87.18% | Recall: 19.97% | G-Means: 41.73%\n",
            "Baseline Epoch 13 | Spec: 86.93% | Recall: 19.82% | G-Means: 41.51%\n",
            "Baseline Epoch 14 | Spec: 90.78% | Recall: 15.83% | G-Means: 37.91%\n",
            "Baseline Epoch 15 | Spec: 82.69% | Recall: 24.20% | G-Means: 44.74%\n",
            "Baseline Epoch 16 | Spec: 81.01% | Recall: 26.81% | G-Means: 46.60%\n",
            "Baseline Epoch 17 | Spec: 91.55% | Recall: 15.51% | G-Means: 37.68%\n",
            "Baseline Epoch 18 | Spec: 89.23% | Recall: 18.35% | G-Means: 40.46%\n",
            "Baseline Epoch 19 | Spec: 81.45% | Recall: 26.44% | G-Means: 46.40%\n",
            "Baseline Epoch 20 | Spec: 90.46% | Recall: 16.11% | G-Means: 38.18%\n",
            "Baseline Epoch 21 | Spec: 89.12% | Recall: 17.48% | G-Means: 39.47%\n",
            "Baseline Epoch 22 | Spec: 83.57% | Recall: 24.42% | G-Means: 45.18%\n",
            "Baseline Epoch 23 | Spec: 89.09% | Recall: 17.81% | G-Means: 39.83%\n",
            "Baseline Epoch 24 | Spec: 81.69% | Recall: 26.59% | G-Means: 46.61%\n",
            "Baseline Epoch 25 | Spec: 84.83% | Recall: 22.88% | G-Means: 44.06%\n",
            "Baseline Epoch 26 | Spec: 90.89% | Recall: 15.14% | G-Means: 37.09%\n",
            "Baseline Epoch 27 | Spec: 90.87% | Recall: 15.46% | G-Means: 37.49%\n",
            "Baseline Epoch 28 | Spec: 86.10% | Recall: 21.47% | G-Means: 42.99%\n",
            "Baseline Epoch 29 | Spec: 86.04% | Recall: 21.28% | G-Means: 42.79%\n",
            "Baseline Epoch 30 | Spec: 85.82% | Recall: 21.86% | G-Means: 43.31%\n",
            "\n",
            "âœ… Baseline VRAM: 2.98 GB\n",
            "âœ… Baseline P95 Latency: 26.86 ms\n",
            "ğŸ Baseline Best G-Means: 46.61%\n",
            "--- Baseline Training took 7037.16 seconds ---\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "model_cfg = load_model_config()\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# Aligned Hyperparameters (Strict Ceteris Paribus)\n",
        "model_cfg.training[\"max_epochs\"] = MAX_EPOCHS\n",
        "model_cfg.training[\"learning_rate\"] = LEARNING_RATE\n",
        "model_cfg.adaptive_mcd[\"alpha\"] = BASELINE_ALPHA  # No MCD\n",
        "model_cfg.graph.similarity_threshold = 0.75\n",
        "\n",
        "print(\"Initializing Vanilla Baseline (No MCD, No RL)...\")\n",
        "trainer = FraudTrainer(model_config=model_cfg, data_config=data_cfg, device=device)\n",
        "\n",
        "# Preprocess\n",
        "trainer._preprocess(train_df, val_df, test_df)\n",
        "trainer._build_graph()\n",
        "trainer._prepare_labels(train_df, val_df, test_df)\n",
        "\n",
        "# Reset VRAM Monitor\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "# Apply class weight\n",
        "weights = torch.tensor([1.0, FRAUD_WEIGHT]).to(device)\n",
        "trainer._init_model()\n",
        "trainer.criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "model = trainer.model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "\n",
        "# Loaders\n",
        "optimized_data = Data(x=trainer.X_full, edge_index=trainer.edge_index, y=trainer.all_labels)\n",
        "optimized_data.train_mask = trainer.train_mask\n",
        "optimized_data.val_mask = trainer.val_mask\n",
        "train_loader = NeighborLoader(optimized_data, num_neighbors=NUM_NEIGHBORS, batch_size=BATCH_SIZE, input_nodes=optimized_data.train_mask, shuffle=True)\n",
        "val_loader = NeighborLoader(optimized_data, num_neighbors=NUM_NEIGHBORS, batch_size=BATCH_SIZE, input_nodes=optimized_data.val_mask, shuffle=False)\n",
        "\n",
        "print(f\"\\n Starting Baseline Training ({MAX_EPOCHS} Epochs)...\")\n",
        "best_gmeans_baseline = 0\n",
        "\n",
        "# MLflow: Start baseline run\n",
        "with mlflow.start_run(run_name=\"Vanilla-Baseline\"):\n",
        "    mlflow.log_params({\n",
        "        \"model_type\": \"baseline\",\n",
        "        \"alpha\": BASELINE_ALPHA,\n",
        "        \"fraud_weight\": FRAUD_WEIGHT,\n",
        "        \"learning_rate\": LEARNING_RATE,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"max_epochs\": MAX_EPOCHS,\n",
        "        \"num_neighbors\": str(NUM_NEIGHBORS),\n",
        "        \"gradient_clip\": GRADIENT_CLIP\n",
        "    })\n",
        "\n",
        "    for epoch in range(MAX_EPOCHS):\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(batch.x, batch.edge_index)\n",
        "            loss = trainer.criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
        "\n",
        "            # Gradient clipping\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=GRADIENT_CLIP)\n",
        "            optimizer.step()\n",
        "\n",
        "        # Eval every epoch\n",
        "        model.eval()\n",
        "        all_preds, all_true = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                out = model(batch.x, batch.edge_index)\n",
        "                pred = out[:batch.batch_size].argmax(dim=1)\n",
        "                all_preds.extend(pred.cpu().numpy())\n",
        "                all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "        metrics = evaluator.compute_metrics(np.array(all_true), np.array(all_preds))\n",
        "        gmeans = metrics['gmeans']\n",
        "\n",
        "        # MLflow: Log metrics per epoch\n",
        "        mlflow.log_metrics({\n",
        "            \"gmeans\": gmeans,\n",
        "            \"recall\": metrics['recall'],\n",
        "            \"specificity\": metrics['specificity']\n",
        "        }, step=epoch)\n",
        "\n",
        "        print(f\"Baseline Epoch {epoch+1:>2} | Spec: {metrics['specificity']*100:.2f}% | Recall: {metrics['recall']*100:.2f}% | G-Means: {gmeans*100:.2f}%\")\n",
        "\n",
        "        if gmeans > best_gmeans_baseline:\n",
        "            best_gmeans_baseline = gmeans\n",
        "            torch.save(model.state_dict(), f\"{MODELS_DIR}/fraudguard_baseline.pt\")\n",
        "\n",
        "    # MLflow: Log final best metric\n",
        "    mlflow.log_metric(\"best_gmeans\", best_gmeans_baseline)\n",
        "\n",
        "# Capture Baseline Metrics\n",
        "baseline_vram = torch.cuda.max_memory_allocated() / 1e9\n",
        "\n",
        "model.load_state_dict(torch.load(f\"{MODELS_DIR}/fraudguard_baseline.pt\"))\n",
        "model.eval()\n",
        "latencies_baseline = []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        start = time.perf_counter()\n",
        "        _ = model(batch.x, batch.edge_index)\n",
        "        latencies_baseline.append((time.perf_counter() - start) * 1000)\n",
        "\n",
        "baseline_p95 = np.percentile(latencies_baseline, 95)\n",
        "\n",
        "print(f\"\\nâœ… Baseline VRAM: {baseline_vram:.2f} GB\")\n",
        "print(f\"âœ… Baseline P95 Latency: {baseline_p95:.2f} ms\")\n",
        "print(f\"ğŸ Baseline Best G-Means: {best_gmeans_baseline*100:.2f}%\")\n",
        "\n",
        "# Clean up\n",
        "del model, trainer, optimized_data, train_loader, val_loader\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(f\"--- Baseline Training took {(time.time() - start_time):.2f} seconds ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DD03jfpCVcO"
      },
      "source": [
        "# Improved AD-RL-GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtF-llRdCXKb",
        "outputId": "e5d34c9d-312a-49fb-b236-fd572b4b5f61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸš€ Initializing AD-RL (MCD=ON, RL=ON)...\n",
            "âœ… Preprocessor artifacts saved to /content/drive/MyDrive/fraudguard-models/processed\n",
            "\n",
            "ğŸ§  Training AdaptiveMCD (Alpha 0.80)...\n",
            "\n",
            "ğŸ¤– Training RL Agent...\n",
            "\n",
            "ğŸ§¹ Flushing VRAM before GNN Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/neighbor_loader.py:229: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  neighbor_sampler = NeighborSampler(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸš€ Starting AD-RL Training (30 Epochs)...\n",
            "Epoch   1 | Spec: 25.15% | Recall: 77.03% | G-Means: 44.02%\n",
            "Epoch   2 | Spec: 5.73% | Recall: 95.36% | G-Means: 23.38%\n",
            "Epoch   3 | Spec: 24.22% | Recall: 79.18% | G-Means: 43.79%\n",
            "Epoch   4 | Spec: 19.94% | Recall: 84.71% | G-Means: 41.10%\n",
            "Epoch   5 | Spec: 21.20% | Recall: 83.58% | G-Means: 42.10%\n",
            "Epoch   6 | Spec: 38.67% | Recall: 69.07% | G-Means: 51.68%\n",
            "Epoch   7 | Spec: 44.97% | Recall: 63.33% | G-Means: 53.37%\n",
            "Epoch   8 | Spec: 40.46% | Recall: 65.80% | G-Means: 51.60%\n",
            "Epoch   9 | Spec: 49.62% | Recall: 59.01% | G-Means: 54.11%\n",
            "Epoch  10 | Spec: 37.89% | Recall: 70.44% | G-Means: 51.66%\n",
            "Epoch  11 | Spec: 38.59% | Recall: 68.58% | G-Means: 51.44%\n",
            "Epoch  12 | Spec: 39.24% | Recall: 70.03% | G-Means: 52.42%\n",
            "Epoch  13 | Spec: 55.48% | Recall: 57.32% | G-Means: 56.39%\n",
            "Epoch  14 | Spec: 42.78% | Recall: 66.49% | G-Means: 53.34%\n",
            "Epoch  15 | Spec: 49.20% | Recall: 62.07% | G-Means: 55.26%\n",
            "Epoch  16 | Spec: 50.25% | Recall: 59.51% | G-Means: 54.68%\n",
            "Epoch  17 | Spec: 50.51% | Recall: 61.72% | G-Means: 55.83%\n",
            "Epoch  18 | Spec: 44.93% | Recall: 65.15% | G-Means: 54.10%\n",
            "Epoch  19 | Spec: 49.29% | Recall: 62.09% | G-Means: 55.32%\n",
            "Epoch  20 | Spec: 57.37% | Recall: 57.04% | G-Means: 57.21%\n",
            "Epoch  21 | Spec: 58.76% | Recall: 54.17% | G-Means: 56.42%\n",
            "Epoch  22 | Spec: 58.32% | Recall: 55.74% | G-Means: 57.02%\n",
            "Epoch  23 | Spec: 47.30% | Recall: 64.61% | G-Means: 55.28%\n",
            "Epoch  24 | Spec: 53.57% | Recall: 57.75% | G-Means: 55.62%\n",
            "Epoch  25 | Spec: 61.78% | Recall: 51.33% | G-Means: 56.32%\n",
            "Epoch  26 | Spec: 59.72% | Recall: 52.16% | G-Means: 55.81%\n",
            "Epoch  27 | Spec: 51.77% | Recall: 60.70% | G-Means: 56.06%\n",
            "Epoch  28 | Spec: 57.40% | Recall: 56.00% | G-Means: 56.69%\n",
            "Epoch  29 | Spec: 71.26% | Recall: 44.18% | G-Means: 56.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026/01/22 17:35:14 WARNING mlflow.utils.requirements_utils: Found torch version (2.9.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.9.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  30 | Spec: 54.77% | Recall: 59.49% | G-Means: 57.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026/01/22 17:35:24 WARNING mlflow.utils.requirements_utils: Found torch version (2.9.0+cu126) contains a local version label (+cu126). MLflow logged a pip requirement for this package as 'torch==2.9.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "\u001b[31m2026/01/22 17:35:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
            "Successfully registered model 'FraudGuard-Production'.\n",
            "Created version '1' of model 'FraudGuard-Production'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š Model logged to MLflow Model Registry\n",
            "\n",
            "âœ… Gold VRAM: 10.62 GB\n",
            "âœ… Gold P95 Latency: 27.84 ms\n",
            "ğŸ Final Best G-Means: 57.21%\n",
            "--- AD-RL Training took 8495.12 seconds ---\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "model_cfg = load_model_config()\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# Aligned Hyperparameters (Strict Ceteris Paribus)\n",
        "model_cfg.training[\"max_epochs\"] = MAX_EPOCHS\n",
        "model_cfg.training[\"learning_rate\"] = LEARNING_RATE\n",
        "model_cfg.rl_agent[\"reward_scaling\"] = 2.0\n",
        "model_cfg.adaptive_mcd[\"alpha\"] = GOLD_ALPHA  # Aggressive cleaning\n",
        "model_cfg.graph.similarity_threshold = 0.75\n",
        "\n",
        "print(f\"\\nğŸš€ Initializing AD-RL (MCD=ON, RL=ON)...\")\n",
        "trainer = FraudTrainer(model_config=model_cfg, data_config=data_cfg, device=device)\n",
        "\n",
        "# Reset Stats\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "# Re-process\n",
        "trainer._preprocess(train_df, val_df, test_df)\n",
        "trainer._build_graph()\n",
        "trainer._prepare_labels(train_df, val_df, test_df)\n",
        "\n",
        "# Save preprocessor artifacts for API deployment (from the deployed model)\n",
        "import pickle\n",
        "PROCESSED_DIR = f\"{MODELS_DIR}/processed\"\n",
        "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
        "\n",
        "with open(f\"{PROCESSED_DIR}/scaler.pkl\", \"wb\") as f:\n",
        "    pickle.dump(trainer.preprocessor.scaler, f)\n",
        "\n",
        "with open(f\"{PROCESSED_DIR}/pca.pkl\", \"wb\") as f:\n",
        "    pickle.dump(trainer.preprocessor.pca, f)\n",
        "\n",
        "print(f\"âœ… Preprocessor artifacts saved to {PROCESSED_DIR}\")\n",
        "\n",
        "print(\"\\nğŸ§  Training AdaptiveMCD (Alpha 0.80)...\")\n",
        "trainer._train_mcd()\n",
        "\n",
        "print(\"\\nğŸ¤– Training RL Agent...\")\n",
        "trainer._train_rl_and_enhance()\n",
        "\n",
        "# VRAM Flush\n",
        "print(\"\\nğŸ§¹ Flushing VRAM before GNN Training...\")\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Apply class weight\n",
        "weights = torch.tensor([1.0, FRAUD_WEIGHT]).to(device)\n",
        "trainer._init_model()\n",
        "trainer.criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "model = trainer.model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "\n",
        "# Loaders\n",
        "optimized_data = Data(x=trainer.X_full, edge_index=trainer.edge_index, y=trainer.all_labels)\n",
        "optimized_data.train_mask = trainer.train_mask\n",
        "optimized_data.val_mask = trainer.val_mask\n",
        "train_loader = NeighborLoader(optimized_data, num_neighbors=NUM_NEIGHBORS, batch_size=BATCH_SIZE, input_nodes=optimized_data.train_mask, shuffle=True)\n",
        "val_loader = NeighborLoader(optimized_data, num_neighbors=NUM_NEIGHBORS, batch_size=BATCH_SIZE, input_nodes=optimized_data.val_mask, shuffle=False)\n",
        "\n",
        "print(f\"\\nğŸš€ Starting AD-RL Training ({MAX_EPOCHS} Epochs)...\")\n",
        "best_gmeans_gold = 0\n",
        "\n",
        "# MLflow: Start AD-RL-GNN run\n",
        "with mlflow.start_run(run_name=\"AD-RL-GNN\"):\n",
        "    mlflow.log_params({\n",
        "        \"model_type\": \"AD-RL-GNN\",\n",
        "        \"alpha\": GOLD_ALPHA,\n",
        "        \"fraud_weight\": FRAUD_WEIGHT,\n",
        "        \"learning_rate\": LEARNING_RATE,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"max_epochs\": MAX_EPOCHS,\n",
        "        \"num_neighbors\": str(NUM_NEIGHBORS),\n",
        "        \"gradient_clip\": GRADIENT_CLIP,\n",
        "        \"reward_scaling\": 2.0\n",
        "    })\n",
        "\n",
        "    for epoch in range(MAX_EPOCHS):\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(batch.x, batch.edge_index)\n",
        "            loss = trainer.criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
        "\n",
        "            # Gradient clipping\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=GRADIENT_CLIP)\n",
        "            optimizer.step()\n",
        "\n",
        "        # Eval every epoch\n",
        "        model.eval()\n",
        "        all_preds, all_true = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                batch = batch.to(device)\n",
        "                out = model(batch.x, batch.edge_index)\n",
        "                pred = out[:batch.batch_size].argmax(dim=1)\n",
        "                all_preds.extend(pred.cpu().numpy())\n",
        "                all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "        metrics = evaluator.compute_metrics(np.array(all_true), np.array(all_preds))\n",
        "        gmeans = metrics['gmeans']\n",
        "\n",
        "        # MLflow: Log metrics per epoch\n",
        "        mlflow.log_metrics({\n",
        "            \"gmeans\": gmeans,\n",
        "            \"recall\": metrics['recall'],\n",
        "            \"specificity\": metrics['specificity']\n",
        "        }, step=epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch+1:>3} | Spec: {metrics['specificity']*100:.2f}% | Recall: {metrics['recall']*100:.2f}% | G-Means: {gmeans*100:.2f}%\")\n",
        "\n",
        "        if gmeans > best_gmeans_gold:\n",
        "            best_gmeans_gold = gmeans\n",
        "            torch.save(model.state_dict(), f\"{MODELS_DIR}/fraudguard_AD_RL.pt\")\n",
        "\n",
        "    # MLflow: Log final metrics and model\n",
        "    mlflow.log_metric(\"best_gmeans\", best_gmeans_gold)\n",
        "\n",
        "    # Load best model and log to MLflow\n",
        "    model.load_state_dict(torch.load(f\"{MODELS_DIR}/fraudguard_AD_RL.pt\"))\n",
        "    mlflow.pytorch.log_model(model, \"fraud_gnn\", registered_model_name=\"FraudGuard-Production\")\n",
        "    print(\"\\nğŸ“Š Model logged to MLflow Model Registry\")\n",
        "\n",
        "# Capture AD-RL Metrics\n",
        "gold_vram = torch.cuda.max_memory_allocated() / 1e9\n",
        "\n",
        "model.eval()\n",
        "latencies_gold = []\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        batch = batch.to(device)\n",
        "        start = time.perf_counter()\n",
        "        _ = model(batch.x, batch.edge_index)\n",
        "        latencies_gold.append((time.perf_counter() - start) * 1000)\n",
        "\n",
        "gold_p95 = np.percentile(latencies_gold, 95)\n",
        "\n",
        "print(f\"\\nâœ… Gold VRAM: {gold_vram:.2f} GB\")\n",
        "print(f\"âœ… Gold P95 Latency: {gold_p95:.2f} ms\")\n",
        "print(f\"ğŸ Final Best G-Means: {best_gmeans_gold*100:.2f}%\")\n",
        "\n",
        "# Clean up\n",
        "del model, trainer, optimized_data, train_loader, val_loader\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(f\"--- AD-RL Training took {(time.time() - start_time):.2f} seconds ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn5d0-Qy-Xk_"
      },
      "source": [
        "## 6ï¸âƒ£ Evaluation & Claims Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QomZFRRzkaw2",
        "outputId": "32562984-4712-47ec-d54e-1aaae99f811a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ¯ FINAL ARCHITECTURAL COMPARISON (Scientifically Aligned)\n",
            "============================================================\n",
            "| Metric      | Baseline | Optimized | Improvement |\n",
            "|-------------|----------|-----------|-------------|\n",
            "| G-Means     | 46.6%    | 57.2%     | +22.7%        |\n",
            "| P95 Latency | 26.9 ms  | 27.8 ms   | -3.7%         |\n",
            "| Peak VRAM   | 3.0 GB   | 10.6 GB    | -256.1%         |\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Compute improvement using Evaluator method\n",
        "gmeans_improvement = evaluator.compute_gmeans_improvement(best_gmeans_baseline, best_gmeans_gold)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ¯ FINAL ARCHITECTURAL COMPARISON (Scientifically Aligned)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"| Metric      | Baseline | Optimized | Improvement |\")\n",
        "print(f\"|-------------|----------|-----------|-------------|\")\n",
        "print(f\"| G-Means     | {best_gmeans_baseline*100:.1f}%    | {best_gmeans_gold*100:.1f}%     | +{gmeans_improvement:.1f}%        |\")\n",
        "print(f\"| P95 Latency | {baseline_p95:.1f} ms  | {gold_p95:.1f} ms   | {((baseline_p95-gold_p95)/baseline_p95)*100:.1f}%         |\")\n",
        "print(f\"| Peak VRAM   | {baseline_vram:.1f} GB   | {gold_vram:.1f} GB    | {((baseline_vram-gold_vram)/baseline_vram)*100:.1f}%         |\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TNHrhZ6CkdSr"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}