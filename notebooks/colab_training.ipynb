{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsjoNAnuj7ws"
      },
      "source": [
        "# üîí FraudGuard Training Notebook\n",
        "\n",
        "**AD-RL-GNN Fraud Detection** | Full training pipeline with mini-batch processing\n",
        "\n",
        "This notebook trains the FraudGuard model on the IEEE-CIS fraud detection dataset using:\n",
        "- **NeighborLoader** for memory-efficient mini-batch training\n",
        "- **FAISS** for similarity graph construction (GPU if available, CPU fallback)\n",
        "- **FocalLoss** for class-imbalanced learning\n",
        "\n",
        "**Target Metrics:**\n",
        "- Specificity: 98.72%\n",
        "- G-Means Improvement: 18.11%\n",
        "- P95 Latency: <100ms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJcMLlwrj7wu"
      },
      "source": [
        "## 1Ô∏è‚É£ Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQkR0H15j7wv",
        "outputId": "de134284-3fcc-46b0-ec2f-a92728717f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for data storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FiJD_x_j7ww",
        "outputId": "baede0ee-f15e-45a3-d2cd-d692070a2ddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fraudguard'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 154 (delta 60), reused 125 (delta 42), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (154/154), 104.58 KiB | 5.23 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n",
            "/content/fraudguard\n"
          ]
        }
      ],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/govind104/fraudguard.git\n",
        "%cd fraudguard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vsh_FW9lj7wx",
        "outputId": "672498ce-57ff-458a-a36a-7a9a7e91528f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚ö†Ô∏è faiss-gpu not available, using faiss-cpu\n",
            "   (Graph building on CPU, but GNN training still runs on GPU!)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPyTorch: 2.9.0, CUDA: cu126\n",
            "Downloading from: https://data.pyg.org/whl/torch-2.9.0+cu126.html\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.9.0+cu126.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy (from torch-sparse)\n",
            "  Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<2.7,>=1.26.4 (from scipy->torch-sparse)\n",
            "  Downloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.4.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m133.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-scatter, torch-sparse\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "# Note: faiss-gpu may not be available on Python 3.12\n",
        "# The code will fallback to faiss-cpu automatically\n",
        "# GNN training STILL runs on GPU - only graph building uses CPU FAISS\n",
        "!pip install -q torch torch-geometric pandas numpy scikit-learn pyyaml structlog\n",
        "\n",
        "# Try faiss-gpu first, fallback to faiss-cpu\n",
        "import subprocess\n",
        "result = subprocess.run(['pip', 'install', '-q', 'faiss-gpu'], capture_output=True)\n",
        "if result.returncode != 0:\n",
        "    print('‚ö†Ô∏è faiss-gpu not available, using faiss-cpu')\n",
        "    print('   (Graph building on CPU, but GNN training still runs on GPU!)')\n",
        "    !pip install -q faiss-cpu\n",
        "else:\n",
        "    print('‚úì faiss-gpu installed')\n",
        "\n",
        "import torch\n",
        "\n",
        "# 1. Get exact versions\n",
        "pt_version = torch.__version__.split('+')[0]  # e.g., 2.5.1\n",
        "cuda_version = \"cu\" + torch.version.cuda.replace('.', '')  # e.g., cu124\n",
        "wheel_url = f\"https://data.pyg.org/whl/torch-{pt_version}+{cuda_version}.html\"\n",
        "\n",
        "print(f\"PyTorch: {pt_version}, CUDA: {cuda_version}\")\n",
        "print(f\"Downloading from: {wheel_url}\")\n",
        "\n",
        "# 2. Install with visible output (force reinstall to fix broken partial installs)\n",
        "!pip install --force-reinstall torch-scatter torch-sparse -f $wheel_url\n",
        "\n",
        "# Install repo in editable mode\n",
        "!pip install -e .\n",
        "\n",
        "print('\\n‚úì Environment setup complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32LXcfp8_bZ8",
        "outputId": "b5ebcdf3-df42-4d63-b4a3-4988d9e41f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Success! Libraries are installed and loaded.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "try:\n",
        "    import torch_scatter\n",
        "    import torch_sparse\n",
        "    import fraudguard\n",
        "    print(\"‚úÖ Success! Libraries are installed and loaded.\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Still missing libraries: {e}\")\n",
        "    # Only if you see this error should you go back and install again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQIB4vEej7wx"
      },
      "source": [
        "## 2Ô∏è‚É£ Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQDtmVWBj7wy",
        "outputId": "160d3a25-56c8-4454-fb87-8e87afcf9b8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: /content/drive/MyDrive/ieee-fraud-detection\n",
            "Models: /content/drive/MyDrive/fraudguard-models\n",
            "Logs: /content/drive/MyDrive/fraudguard-logs\n",
            "\n",
            "Batch size: 4096\n",
            "Sample fraction: 100%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# ==============================================\n",
        "# CONFIGURATION - UPDATE THESE PATHS AS NEEDED\n",
        "# ==============================================\n",
        "\n",
        "# Data paths - Point to your Google Drive folders\n",
        "DATA_DIR = \"/content/drive/MyDrive/ieee-fraud-detection\"\n",
        "MODELS_DIR = \"/content/drive/MyDrive/fraudguard-models\"\n",
        "LOGS_DIR = \"/content/drive/MyDrive/fraudguard-logs\"\n",
        "\n",
        "# Training parameters\n",
        "SAMPLE_FRAC = 1.0      # Use full dataset (1.0 = 100%)\n",
        "MAX_EPOCHS = 30\n",
        "BATCH_SIZE = 4096      # Reduce to 2048 or 1024 if OOM\n",
        "NUM_NEIGHBORS = [25, 10]  # 2-hop neighborhood sampling\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(LOGS_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Data: {DATA_DIR}\")\n",
        "print(f\"Models: {MODELS_DIR}\")\n",
        "print(f\"Logs: {LOGS_DIR}\")\n",
        "print(f\"\\nBatch size: {BATCH_SIZE}\")\n",
        "print(f\"Sample fraction: {SAMPLE_FRAC*100:.0f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM3sXum3j7wz"
      },
      "source": [
        "## 3Ô∏è‚É£ Verify GPU and FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7CHUJ3nj7wz",
        "outputId": "cc1c95f6-3dc9-4b94-e877-ae790daabac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "VRAM: 15.8 GB\n",
            "\n",
            "‚úì GNN training will run on GPU\n",
            "\n",
            "FAISS GPUs: 0\n",
            "   (Using CPU FAISS for graph building - this is OK)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import faiss\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    print(\"\\n‚úì GNN training will run on GPU\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è WARNING: No GPU detected. Go to Runtime > Change runtime type > GPU\")\n",
        "\n",
        "# Check FAISS GPU\n",
        "faiss_gpus = faiss.get_num_gpus() if hasattr(faiss, 'get_num_gpus') else 0\n",
        "print(f\"\\nFAISS GPUs: {faiss_gpus}\")\n",
        "if faiss_gpus == 0:\n",
        "    print(\"   (Using CPU FAISS for graph building - this is OK)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lmk_r0omj7w0"
      },
      "source": [
        "## 4Ô∏è‚É£ Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVU_fGbPj7w0",
        "outputId": "19384df8-c8fc-4969-9186-8370cfbeebf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading faiss with CPU support (no GPU detected).\n",
            "Using device: cuda\n",
            "\n",
            "Data loaded:\n",
            "  Train: 354,324\n",
            "  Val: 118,108\n",
            "  Test: 118,108\n",
            "  Fraud rate: 3.50%\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/fraudguard')\n",
        "\n",
        "from pathlib import Path\n",
        "from src.data.loader import FraudDataLoader\n",
        "from src.data.preprocessor import FeaturePreprocessor\n",
        "from src.data.graph_builder import GraphBuilder\n",
        "from src.utils.config import load_data_config\n",
        "from src.utils.device_utils import set_seed, get_device\n",
        "\n",
        "set_seed(42)\n",
        "device = get_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load config and override path with notebook variable\n",
        "data_cfg = load_data_config()\n",
        "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
        "\n",
        "# Load data with corrected path\n",
        "loader = FraudDataLoader(config=data_cfg)\n",
        "df = loader.load_train_data(sample_frac=SAMPLE_FRAC)\n",
        "train_df, val_df, test_df = loader.create_splits(df)\n",
        "\n",
        "print(f\"\\nData loaded:\")\n",
        "print(f\"  Train: {len(train_df):,}\")\n",
        "print(f\"  Val: {len(val_df):,}\")\n",
        "print(f\"  Test: {len(test_df):,}\")\n",
        "print(f\"  Fraud rate: {df['isFraud'].mean()*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV4Kblyi-Xk_"
      },
      "source": [
        "## 5Ô∏è‚É£ Run Full AD-RL-GNN Pipeline\n",
        "\n",
        "We use the `FraudTrainer` class to orchestrate the full pipeline, including:\n",
        "1. **AdaptiveMCD**: Intelligent majority downsampling\n",
        "2. **RL Agent**: Dynamic subgraph selection (Random Walk, K-Hop, K-Ego)\n",
        "3. **Graph Enhancement**: Adding semantic edges\n",
        "4. **GNN Training**: CrossEntropyLoss (15x weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVCPMmZ6-Xk_",
        "outputId": "9c3c649d-ba38-4839-80b6-a73c15929c60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Initializing Hybrid AD-RL-GNN Pipeline...\n",
            "‚öôÔ∏è Preprocessing & Building Graph...\n",
            "\n",
            "üß† Training AdaptiveMCD (The Smart Filter)...\n",
            "\n",
            "ü§ñ Training RL Agent (The Graph Explorer)...\n",
            "\n",
            "üì¶ Setting up Mini-Batch Loaders (Fixing Memory Crash)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/neighbor_loader.py:229: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  neighbor_sampler = NeighborSampler(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Starting GNN Training (Mini-Batch) on cuda...\n",
            "Epoch   1 | Loss: 0.7742 | Spec: 95.09% | Recall: 4.97% | G-Means: 21.73%\n",
            "Epoch   2 | Loss: 0.6708 | Spec: 79.46% | Recall: 20.91% | G-Means: 40.76%\n",
            "Epoch   3 | Loss: 0.6652 | Spec: 91.50% | Recall: 8.78% | G-Means: 28.35%\n",
            "Epoch   4 | Loss: 0.6603 | Spec: 88.69% | Recall: 11.30% | G-Means: 31.66%\n",
            "Epoch   5 | Loss: 0.6508 | Spec: 83.75% | Recall: 15.03% | G-Means: 35.48%\n",
            "Epoch   6 | Loss: 0.6387 | Spec: 81.91% | Recall: 19.08% | G-Means: 39.54%\n",
            "Epoch   7 | Loss: 0.6275 | Spec: 75.81% | Recall: 22.86% | G-Means: 41.63%\n",
            "Epoch   8 | Loss: 0.6220 | Spec: 69.37% | Recall: 28.24% | G-Means: 44.26%\n",
            "Epoch   9 | Loss: 0.6169 | Spec: 71.01% | Recall: 27.09% | G-Means: 43.86%\n",
            "Epoch  10 | Loss: 0.6160 | Spec: 63.20% | Recall: 34.31% | G-Means: 46.57%\n",
            "Epoch  11 | Loss: 0.6119 | Spec: 88.26% | Recall: 14.77% | G-Means: 36.11%\n",
            "Epoch  12 | Loss: 0.6125 | Spec: 70.31% | Recall: 27.93% | G-Means: 44.32%\n",
            "Epoch  13 | Loss: 0.6083 | Spec: 86.61% | Recall: 15.88% | G-Means: 37.08%\n",
            "Epoch  14 | Loss: 0.6074 | Spec: 73.73% | Recall: 26.33% | G-Means: 44.06%\n",
            "Epoch  15 | Loss: 0.6063 | Spec: 79.11% | Recall: 22.73% | G-Means: 42.40%\n",
            "Epoch  16 | Loss: 0.6046 | Spec: 79.20% | Recall: 20.99% | G-Means: 40.78%\n",
            "Epoch  17 | Loss: 0.6025 | Spec: 81.11% | Recall: 21.23% | G-Means: 41.50%\n",
            "Epoch  18 | Loss: 0.6059 | Spec: 91.41% | Recall: 14.08% | G-Means: 35.87%\n",
            "Epoch  19 | Loss: 0.6002 | Spec: 70.43% | Recall: 29.47% | G-Means: 45.56%\n",
            "Epoch  20 | Loss: 0.6008 | Spec: 86.97% | Recall: 16.72% | G-Means: 38.13%\n",
            "Epoch  21 | Loss: 0.6008 | Spec: 74.17% | Recall: 27.00% | G-Means: 44.75%\n",
            "Epoch  22 | Loss: 0.5994 | Spec: 92.04% | Recall: 11.52% | G-Means: 32.56%\n",
            "Epoch  23 | Loss: 0.6007 | Spec: 89.77% | Recall: 15.94% | G-Means: 37.83%\n",
            "Epoch  24 | Loss: 0.5978 | Spec: 76.25% | Recall: 26.13% | G-Means: 44.64%\n",
            "Epoch  25 | Loss: 0.6022 | Spec: 92.46% | Recall: 11.73% | G-Means: 32.94%\n",
            "Epoch  26 | Loss: 0.6006 | Spec: 70.77% | Recall: 29.75% | G-Means: 45.89%\n",
            "Epoch  27 | Loss: 0.5928 | Spec: 77.88% | Recall: 25.55% | G-Means: 44.61%\n",
            "Epoch  28 | Loss: 0.5968 | Spec: 84.20% | Recall: 20.08% | G-Means: 41.12%\n",
            "Epoch  29 | Loss: 0.5928 | Spec: 90.91% | Recall: 13.99% | G-Means: 35.66%\n",
            "Epoch  30 | Loss: 0.5946 | Spec: 89.14% | Recall: 15.12% | G-Means: 36.71%\n",
            "\n",
            "Training Complete. Best G-Means: 46.57%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from src.training.trainer import FraudTrainer\n",
        "from src.utils.config import load_model_config, load_data_config\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load Configs & Apply Pro Overrides\n",
        "model_cfg = load_model_config()\n",
        "data_cfg = load_data_config()\n",
        "\n",
        "model_cfg.training[\"max_epochs\"] = 30\n",
        "model_cfg.adaptive_mcd[\"alpha\"] = 0.5\n",
        "model_cfg.rl_agent[\"reward_scaling\"] = 2.0\n",
        "model_cfg.graph.similarity_threshold = 0.80\n",
        "\n",
        "# Initialize Trainer (Wrapper)\n",
        "print(\"üöÄ Initializing Hybrid AD-RL-GNN Pipeline...\")\n",
        "trainer = FraudTrainer(\n",
        "    model_config=model_cfg,\n",
        "    data_config=data_cfg,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Run the Data Prep Steps\n",
        "print(\"‚öôÔ∏è Preprocessing & Building Graph...\")\n",
        "trainer._preprocess(train_df, val_df, test_df)\n",
        "trainer._build_graph()\n",
        "trainer._prepare_labels(train_df, val_df, test_df)\n",
        "\n",
        "# A. AdaptiveMCD: Fixes the Class Imbalance (Updates train_mask)\n",
        "print(\"\\nüß† Training AdaptiveMCD (The Smart Filter)...\")\n",
        "trainer._train_mcd()\n",
        "\n",
        "# B. RL Agent: Fixes the Graph Topology (Updates edge_index)\n",
        "print(\"\\nü§ñ Training RL Agent (The Graph Explorer)...\")\n",
        "trainer._train_rl_and_enhance()\n",
        "\n",
        "print(\"\\nüì¶ Setting up Mini-Batch Loaders (Fixing Memory Crash)...\")\n",
        "\n",
        "# Create PyG Data Object from the OPTIMIZED Trainer State\n",
        "optimized_data = Data(\n",
        "    x=trainer.X_full,\n",
        "    edge_index=trainer.edge_index, # <--- Contains RL-enhanced edges\n",
        "    y=trainer.all_labels\n",
        ")\n",
        "optimized_data.train_mask = trainer.train_mask\n",
        "optimized_data.val_mask = trainer.val_mask\n",
        "optimized_data.test_mask = trainer.test_mask\n",
        "\n",
        "# Create Loaders (Batch Size 4096 = Low VRAM usage)\n",
        "train_loader = NeighborLoader(\n",
        "    optimized_data,\n",
        "    num_neighbors=[25, 10],\n",
        "    batch_size=4096,\n",
        "    input_nodes=optimized_data.train_mask,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = NeighborLoader(\n",
        "    optimized_data,\n",
        "    num_neighbors=[25, 10],\n",
        "    batch_size=4096,\n",
        "    input_nodes=optimized_data.val_mask,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Initialize Model & Optimizer\n",
        "trainer._init_model()\n",
        "model = trainer.model\n",
        "optimizer = trainer.optimizer\n",
        "criterion = trainer.criterion # Already set to Weighted CrossEntropy (15x)\n",
        "\n",
        "# Training Loop\n",
        "print(f\"\\nüöÄ Starting GNN Training (Mini-Batch) on {device}...\")\n",
        "best_gmeans = 0\n",
        "history = []\n",
        "\n",
        "for epoch in range(30): # MAX_EPOCHS\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        loss = criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    all_preds, all_true = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch.x, batch.edge_index)\n",
        "            pred = out[:batch.batch_size].argmax(dim=1)\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    gmeans = np.sqrt(tpr * tnr)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:>3} | Loss: {avg_loss:.4f} | Spec: {tnr*100:.2f}% | Recall: {tpr*100:.2f}% | G-Means: {gmeans*100:.2f}%\")\n",
        "\n",
        "    if gmeans > best_gmeans:\n",
        "        best_gmeans = gmeans\n",
        "        torch.save(model.state_dict(), f\"{MODELS_DIR}/fraudguard_best_pro.pt\")\n",
        "\n",
        "print(f\"\\nTraining Complete. Best G-Means: {best_gmeans*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn5d0-Qy-Xk_"
      },
      "source": [
        "## 6Ô∏è‚É£ Evaluation & Claims Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKLZjQO0-Xk_",
        "outputId": "b501b6f1-b78f-4fa1-ba37-b027e5da045a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Benchmarking & Evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/neighbor_loader.py:229: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  neighbor_sampler = NeighborSampler(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "FINAL RESULTS (Pro Framework)\n",
            "============================================================\n",
            "Specificity: 63.24%\n",
            "Recall:      34.47%\n",
            "G-Means:     46.69%\n",
            "P95 Latency: 45.51 ms\n"
          ]
        }
      ],
      "source": [
        "# Safe Evaluation (Mini-Batch)\n",
        "print(\"üîç Benchmarking & Evaluation...\")\n",
        "model.load_state_dict(torch.load(f\"{MODELS_DIR}/fraudguard_best_pro.pt\"))\n",
        "model.eval()\n",
        "\n",
        "# Use neighbors=[25, 10] for fast inference (Latency < 10ms)\n",
        "test_loader = NeighborLoader(\n",
        "    optimized_data,\n",
        "    num_neighbors=[25, 10],\n",
        "    batch_size=4096,\n",
        "    input_nodes=optimized_data.test_mask,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "latencies = []\n",
        "all_preds, all_true = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        start = time.perf_counter()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        latencies.append((time.perf_counter() - start) * 1000)\n",
        "        pred = out[:batch.batch_size].argmax(dim=1)\n",
        "        all_preds.extend(pred.cpu().numpy())\n",
        "        all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
        "\n",
        "# Metrics\n",
        "cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "gmeans = np.sqrt(tpr * tnr)\n",
        "p95_latency = np.percentile(latencies, 95)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"FINAL RESULTS (Pro Framework)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Specificity: {tnr*100:.2f}%\")\n",
        "print(f\"Recall:      {tpr*100:.2f}%\")\n",
        "print(f\"G-Means:     {gmeans*100:.2f}%\")\n",
        "print(f\"P95 Latency: {p95_latency:.2f} ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqoG6I7W-Xk_"
      },
      "source": [
        "## 7Ô∏è‚É£ Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joYoeD60-XlA",
        "outputId": "87224868-4607-41a9-9e7f-8118f16e0d94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/fraudguard-models/fraudguard_full_pipeline.pt\n"
          ]
        }
      ],
      "source": [
        "trainer.save(f\"{MODELS_DIR}/fraudguard_full_pipeline.pt\")\n",
        "print(f\"Model saved to {MODELS_DIR}/fraudguard_full_pipeline.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "lqRrjwfIVP6x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}