{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ”’ FraudGuard Training Notebook\n",
                "\n",
                "**AD-RL-GNN Fraud Detection** | Full training pipeline with mini-batch processing\n",
                "\n",
                "This notebook trains the FraudGuard model on the IEEE-CIS fraud detection dataset using:\n",
                "- **NeighborLoader** for memory-efficient mini-batch training\n",
                "- **FAISS** for similarity graph construction (GPU if available, CPU fallback)\n",
                "- **FocalLoss** for class-imbalanced learning\n",
                "\n",
                "**Target Metrics:**\n",
                "- Specificity: 98.72%\n",
                "- G-Means Improvement: 18.11%\n",
                "- P95 Latency: <100ms"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1ï¸âƒ£ Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive for data storage\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone repository\n",
                "!git clone https://github.com/govind104/fraudguard.git\n",
                "%cd fraudguard"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "# Note: faiss-gpu may not be available on Python 3.12\n",
                "# The code will fallback to faiss-cpu automatically\n",
                "# GNN training STILL runs on GPU - only graph building uses CPU FAISS\n",
                "!pip install -q torch torch-geometric pandas numpy scikit-learn pyyaml structlog\n",
                "\n",
                "# Try faiss-gpu first, fallback to faiss-cpu\n",
                "import subprocess\n",
                "result = subprocess.run(['pip', 'install', '-q', 'faiss-gpu'], capture_output=True)\n",
                "if result.returncode != 0:\n",
                "    print('âš ï¸ faiss-gpu not available, using faiss-cpu')\n",
                "    print('   (Graph building on CPU, but GNN training still runs on GPU!)')\n",
                "    !pip install -q faiss-cpu\n",
                "else:\n",
                "    print('âœ“ faiss-gpu installed')\n",
                "\n",
                "import torch\n",
                "\n",
                "# 1. Get exact versions\n",
                "pt_version = torch.__version__.split('+')[0]  # e.g., 2.5.1\n",
                "cuda_version = \"cu\" + torch.version.cuda.replace('.', '')  # e.g., cu124\n",
                "wheel_url = f\"https://data.pyg.org/whl/torch-{pt_version}+{cuda_version}.html\"\n",
                "\n",
                "print(f\"PyTorch: {pt_version}, CUDA: {cuda_version}\")\n",
                "print(f\"Downloading from: {wheel_url}\")\n",
                "\n",
                "# 2. Install with visible output (force reinstall to fix broken partial installs)\n",
                "!pip install --force-reinstall torch-scatter torch-sparse -f $wheel_url\n",
                "\n",
                "# Install repo in editable mode\n",
                "!pip install -e .\n",
                "\n",
                "print('\\nâœ“ Environment setup complete')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2ï¸âƒ£ Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# ==============================================\n",
                "# CONFIGURATION - UPDATE THESE PATHS AS NEEDED\n",
                "# ==============================================\n",
                "\n",
                "# Data paths - Point to your Google Drive folders\n",
                "DATA_DIR = \"/content/drive/MyDrive/ieee-fraud-detection\"\n",
                "MODELS_DIR = \"/content/drive/MyDrive/fraudguard-models\"\n",
                "LOGS_DIR = \"/content/drive/MyDrive/fraudguard-logs\"\n",
                "\n",
                "# Training parameters\n",
                "SAMPLE_FRAC = 1.0      # Use full dataset (1.0 = 100%)\n",
                "MAX_EPOCHS = 100\n",
                "BATCH_SIZE = 4096      # Reduce to 2048 or 1024 if OOM\n",
                "NUM_NEIGHBORS = [25, 10]  # 2-hop neighborhood sampling\n",
                "\n",
                "# Create directories\n",
                "os.makedirs(MODELS_DIR, exist_ok=True)\n",
                "os.makedirs(LOGS_DIR, exist_ok=True)\n",
                "\n",
                "print(f\"Data: {DATA_DIR}\")\n",
                "print(f\"Models: {MODELS_DIR}\")\n",
                "print(f\"Logs: {LOGS_DIR}\")\n",
                "print(f\"\\nBatch size: {BATCH_SIZE}\")\n",
                "print(f\"Sample fraction: {SAMPLE_FRAC*100:.0f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3ï¸âƒ£ Verify GPU and FAISS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import faiss\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
                "    print(\"\\nâœ“ GNN training will run on GPU\")\n",
                "else:\n",
                "    print(\"\\nâš ï¸ WARNING: No GPU detected. Go to Runtime > Change runtime type > GPU\")\n",
                "\n",
                "# Check FAISS GPU\n",
                "faiss_gpus = faiss.get_num_gpus() if hasattr(faiss, 'get_num_gpus') else 0\n",
                "print(f\"\\nFAISS GPUs: {faiss_gpus}\")\n",
                "if faiss_gpus == 0:\n",
                "    print(\"   (Using CPU FAISS for graph building - this is OK)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4ï¸âƒ£ Load and Preprocess Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '/content/fraudguard')\n",
                "\n",
                "from pathlib import Path\n",
                "from src.data.loader import FraudDataLoader\n",
                "from src.data.preprocessor import FeaturePreprocessor\n",
                "from src.data.graph_builder import GraphBuilder\n",
                "from src.utils.config import load_data_config\n",
                "from src.utils.device_utils import set_seed, get_device\n",
                "\n",
                "set_seed(42)\n",
                "device = get_device()\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Load config and override path with notebook variable\n",
                "data_cfg = load_data_config()\n",
                "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
                "\n",
                "# Load data with corrected path\n",
                "loader = FraudDataLoader(config=data_cfg)\n",
                "df = loader.load_train_data(sample_frac=SAMPLE_FRAC)\n",
                "train_df, val_df, test_df = loader.create_splits(df)\n",
                "\n",
                "print(f\"\\nData loaded:\")\n",
                "print(f\"  Train: {len(train_df):,}\")\n",
                "print(f\"  Val: {len(val_df):,}\")\n",
                "print(f\"  Test: {len(test_df):,}\")\n",
                "print(f\"  Fraud rate: {df['isFraud'].mean()*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5ï¸âƒ£ Build or Load Graph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "import faiss\n",
                "import gc\n",
                "import os\n",
                "from src.utils.config import load_model_config\n",
                "\n",
                "GRAPH_CACHE = f\"{MODELS_DIR}/edges_full.pt\"\n",
                "FEATURES_CACHE = f\"{MODELS_DIR}/features_full.pt\"\n",
                "\n",
                "# Configuration\n",
                "CHUNK_SIZE = 50000        \n",
                "THRESHOLD = 0.90          \n",
                "MAX_NEIGHBORS = 50        \n",
                "\n",
                "def build_edges_in_chunks(source_feats, target_feats, index, start_offset_idx, desc=\"Processing\"):\n",
                "    \"\"\"\n",
                "    Searches 'index' using 'source_feats' in chunks to avoid OOM.\n",
                "    Returns a list of edge tensors (2, num_edges).\n",
                "    \"\"\"\n",
                "    edge_chunks = []\n",
                "    num_source = len(source_feats)\n",
                "    \n",
                "    for start in range(0, num_source, CHUNK_SIZE):\n",
                "        end = min(start + CHUNK_SIZE, num_source)\n",
                "        print(f\"  [{desc}] Batch {start}-{end} / {num_source}...\")\n",
                "        \n",
                "        # 1. Get batch\n",
                "        batch_feats = source_feats[start:end]\n",
                "        \n",
                "        # 2. Search FAISS\n",
                "        D, I = index.search(batch_feats, MAX_NEIGHBORS)\n",
                "        \n",
                "        # 3. Vectorized Filter\n",
                "        src_indices = np.arange(start, end) + start_offset_idx\n",
                "        src_expanded = src_indices[:, None]\n",
                "        \n",
                "        # Create mask\n",
                "        mask = (D > THRESHOLD) & (I != src_expanded) & (I != -1)\n",
                "        \n",
                "        # Broadcast src to match shape\n",
                "        src_broadcast = np.broadcast_to(src_expanded, I.shape)\n",
                "        \n",
                "        valid_src = src_broadcast[mask]\n",
                "        valid_dst = I[mask]\n",
                "        \n",
                "        if len(valid_src) > 0:\n",
                "            chunk_edges = torch.stack([\n",
                "                torch.from_numpy(valid_src),\n",
                "                torch.from_numpy(valid_dst)\n",
                "            ], dim=0).to(torch.long)\n",
                "            edge_chunks.append(chunk_edges)\n",
                "            \n",
                "        del D, I, mask, batch_feats, valid_src, valid_dst, src_broadcast\n",
                "        gc.collect()\n",
                "        \n",
                "    return edge_chunks\n",
                "\n",
                "# ==========================================\n",
                "# Main Execution Flow\n",
                "# ==========================================\n",
                "\n",
                "if os.path.exists(GRAPH_CACHE):\n",
                "    print(\"Loading cached graph from Google Drive...\")\n",
                "    edge_index = torch.load(GRAPH_CACHE)\n",
                "    print(f\"Loaded {edge_index.shape[1]:,} edges\")\n",
                "    \n",
                "    if 'X_full' not in locals():\n",
                "         X_full = torch.load(FEATURES_CACHE)\n",
                "    \n",
                "    edge_index = edge_index.to(device)\n",
                "    X_full = X_full.to(device)\n",
                "\n",
                "else:\n",
                "    print(\"ðŸš€ Starting Memory-Optimized Graph Build (Directed)...\")\n",
                "    \n",
                "    # 1. Prepare Data\n",
                "    prep = FeaturePreprocessor()\n",
                "    X_train_np = prep.fit_transform(train_df).cpu().numpy().astype(np.float32)\n",
                "    X_val_np = prep.transform(val_df).cpu().numpy().astype(np.float32)\n",
                "    X_test_np = prep.transform(test_df).cpu().numpy().astype(np.float32)\n",
                "    \n",
                "    # Save lengths\n",
                "    n_train = len(X_train_np)\n",
                "    n_val = len(X_val_np)\n",
                "    n_test = len(X_test_np)\n",
                "    \n",
                "    # Save full features\n",
                "    X_full = torch.cat([\n",
                "        torch.from_numpy(X_train_np), \n",
                "        torch.from_numpy(X_val_np), \n",
                "        torch.from_numpy(X_test_np)\n",
                "    ])\n",
                "    \n",
                "    # Clear DataFrames\n",
                "    del df, train_df, val_df, test_df\n",
                "    gc.collect()\n",
                "\n",
                "    # 2. Setup FAISS (CPU)\n",
                "    print(\"Building FAISS Index on Train Data...\")\n",
                "    faiss.normalize_L2(X_train_np)\n",
                "    index = faiss.IndexFlatIP(X_train_np.shape[1])\n",
                "    index.add(X_train_np)\n",
                "    print(\"âœ“ FAISS index built (CPU mode)\")\n",
                "\n",
                "    # 3. Build Edges (Phased)\n",
                "    print(\"\\nPhase 1: linking Train -> Train...\")\n",
                "    train_chunks = build_edges_in_chunks(X_train_np, None, index, 0, \"Train\")\n",
                "    del X_train_np; gc.collect()\n",
                "\n",
                "    print(\"\\nPhase 2: linking Val -> Train...\")\n",
                "    faiss.normalize_L2(X_val_np)\n",
                "    val_chunks = build_edges_in_chunks(X_val_np, None, index, n_train, \"Val\")\n",
                "    del X_val_np; gc.collect()\n",
                "\n",
                "    print(\"\\nPhase 3: linking Test -> Train...\")\n",
                "    faiss.normalize_L2(X_test_np)\n",
                "    test_chunks = build_edges_in_chunks(X_test_np, None, index, n_train + n_val, \"Test\")\n",
                "    del X_test_np; gc.collect()\n",
                "\n",
                "    # 4. Merge (Directed Graph Only)\n",
                "    print(\"\\nMerging edge chunks...\")\n",
                "    all_chunks = train_chunks + val_chunks + test_chunks\n",
                "    \n",
                "    if len(all_chunks) > 0:\n",
                "        edge_index = torch.cat(all_chunks, dim=1)\n",
                "        \n",
                "        # --- OOM FIX: SKIPPING SYMMETRIZATION ---\n",
                "        # We perform a lightweight sort instead of a heavy unique/symmetrize\n",
                "        # This keeps the graph directed (A->B) but saves 50% RAM\n",
                "        print(\"Sorting edges (Directed)...\")\n",
                "        # Sort by source node (row 0)\n",
                "        idx = edge_index[0].argsort()\n",
                "        edge_index = edge_index[:, idx]\n",
                "        \n",
                "    else:\n",
                "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
                "\n",
                "    print(f\"Total Edges Generated: {edge_index.shape[1]:,}\")\n",
                "    \n",
                "    # Save to Drive\n",
                "    torch.save(edge_index, GRAPH_CACHE)\n",
                "    torch.save(X_full, FEATURES_CACHE)\n",
                "    print(f\"âœ“ Saved to {GRAPH_CACHE}\")\n",
                "    \n",
                "    del index, all_chunks\n",
                "    gc.collect()\n",
                "\n",
                "# Final Device Move\n",
                "print(\"Moving final tensors to GPU...\")\n",
                "X_full = X_full.to(device)\n",
                "edge_index = edge_index.to(device)\n",
                "print(f\"\\nFinal Graph ready on {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6ï¸âƒ£ Setup Mini-Batch Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch_geometric.loader import NeighborLoader\n",
                "from torch_geometric.data import Data\n",
                "from pathlib import Path\n",
                "import torch.nn.functional as F\n",
                "import gc\n",
                "import sys\n",
                "\n",
                "# 1. Reload Data briefly to get Labels & Lengths (since we deleted them)\n",
                "# We need to re-import loader components if they were lost\n",
                "sys.path.insert(0, '/content/fraudguard')\n",
                "from src.data.loader import FraudDataLoader\n",
                "from src.utils.config import load_data_config\n",
                "\n",
                "print(\"Reloading data to extract labels...\")\n",
                "data_cfg = load_data_config()\n",
                "data_cfg.paths.raw_data_dir = Path(DATA_DIR) # Ensure pointing to Drive\n",
                "loader = FraudDataLoader(config=data_cfg)\n",
                "\n",
                "# Load and split\n",
                "df_temp = loader.load_train_data(sample_frac=1.0) # Use same sample_frac!\n",
                "train_df, val_df, test_df = loader.create_splits(df_temp)\n",
                "\n",
                "# 2. Extract Labels & Sizes\n",
                "print(\"Extracting labels...\")\n",
                "train_labels = torch.tensor(train_df[\"isFraud\"].values, dtype=torch.long)\n",
                "val_labels = torch.tensor(val_df[\"isFraud\"].values, dtype=torch.long)\n",
                "test_labels = torch.tensor(test_df[\"isFraud\"].values, dtype=torch.long)\n",
                "\n",
                "n_train = len(train_df)\n",
                "n_val = len(val_df)\n",
                "n_test = len(test_df)\n",
                "\n",
                "# 3. Aggressive Cleanup (Free RAM immediately)\n",
                "del df_temp, train_df, val_df, test_df\n",
                "gc.collect()\n",
                "print(\"Dataframes deleted to free RAM.\")\n",
                "\n",
                "# 4. Prepare Masks & Labels\n",
                "all_labels = torch.cat([train_labels, val_labels, test_labels]).to(device)\n",
                "\n",
                "n_total = n_train + n_val + n_test\n",
                "train_mask = torch.zeros(n_total, dtype=torch.bool)\n",
                "val_mask = torch.zeros(n_total, dtype=torch.bool)\n",
                "test_mask = torch.zeros(n_total, dtype=torch.bool)\n",
                "\n",
                "# Set masks using the calculated lengths\n",
                "train_mask[:n_train] = True\n",
                "val_mask[n_train : n_train + n_val] = True\n",
                "test_mask[n_train + n_val :] = True\n",
                "\n",
                "print(f\"Masks created: Train={train_mask.sum()}, Val={val_mask.sum()}, Test={test_mask.sum()}\")\n",
                "\n",
                "# 5. Create PyG Data object\n",
                "# Ensure X_full and edge_index are on the correct device\n",
                "if X_full.device != device:\n",
                "    X_full = X_full.to(device)\n",
                "if edge_index.device != device:\n",
                "    edge_index = edge_index.to(device)\n",
                "\n",
                "data = Data(x=X_full, edge_index=edge_index, y=all_labels)\n",
                "data.train_mask = train_mask\n",
                "data.val_mask = val_mask\n",
                "data.test_mask = test_mask\n",
                "\n",
                "# 6. Create NeighborLoaders\n",
                "print(f\"Initializing NeighborLoaders (Batch Size: {BATCH_SIZE})...\")\n",
                "\n",
                "train_loader = NeighborLoader(\n",
                "    data,\n",
                "    num_neighbors=NUM_NEIGHBORS,  # [25, 10]\n",
                "    batch_size=BATCH_SIZE,\n",
                "    input_nodes=train_mask,\n",
                "    shuffle=True\n",
                ")\n",
                "\n",
                "val_loader = NeighborLoader(\n",
                "    data,\n",
                "    num_neighbors=NUM_NEIGHBORS,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    input_nodes=val_mask,\n",
                "    shuffle=False\n",
                ")\n",
                "\n",
                "print(f\"âœ“ Train batches: {len(train_loader)}\")\n",
                "print(f\"âœ“ Val batches: {len(val_loader)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7ï¸âƒ£ Train Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.models import FraudGNN, FocalLoss, compute_class_weights\n",
                "from sklearn.metrics import confusion_matrix, f1_score\n",
                "import numpy as np\n",
                "import time\n",
                "\n",
                "# Initialize model\n",
                "model = FraudGNN(in_channels=X_full.shape[1]).to(device)\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
                "weights = compute_class_weights(train_labels, device)\n",
                "criterion = FocalLoss(alpha=0.5, gamma=4, weight=weights)\n",
                "\n",
                "# Training config\n",
                "best_gmeans = 0\n",
                "patience = 30\n",
                "patience_counter = 0\n",
                "history = []\n",
                "\n",
                "print(\"Starting training...\\n\")\n",
                "print(f\"{'Epoch':>5} | {'Loss':>8} | {'Spec':>8} | {'Recall':>8} | {'F1':>8} | {'G-Means':>8}\")\n",
                "print(\"-\" * 60)\n",
                "\n",
                "start_time = time.time()\n",
                "\n",
                "for epoch in range(MAX_EPOCHS):\n",
                "    # Training\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    for batch in train_loader:\n",
                "        batch = batch.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        out = model(batch.x, batch.edge_index)\n",
                "        loss = criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += loss.item()\n",
                "    \n",
                "    avg_loss = total_loss / len(train_loader)\n",
                "    \n",
                "    # Validation every 5 epochs\n",
                "    if epoch % 5 == 0:\n",
                "        model.eval()\n",
                "        all_preds, all_true = [], []\n",
                "        with torch.no_grad():\n",
                "            for batch in val_loader:\n",
                "                batch = batch.to(device)\n",
                "                out = model(batch.x, batch.edge_index)\n",
                "                pred = out[:batch.batch_size].argmax(dim=1)\n",
                "                all_preds.extend(pred.cpu().numpy())\n",
                "                all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
                "        \n",
                "        cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
                "        tn, fp, fn, tp = cm.ravel()\n",
                "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
                "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
                "        gmeans = np.sqrt(tpr * tnr)\n",
                "        f1 = f1_score(all_true, all_preds, zero_division=0)\n",
                "        \n",
                "        history.append({'epoch': epoch, 'loss': avg_loss, 'spec': tnr, 'recall': tpr, 'f1': f1, 'gmeans': gmeans})\n",
                "        \n",
                "        print(f\"{epoch+1:>5} | {avg_loss:>8.4f} | {tnr*100:>7.2f}% | {tpr*100:>7.2f}% | {f1*100:>7.2f}% | {gmeans*100:>7.2f}%\")\n",
                "        \n",
                "        # Early stopping\n",
                "        if gmeans > best_gmeans:\n",
                "            best_gmeans = gmeans\n",
                "            patience_counter = 0\n",
                "            torch.save(model.state_dict(), f\"{MODELS_DIR}/best_model.pt\")\n",
                "        else:\n",
                "            patience_counter += 1\n",
                "            if patience_counter >= patience // 5:\n",
                "                print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
                "                break\n",
                "\n",
                "train_time = time.time() - start_time\n",
                "print(f\"\\nTraining complete in {train_time/60:.1f} minutes\")\n",
                "print(f\"Best validation G-Means: {best_gmeans*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8ï¸âƒ£ Evaluate on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "# Load best model\n",
                "model.load_state_dict(torch.load(f\"{MODELS_DIR}/best_model.pt\"))\n",
                "model.eval()\n",
                "\n",
                "# Full neighborhood for test evaluation\n",
                "test_loader = NeighborLoader(\n",
                "    data,\n",
                "    num_neighbors=[-1, -1],  # Full neighborhood\n",
                "    batch_size=BATCH_SIZE,\n",
                "    input_nodes=test_mask,\n",
                "    shuffle=False,\n",
                ")\n",
                "\n",
                "all_preds, all_true = [], []\n",
                "latencies = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for batch in test_loader:\n",
                "        batch = batch.to(device)\n",
                "        start = time.perf_counter()\n",
                "        out = model(batch.x, batch.edge_index)\n",
                "        latencies.append((time.perf_counter() - start) * 1000)\n",
                "        pred = out[:batch.batch_size].argmax(dim=1)\n",
                "        all_preds.extend(pred.cpu().numpy())\n",
                "        all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
                "\n",
                "# Compute metrics\n",
                "cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
                "tn, fp, fn, tp = cm.ravel()\n",
                "tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
                "tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
                "gmeans = np.sqrt(tpr * tnr)\n",
                "f1 = f1_score(all_true, all_preds, zero_division=0)\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"FINAL TEST RESULTS\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"\\nConfusion Matrix:\")\n",
                "print(f\"  TP: {tp:,}  |  FN: {fn:,}\")\n",
                "print(f\"  FP: {fp:,}  |  TN: {tn:,}\")\n",
                "print(f\"\\nPerformance:\")\n",
                "print(f\"  Specificity:  {tnr*100:.2f}%  (CV target: 98.72%)\")\n",
                "print(f\"  Recall:       {tpr*100:.2f}%\")\n",
                "print(f\"  F1 Score:     {f1*100:.2f}%\")\n",
                "print(f\"  G-Means:      {gmeans*100:.2f}%\")\n",
                "print(f\"\\nLatency:\")\n",
                "print(f\"  Mean: {np.mean(latencies):.1f}ms\")\n",
                "print(f\"  P95:  {np.percentile(latencies, 95):.1f}ms  (CV target: <100ms)\")\n",
                "print(f\"  P99:  {np.percentile(latencies, 99):.1f}ms\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9ï¸âƒ£ Save Final Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save final model with metrics\n",
                "torch.save({\n",
                "    \"model_state_dict\": model.state_dict(),\n",
                "    \"config\": {\n",
                "        \"in_channels\": X_full.shape[1],\n",
                "        \"specificity\": tnr,\n",
                "        \"recall\": tpr,\n",
                "        \"gmeans\": gmeans,\n",
                "        \"f1\": f1,\n",
                "    },\n",
                "    \"history\": history,\n",
                "}, f\"{MODELS_DIR}/fraudguard_final.pt\")\n",
                "\n",
                "print(f\"âœ“ Model saved to {MODELS_DIR}/fraudguard_final.pt\")\n",
                "print(f\"âœ“ Best model saved to {MODELS_DIR}/best_model.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ”Ÿ CV Claims Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CV Claims comparison\n",
                "CV_CLAIMS = {\n",
                "    \"specificity\": 98.72,\n",
                "    \"gmeans_improvement\": 18.11,\n",
                "    \"p95_latency_ms\": 100,\n",
                "}\n",
                "\n",
                "achieved_spec = tnr * 100\n",
                "p95_latency = np.percentile(latencies, 95)\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"CV CLAIMS COMPARISON\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"| {'Metric':<20} | {'Achieved':>12} | {'CV Claim':>12} | {'Status':>6} |\")\n",
                "print(f\"|{'-'*22}|{'-'*14}|{'-'*14}|{'-'*8}|\")\n",
                "\n",
                "# Specificity\n",
                "status_spec = \"âœ“\" if abs(achieved_spec - CV_CLAIMS['specificity']) <= 3 else \"âœ—\"\n",
                "print(f\"| {'Specificity':<20} | {achieved_spec:>11.2f}% | {CV_CLAIMS['specificity']:>11.2f}% | {status_spec:>6} |\")\n",
                "\n",
                "# Latency\n",
                "status_lat = \"âœ“\" if p95_latency < CV_CLAIMS['p95_latency_ms'] else \"âœ—\"\n",
                "print(f\"| {'P95 Latency':<20} | {p95_latency:>10.1f}ms | {'<100':>10}ms | {status_lat:>6} |\")\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"\\nâœ“ = PASS (within tolerance) | âœ— = INVESTIGATE\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
