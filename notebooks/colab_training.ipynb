{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ”’ FraudGuard Training Notebook\n",
                "\n",
                "**AD-RL-GNN Fraud Detection** | Full training pipeline with mini-batch processing\n",
                "\n",
                "This notebook trains the FraudGuard model on the IEEE-CIS fraud detection dataset using:\n",
                "- **NeighborLoader** for memory-efficient mini-batch training\n",
                "- **FAISS** for similarity graph construction (GPU if available, CPU fallback)\n",
                "- **FocalLoss** for class-imbalanced learning\n",
                "\n",
                "**Target Metrics:**\n",
                "- Specificity: 98.72%\n",
                "- G-Means Improvement: 18.11%\n",
                "- P95 Latency: <100ms"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1ï¸âƒ£ Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive for data storage\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone repository\n",
                "!git clone https://github.com/govind104/fraudguard.git\n",
                "%cd fraudguard"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "# Note: faiss-gpu may not be available on Python 3.12\n",
                "# The code will fallback to faiss-cpu automatically\n",
                "# GNN training STILL runs on GPU - only graph building uses CPU FAISS\n",
                "!pip install -q torch torch-geometric pandas numpy scikit-learn pyyaml structlog\n",
                "\n",
                "# Try faiss-gpu first, fallback to faiss-cpu\n",
                "import subprocess\n",
                "result = subprocess.run(['pip', 'install', '-q', 'faiss-gpu'], capture_output=True)\n",
                "if result.returncode != 0:\n",
                "    print('âš ï¸ faiss-gpu not available, using faiss-cpu')\n",
                "    print('   (Graph building on CPU, but GNN training still runs on GPU!)')\n",
                "    !pip install -q faiss-cpu\n",
                "else:\n",
                "    print('âœ“ faiss-gpu installed')\n",
                "\n",
                "# Install repo in editable mode\n",
                "!pip install -e .\n",
                "\n",
                "print('\\nâœ“ Environment setup complete')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2ï¸âƒ£ Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# ==============================================\n",
                "# CONFIGURATION - UPDATE THESE PATHS AS NEEDED\n",
                "# ==============================================\n",
                "\n",
                "# Data paths - Point to your Google Drive folders\n",
                "DATA_DIR = \"/content/drive/MyDrive/ieee-fraud-detection\"\n",
                "MODELS_DIR = \"/content/drive/MyDrive/fraudguard-models\"\n",
                "LOGS_DIR = \"/content/drive/MyDrive/fraudguard-logs\"\n",
                "\n",
                "# Training parameters\n",
                "SAMPLE_FRAC = 1.0      # Use full dataset (1.0 = 100%)\n",
                "MAX_EPOCHS = 100\n",
                "BATCH_SIZE = 4096      # Reduce to 2048 or 1024 if OOM\n",
                "NUM_NEIGHBORS = [25, 10]  # 2-hop neighborhood sampling\n",
                "\n",
                "# Create directories\n",
                "os.makedirs(MODELS_DIR, exist_ok=True)\n",
                "os.makedirs(LOGS_DIR, exist_ok=True)\n",
                "\n",
                "print(f\"Data: {DATA_DIR}\")\n",
                "print(f\"Models: {MODELS_DIR}\")\n",
                "print(f\"Logs: {LOGS_DIR}\")\n",
                "print(f\"\\nBatch size: {BATCH_SIZE}\")\n",
                "print(f\"Sample fraction: {SAMPLE_FRAC*100:.0f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3ï¸âƒ£ Verify GPU and FAISS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import faiss\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
                "    print(\"\\nâœ“ GNN training will run on GPU\")\n",
                "else:\n",
                "    print(\"\\nâš ï¸ WARNING: No GPU detected. Go to Runtime > Change runtime type > GPU\")\n",
                "\n",
                "# Check FAISS GPU\n",
                "faiss_gpus = faiss.get_num_gpus() if hasattr(faiss, 'get_num_gpus') else 0\n",
                "print(f\"\\nFAISS GPUs: {faiss_gpus}\")\n",
                "if faiss_gpus == 0:\n",
                "    print(\"   (Using CPU FAISS for graph building - this is OK)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4ï¸âƒ£ Load and Preprocess Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '/content/fraudguard')\n",
                "\n",
                "from pathlib import Path\n",
                "from src.data.loader import FraudDataLoader\n",
                "from src.data.preprocessor import FeaturePreprocessor\n",
                "from src.data.graph_builder import GraphBuilder\n",
                "from src.utils.config import load_data_config\n",
                "from src.utils.device_utils import set_seed, get_device\n",
                "\n",
                "set_seed(42)\n",
                "device = get_device()\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Load config and override path with notebook variable\n",
                "data_cfg = load_data_config()\n",
                "data_cfg.paths.raw_data_dir = Path(DATA_DIR)\n",
                "\n",
                "# Load data with corrected path\n",
                "loader = FraudDataLoader(config=data_cfg)\n",
                "df = loader.load_train_data(sample_frac=SAMPLE_FRAC)\n",
                "train_df, val_df, test_df = loader.create_splits(df)\n",
                "\n",
                "print(f\"\\nData loaded:\")\n",
                "print(f\"  Train: {len(train_df):,}\")\n",
                "print(f\"  Val: {len(val_df):,}\")\n",
                "print(f\"  Test: {len(test_df):,}\")\n",
                "print(f\"  Fraud rate: {df['isFraud'].mean()*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5ï¸âƒ£ Build or Load Graph"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import os\n",
                "import gc\n",
                "from src.utils.config import load_model_config\n",
                "\n",
                "GRAPH_CACHE = f\"{MODELS_DIR}/edges_full.pt\"\n",
                "FEATURES_CACHE = f\"{MODELS_DIR}/features_full.pt\"\n",
                "\n",
                "# 1. Aggressive Cleanup before starting\n",
                "# We don't need the raw pandas DataFrames anymore if we have the tensors\n",
                "# This frees up ~1-2GB of System RAM immediately\n",
                "del df\n",
                "gc.collect()\n",
                "\n",
                "# 2. Preprocess features - KEEP ON CPU INITIALLY\n",
                "# We do NOT move to .to(device) yet to save GPU VRAM for FAISS\n",
                "print(\"Preprocessing features (CPU)...\")\n",
                "prep = FeaturePreprocessor()\n",
                "X_train = prep.fit_transform(train_df)\n",
                "X_val = prep.transform(val_df)\n",
                "X_test = prep.transform(test_df)\n",
                "\n",
                "# In Cell 6, the labels were already extracted before the del\n",
                "# If you get a NameError for train_df, save labels BEFORE the del in Cell 5:\n",
                "\n",
                "# Prepare labels\n",
                "train_labels = torch.tensor(train_df[\"isFraud\"].values, dtype=torch.long)\n",
                "val_labels = torch.tensor(val_df[\"isFraud\"].values, dtype=torch.long)\n",
                "test_labels = torch.tensor(test_df[\"isFraud\"].values, dtype=torch.long)\n",
                "\n",
                "# Free up dataframe memory\n",
                "del train_df, val_df, test_df\n",
                "gc.collect()\n",
                "\n",
                "# Concatenate on CPU\n",
                "X_full = torch.cat([X_train, X_val, X_test])\n",
                "print(f\"Features shape: {X_full.shape}\")\n",
                "\n",
                "# 3. Graph Logic\n",
                "if os.path.exists(GRAPH_CACHE):\n",
                "    print(\"Loading cached graph from Google Drive...\")\n",
                "    edge_index = torch.load(GRAPH_CACHE)\n",
                "    print(f\"Loaded {edge_index.shape[1]:,} edges\")\n",
                "else:\n",
                "    print(\"Building graph with STRICTER threshold (0.9)...\")\n",
                "    \n",
                "    # LOAD & OVERRIDE CONFIG\n",
                "    # We force the threshold to 0.9 to reduce edge count by ~70-80%\n",
                "    model_cfg = load_model_config()\n",
                "    model_cfg.graph.similarity_threshold = 0.9 \n",
                "    \n",
                "    builder = GraphBuilder(config=model_cfg)\n",
                "    \n",
                "    # Fit on Train\n",
                "    print(\"Fitting FAISS index...\")\n",
                "    train_edges = builder.fit(X_train)\n",
                "    \n",
                "    # Transform Remainder (Val/Test)\n",
                "    # We pass the config explicitly if your class supports it, \n",
                "    # otherwise the builder.config update above handles it\n",
                "    print(\"Searching for neighbors (this is the memory-intensive part)...\")\n",
                "    edge_index = builder.transform(torch.cat([X_val, X_test]), train_size=len(X_train))\n",
                "    \n",
                "    # Verify leak-free\n",
                "    print(\"Verifying graph integrity...\")\n",
                "    builder.verify_no_leakage(edge_index, train_size=len(X_train))\n",
                "    \n",
                "    # Cache to Drive\n",
                "    print(f\"Saving {edge_index.shape[1]:,} edges to Drive...\")\n",
                "    torch.save(edge_index, GRAPH_CACHE)\n",
                "    torch.save(X_full, FEATURES_CACHE)\n",
                "    print(f\"Graph cached to {GRAPH_CACHE}\")\n",
                "\n",
                "# 4. Final Move to GPU\n",
                "# Now that the heavy lifting is done, we move data to GPU\n",
                "print(\"Moving data to GPU...\")\n",
                "X_full = X_full.to(device)\n",
                "edge_index = edge_index.to(device)\n",
                "\n",
                "print(f\"\\nFinal Graph: {edge_index.shape[1]:,} edges on {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6ï¸âƒ£ Setup Mini-Batch Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch_geometric.loader import NeighborLoader\n",
                "from torch_geometric.data import Data\n",
                "import torch.nn.functional as F\n",
                "\n",
                "# Prepare labels\n",
                "train_labels = torch.tensor(train_df[\"isFraud\"].values, dtype=torch.long)\n",
                "val_labels = torch.tensor(val_df[\"isFraud\"].values, dtype=torch.long)\n",
                "test_labels = torch.tensor(test_df[\"isFraud\"].values, dtype=torch.long)\n",
                "all_labels = torch.cat([train_labels, val_labels, test_labels]).to(device)\n",
                "\n",
                "# Create masks\n",
                "n = len(X_full)\n",
                "train_mask = torch.zeros(n, dtype=torch.bool)\n",
                "val_mask = torch.zeros(n, dtype=torch.bool)\n",
                "test_mask = torch.zeros(n, dtype=torch.bool)\n",
                "train_mask[:len(X_train)] = True\n",
                "val_mask[len(X_train):len(X_train)+len(X_val)] = True\n",
                "test_mask[len(X_train)+len(X_val):] = True\n",
                "\n",
                "# Create PyG Data object\n",
                "data = Data(x=X_full, edge_index=edge_index, y=all_labels)\n",
                "data.train_mask = train_mask\n",
                "data.val_mask = val_mask\n",
                "data.test_mask = test_mask\n",
                "\n",
                "# Create NeighborLoader for mini-batch training\n",
                "# This is the KEY to avoiding OOM - samples subgraphs instead of full graph\n",
                "train_loader = NeighborLoader(\n",
                "    data,\n",
                "    num_neighbors=NUM_NEIGHBORS,  # [25, 10] = 25 first-hop, 10 second-hop\n",
                "    batch_size=BATCH_SIZE,\n",
                "    input_nodes=train_mask,\n",
                "    shuffle=True,\n",
                ")\n",
                "\n",
                "val_loader = NeighborLoader(\n",
                "    data,\n",
                "    num_neighbors=NUM_NEIGHBORS,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    input_nodes=val_mask,\n",
                "    shuffle=False,\n",
                ")\n",
                "\n",
                "print(f\"Train batches: {len(train_loader)}\")\n",
                "print(f\"Val batches: {len(val_loader)}\")\n",
                "print(f\"Batch size: {BATCH_SIZE}\")\n",
                "print(f\"Neighbor sampling: {NUM_NEIGHBORS}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7ï¸âƒ£ Train Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.models import FraudGNN, FocalLoss, compute_class_weights\n",
                "from sklearn.metrics import confusion_matrix, f1_score\n",
                "import numpy as np\n",
                "import time\n",
                "\n",
                "# Initialize model\n",
                "model = FraudGNN(in_channels=X_full.shape[1]).to(device)\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
                "weights = compute_class_weights(train_labels, device)\n",
                "criterion = FocalLoss(alpha=0.5, gamma=4, weight=weights)\n",
                "\n",
                "# Training config\n",
                "best_gmeans = 0\n",
                "patience = 30\n",
                "patience_counter = 0\n",
                "history = []\n",
                "\n",
                "print(\"Starting training...\\n\")\n",
                "print(f\"{'Epoch':>5} | {'Loss':>8} | {'Spec':>8} | {'Recall':>8} | {'F1':>8} | {'G-Means':>8}\")\n",
                "print(\"-\" * 60)\n",
                "\n",
                "start_time = time.time()\n",
                "\n",
                "for epoch in range(MAX_EPOCHS):\n",
                "    # Training\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    for batch in train_loader:\n",
                "        batch = batch.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        out = model(batch.x, batch.edge_index)\n",
                "        loss = criterion(out[:batch.batch_size], batch.y[:batch.batch_size])\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += loss.item()\n",
                "    \n",
                "    avg_loss = total_loss / len(train_loader)\n",
                "    \n",
                "    # Validation every 5 epochs\n",
                "    if epoch % 5 == 0:\n",
                "        model.eval()\n",
                "        all_preds, all_true = [], []\n",
                "        with torch.no_grad():\n",
                "            for batch in val_loader:\n",
                "                batch = batch.to(device)\n",
                "                out = model(batch.x, batch.edge_index)\n",
                "                pred = out[:batch.batch_size].argmax(dim=1)\n",
                "                all_preds.extend(pred.cpu().numpy())\n",
                "                all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
                "        \n",
                "        cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
                "        tn, fp, fn, tp = cm.ravel()\n",
                "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
                "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
                "        gmeans = np.sqrt(tpr * tnr)\n",
                "        f1 = f1_score(all_true, all_preds, zero_division=0)\n",
                "        \n",
                "        history.append({'epoch': epoch, 'loss': avg_loss, 'spec': tnr, 'recall': tpr, 'f1': f1, 'gmeans': gmeans})\n",
                "        \n",
                "        print(f\"{epoch+1:>5} | {avg_loss:>8.4f} | {tnr*100:>7.2f}% | {tpr*100:>7.2f}% | {f1*100:>7.2f}% | {gmeans*100:>7.2f}%\")\n",
                "        \n",
                "        # Early stopping\n",
                "        if gmeans > best_gmeans:\n",
                "            best_gmeans = gmeans\n",
                "            patience_counter = 0\n",
                "            torch.save(model.state_dict(), f\"{MODELS_DIR}/best_model.pt\")\n",
                "        else:\n",
                "            patience_counter += 1\n",
                "            if patience_counter >= patience // 5:\n",
                "                print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
                "                break\n",
                "\n",
                "train_time = time.time() - start_time\n",
                "print(f\"\\nTraining complete in {train_time/60:.1f} minutes\")\n",
                "print(f\"Best validation G-Means: {best_gmeans*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8ï¸âƒ£ Evaluate on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "# Load best model\n",
                "model.load_state_dict(torch.load(f\"{MODELS_DIR}/best_model.pt\"))\n",
                "model.eval()\n",
                "\n",
                "# Full neighborhood for test evaluation\n",
                "test_loader = NeighborLoader(\n",
                "    data,\n",
                "    num_neighbors=[-1, -1],  # Full neighborhood\n",
                "    batch_size=BATCH_SIZE,\n",
                "    input_nodes=test_mask,\n",
                "    shuffle=False,\n",
                ")\n",
                "\n",
                "all_preds, all_true = [], []\n",
                "latencies = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for batch in test_loader:\n",
                "        batch = batch.to(device)\n",
                "        start = time.perf_counter()\n",
                "        out = model(batch.x, batch.edge_index)\n",
                "        latencies.append((time.perf_counter() - start) * 1000)\n",
                "        pred = out[:batch.batch_size].argmax(dim=1)\n",
                "        all_preds.extend(pred.cpu().numpy())\n",
                "        all_true.extend(batch.y[:batch.batch_size].cpu().numpy())\n",
                "\n",
                "# Compute metrics\n",
                "cm = confusion_matrix(all_true, all_preds, labels=[0, 1])\n",
                "tn, fp, fn, tp = cm.ravel()\n",
                "tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
                "tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
                "gmeans = np.sqrt(tpr * tnr)\n",
                "f1 = f1_score(all_true, all_preds, zero_division=0)\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"FINAL TEST RESULTS\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"\\nConfusion Matrix:\")\n",
                "print(f\"  TP: {tp:,}  |  FN: {fn:,}\")\n",
                "print(f\"  FP: {fp:,}  |  TN: {tn:,}\")\n",
                "print(f\"\\nPerformance:\")\n",
                "print(f\"  Specificity:  {tnr*100:.2f}%  (CV target: 98.72%)\")\n",
                "print(f\"  Recall:       {tpr*100:.2f}%\")\n",
                "print(f\"  F1 Score:     {f1*100:.2f}%\")\n",
                "print(f\"  G-Means:      {gmeans*100:.2f}%\")\n",
                "print(f\"\\nLatency:\")\n",
                "print(f\"  Mean: {np.mean(latencies):.1f}ms\")\n",
                "print(f\"  P95:  {np.percentile(latencies, 95):.1f}ms  (CV target: <100ms)\")\n",
                "print(f\"  P99:  {np.percentile(latencies, 99):.1f}ms\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9ï¸âƒ£ Save Final Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save final model with metrics\n",
                "torch.save({\n",
                "    \"model_state_dict\": model.state_dict(),\n",
                "    \"config\": {\n",
                "        \"in_channels\": X_full.shape[1],\n",
                "        \"specificity\": tnr,\n",
                "        \"recall\": tpr,\n",
                "        \"gmeans\": gmeans,\n",
                "        \"f1\": f1,\n",
                "    },\n",
                "    \"history\": history,\n",
                "}, f\"{MODELS_DIR}/fraudguard_final.pt\")\n",
                "\n",
                "print(f\"âœ“ Model saved to {MODELS_DIR}/fraudguard_final.pt\")\n",
                "print(f\"âœ“ Best model saved to {MODELS_DIR}/best_model.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ”Ÿ CV Claims Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CV Claims comparison\n",
                "CV_CLAIMS = {\n",
                "    \"specificity\": 98.72,\n",
                "    \"gmeans_improvement\": 18.11,\n",
                "    \"p95_latency_ms\": 100,\n",
                "}\n",
                "\n",
                "achieved_spec = tnr * 100\n",
                "p95_latency = np.percentile(latencies, 95)\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"CV CLAIMS COMPARISON\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"| {'Metric':<20} | {'Achieved':>12} | {'CV Claim':>12} | {'Status':>6} |\")\n",
                "print(f\"|{'-'*22}|{'-'*14}|{'-'*14}|{'-'*8}|\")\n",
                "\n",
                "# Specificity\n",
                "status_spec = \"âœ“\" if abs(achieved_spec - CV_CLAIMS['specificity']) <= 3 else \"âœ—\"\n",
                "print(f\"| {'Specificity':<20} | {achieved_spec:>11.2f}% | {CV_CLAIMS['specificity']:>11.2f}% | {status_spec:>6} |\")\n",
                "\n",
                "# Latency\n",
                "status_lat = \"âœ“\" if p95_latency < CV_CLAIMS['p95_latency_ms'] else \"âœ—\"\n",
                "print(f\"| {'P95 Latency':<20} | {p95_latency:>10.1f}ms | {'<100':>10}ms | {status_lat:>6} |\")\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"\\nâœ“ = PASS (within tolerance) | âœ— = INVESTIGATE\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
